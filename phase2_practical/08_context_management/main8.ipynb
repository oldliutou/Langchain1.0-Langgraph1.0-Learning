{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "26d5f0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LangChain 1.0 - Context Management (上下文管理)\n",
      "==============================================\n",
      "\n",
      "本模块重点讲解：\n",
      "1. SummarizationMiddleware - 自动摘要中间件（LangChain 1.0 新增）\n",
      "2. trim_messages - 消息修剪工具\n",
      "3. 管理对话长度，避免超 token\n",
      "4. 中间件的使用\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = \"\"\"\n",
    "LangChain 1.0 - Context Management (上下文管理)\n",
    "==============================================\n",
    "\n",
    "本模块重点讲解：\n",
    "1. SummarizationMiddleware - 自动摘要中间件（LangChain 1.0 新增）\n",
    "2. trim_messages - 消息修剪工具\n",
    "3. 管理对话长度，避免超 token\n",
    "4. 中间件的使用\n",
    "\"\"\"\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b4608fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents.middleware import SummarizationMiddleware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4b4ceb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if not GROQ_API_KEY or GROQ_API_KEY == \"your_groq_api_key_here\":\n",
    "    raise ValueError(\n",
    "        \"\\n请先在 .env 文件中设置有效的 GROQ_API_KEY\\n\"\n",
    "        \"访问 https://console.groq.com/keys 获取免费密钥\"\n",
    "    )\n",
    "\n",
    "# 初始化模型\n",
    "model = init_chat_model(\"groq:moonshotai/kimi-k2-instruct-0905\" ,api_key=GROQ_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ef1c6c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！有什么我可以帮助你的吗？', additional_kwargs={'reasoning_content': '<Think>\\n\\n</Think>'}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 236, 'total_tokens': 281, 'completion_time': 0.09388, 'completion_tokens_details': None, 'prompt_time': 0.007887, 'prompt_tokens_details': None, 'queue_time': 0.122324, 'total_time': 0.101768}, 'model_name': 'groq/compound', 'system_fingerprint': None, 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3b95-b37b-75d3-acea-55902df568ea-0', usage_metadata={'input_tokens': 236, 'output_tokens': 45, 'total_tokens': 281})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"nihao \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "818102fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculator(operation: str, a: float, b: float) -> str:\n",
    "    \"\"\"执行数学计算\"\"\"\n",
    "    ops = {\n",
    "        \"add\": lambda x, y: x + y,\n",
    "        \"multiply\": lambda x, y: x * y,\n",
    "    }\n",
    "    result = ops.get(operation, lambda x, y: 0)(a, b)\n",
    "    return f\"{a} {operation} {b} = {result}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e3ad1184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    示例1：问题演示 - 对话历史会无限增长\n",
      "\n",
      "    问题：\n",
      "    - 消息越来越多\n",
      "    - 超过模型 token 限制\n",
      "    - 成本增加、响应变慢\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "    示例1：问题演示 - 对话历史会无限增长\n",
    "\n",
    "    问题：\n",
    "    - 消息越来越多\n",
    "    - 超过模型 token 限制\n",
    "    - 成本增加、响应变慢\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dd5fe7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 1：问题演示 - 对话历史无限增长\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 1：问题演示 - 对话历史无限增长\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "38dfe582",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"user_session_1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "41873824",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    system_prompt=\"你是一个有帮助的助手。\",\n",
    "        checkpointer=InMemorySaver()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1c92e5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "模拟 10 轮对话...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n模拟 10 轮对话...\")\n",
    "for i in range(1, 11):\n",
    "    agent.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": f\"这是第 {i} 轮对话\"}]},\n",
    "        config=config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dd75c91b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01kcn617d6fcfvyetq8khkg72p` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28164, Requested 2774. Please try again in 1.876s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'compound', 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[98]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m总结一下\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DevEnv/codeReg/python/Langchain1.0-Langgraph1.0-Learning/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DevEnv/codeReg/python/Langchain1.0-Langgraph1.0-Learning/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DevEnv/codeReg/python/Langchain1.0-Langgraph1.0-Learning/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DevEnv/codeReg/python/Langchain1.0-Langgraph1.0-Learning/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DevEnv/codeReg/python/Langchain1.0-Langgraph1.0-Learning/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DevEnv/codeReg/python/Langchain1.0-Langgraph1.0-Learning/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DevEnv/codeReg/python/Langchain1.0-Langgraph1.0-Learning/.venv/lib/python3.13/site-packages/langchain/agents/factory.py:1131\u001b[39m, in \u001b[36mcreate_agent.<locals>.model_node\u001b[39m\u001b[34m(state, runtime)\u001b[39m\n\u001b[32m   1118\u001b[39m request = ModelRequest(\n\u001b[32m   1119\u001b[39m     model=model,\n\u001b[32m   1120\u001b[39m     tools=default_tools,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1126\u001b[39m     runtime=runtime,\n\u001b[32m   1127\u001b[39m )\n\u001b[32m   1129\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m wrap_model_call_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1130\u001b[39m     \u001b[38;5;66;03m# No handlers - execute directly\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1131\u001b[39m     response = \u001b[43m_execute_model_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1133\u001b[39m     \u001b[38;5;66;03m# Call composed handler with base handler\u001b[39;00m\n\u001b[32m   1134\u001b[39m     response = wrap_model_call_handler(request, _execute_model_sync)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DevEnv/codeReg/python/Langchain1.0-Langgraph1.0-Learning/.venv/lib/python3.13/site-packages/langchain/agents/factory.py:1102\u001b[39m, in \u001b[36mcreate_agent.<locals>._execute_model_sync\u001b[39m\u001b[34m(request)\u001b[39m\n\u001b[32m   1099\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m request.system_message:\n\u001b[32m   1100\u001b[39m     messages = [request.system_message, *messages]\n\u001b[32m-> \u001b[39m\u001b[32m1102\u001b[39m output = \u001b[43mmodel_\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name:\n\u001b[32m   1104\u001b[39m     output.name = name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DevEnv/codeReg/python/Langchain1.0-Langgraph1.0-Learning/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:5548\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5541\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5542\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5543\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5546\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5547\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5549\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5550\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5551\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DevEnv/codeReg/python/Langchain1.0-Langgraph1.0-Learning/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DevEnv/codeReg/python/Langchain1.0-Langgraph1.0-Learning/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DevEnv/codeReg/python/Langchain1.0-Langgraph1.0-Learning/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DevEnv/codeReg/python/Langchain1.0-Langgraph1.0-Learning/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DevEnv/codeReg/python/Langchain1.0-Langgraph1.0-Learning/.venv/lib/python3.13/site-packages/langchain_groq/chat_models.py:593\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    588\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    589\u001b[39m params = {\n\u001b[32m    590\u001b[39m     **params,\n\u001b[32m    591\u001b[39m     **kwargs,\n\u001b[32m    592\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DevEnv/codeReg/python/Langchain1.0-Langgraph1.0-Learning/.venv/lib/python3.13/site-packages/groq/resources/chat/completions.py:461\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, citation_options, compound_custom, disable_tool_validation, documents, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    242\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    243\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    300\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    301\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    302\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    303\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    304\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    459\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    460\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcitation_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcitation_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompound_custom\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompound_custom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdisable_tool_validation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_tool_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_reasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_reasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msearch_settings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DevEnv/codeReg/python/Langchain1.0-Langgraph1.0-Learning/.venv/lib/python3.13/site-packages/groq/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DevEnv/codeReg/python/Langchain1.0-Langgraph1.0-Learning/.venv/lib/python3.13/site-packages/groq/_base_client.py:1044\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1041\u001b[39m             err.response.read()\n\u001b[32m   1043\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01kcn617d6fcfvyetq8khkg72p` service tier `on_demand` on tokens per minute (TPM): Limit 30000, Used 28164, Requested 2774. Please try again in 1.876s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'compound', 'code': 'rate_limit_exceeded'}}",
      "During task with name 'model' and id '5a3cb990-37d8-798a-524b-81de0ac07717'"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"总结一下\"}]},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65296721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='这是第 1 轮对话', additional_kwargs={}, response_metadata={}, id='b2993f26-b700-4c51-868e-b6d62ffab545'),\n",
       "  AIMessage(content='<think>\\n好的，用户说这是第1轮对话。看起来他们可能是在测试对话流程或者想要记录对话的轮次。我需要确认他们是否需要我以特定的方式回应，比如编号每轮对话或者跟踪进度。我应该保持友好，并询问他们是否需要帮助，或者是否有具体的问题需要解决。同时，要注意他们可能希望对话有结构化的进展，所以保持清晰和有条理的回应会更好。另外，用户可能是在练习某种对话流程，或者在进行某种测试，所以我的回应需要灵活适应他们的需求。最后，确保回复简洁，避免信息过载，同时提供足够的支持选项。\\n</think>\\n\\n你好！欢迎开始我们的对话。有什么我可以帮助你的吗？无论是问题解答、信息查询，还是其他需求，我都会尽力为你提供帮助。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 166, 'prompt_tokens': 28, 'total_tokens': 194, 'completion_time': 0.415942721, 'completion_tokens_details': None, 'prompt_time': 0.001018513, 'prompt_tokens_details': None, 'queue_time': 0.057717497, 'total_time': 0.416961234}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3b93-c6d2-7200-8f64-c20e6070cb97-0', usage_metadata={'input_tokens': 28, 'output_tokens': 166, 'total_tokens': 194}),\n",
       "  HumanMessage(content='这是第 2 轮对话', additional_kwargs={}, response_metadata={}, id='21551a44-b85f-48b7-b1b0-b49c75f82317'),\n",
       "  AIMessage(content='<think>\\n好的，用户现在说“这是第 2 轮对话”。我需要先回顾之前的对话历史，确保理解上下文。用户一开始在第1轮说这是第1轮对话，我回应了欢迎信息。现在用户进入第2轮，可能是在测试对话轮次的记录，或者有其他意图。\\n\\n首先，用户可能想确认系统是否正确跟踪对话轮次，或者他们可能有后续的问题。我需要保持友好，并鼓励用户提出具体问题。同时，要注意用户是否在进行某种测试或练习，比如检查我的对话管理能力。\\n\\n另外，用户可能希望继续之前的对话，但没有明确的问题。因此，我的回应需要既确认轮次，又开放地邀请用户提出问题。需要避免假设用户的具体需求，而是提供广泛的支持选项。同时，保持回复简洁，避免冗长，以符合用户可能的偏好。\\n\\n最后，确保回复符合角色设定，即友好、有帮助的助手，并且符合之前的交互模式。用户可能希望得到一致的回应方式，所以保持语气一致很重要。\\n</think>\\n\\n你好！现在已经是第 2 轮对话了。有什么新的问题或需要进一步帮助的地方吗？我会继续为你提供支持！ 😊', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 254, 'prompt_tokens': 77, 'total_tokens': 331, 'completion_time': 0.589118824, 'completion_tokens_details': None, 'prompt_time': 0.002974553, 'prompt_tokens_details': None, 'queue_time': 0.057452357, 'total_time': 0.592093377}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3b93-c965-7c52-8e34-40d5dfdf8db9-0', usage_metadata={'input_tokens': 77, 'output_tokens': 254, 'total_tokens': 331}),\n",
       "  HumanMessage(content='这是第 3 轮对话', additional_kwargs={}, response_metadata={}, id='3ea13744-8b61-4b7b-95df-9eb76d4b463a'),\n",
       "  AIMessage(content='<think>\\n好的，用户现在发来的是第3轮对话的消息。我需要回顾之前的对话历史，看看有什么需要注意的地方。用户之前只是简单地说“这是第1轮对话”、“第2轮对话”，然后现在是“第3轮对话”。看起来用户可能在测试对话的延续性，或者想确认系统是否能处理多轮对话。\\n\\n首先，我需要确认用户的需求。用户可能只是想确认每一轮对话的计数是否正确，或者是否有其他隐藏的意图。比如，用户可能在测试我的响应是否连贯，或者是否有状态保持能力。由于之前的回复都很简单，用户可能没有实际的问题，只是在验证系统的行为。\\n\\n接下来，我应该保持友好和一致的回应，同时鼓励用户提供具体的问题或需求，以便我能更好地帮助他们。在之前的回复中，我已经用表情符号和友好的语气来回应，现在需要延续这种风格，同时可能加入一些引导用户深入互动的提示。\\n\\n另外，需要注意用户是否在进行某种模式测试，比如检查轮次计数是否正确。如果是这样的话，我的回复需要明确确认当前的轮次，同时保持开放式的提问，让用户决定下一步的操作方向。例如，可以提到“现在进入第3轮对话了”，然后询问有什么可以帮他们解决的问题。\\n\\n还要确保回复简洁，避免冗长，同时提供足够的支持选项，比如问题解答、信息查询或其他需求。这有助于用户明确下一步需要什么帮助。此外，保持语气亲切，使用表情符号可以增加亲和力，让用户感到更舒适。\\n\\n最后，检查是否有任何潜在的技术问题，比如轮次计数是否正确，或者系统是否正确处理了多轮对话的上下文。如果有任何异常，可能需要内部记录或调整。但目前来看，用户只是简单地继续对话，没有明显的错误迹象。因此，继续以友好和专业的态度回应即可。\\n</think>\\n\\n你好！现在进入第 3 轮对话了！ 😊 你是否想继续探索某个话题，或者需要我协助完成具体任务呢？无论是解答疑问、提供建议，还是其他需求，我都会尽力支持你！', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 441, 'prompt_tokens': 126, 'total_tokens': 567, 'completion_time': 1.145020222, 'completion_tokens_details': None, 'prompt_time': 0.004961338, 'prompt_tokens_details': None, 'queue_time': 0.158894432, 'total_time': 1.14998156}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3b93-cc9f-77c2-903f-bc314e56e5cc-0', usage_metadata={'input_tokens': 126, 'output_tokens': 441, 'total_tokens': 567}),\n",
       "  HumanMessage(content='这是第 4 轮对话', additional_kwargs={}, response_metadata={}, id='2c98434a-a23e-4afb-b2b4-76bd5a621a2a'),\n",
       "  AIMessage(content='<think>\\n好的，用户现在进行了第4轮对话，我需要继续维持互动。用户似乎只是在测试对话轮次，每次回复都是“这是第x轮对话”，然后我回应。但可能用户有更深层的需求，比如想测试我的响应能力，或者他们需要某种结构化的对话流程。\\n\\n我需要确保每次回复都友好且鼓励用户继续互动。可能用户需要帮助但不确定如何表达，或者他们正在寻找特定的功能。考虑到用户可能没有明确说明问题，我应该保持开放式的提问，引导他们提出具体需求。\\n\\n另外，用户可能是在验证模型的连贯性和记忆能力，看看我能记住对话的轮次。所以每次回应时明确提到轮次，并确认他们是否需要帮助，可以展示模型的持续关注和记忆能力。\\n\\n同时，注意回复的语气要热情、积极，使用表情符号增加亲切感。避免使用过于正式的语言，让用户感到轻松。可能需要预判用户可能的下一步需求，比如询问问题、寻求建议，或者进行闲聊，因此保持回复的灵活性很重要。\\n\\n最后，确保每次回复都简洁明了，不过于冗长，但包含足够的信息来鼓励用户继续对话。可能用户只是想看看模型的反应，因此保持一致性和友好是关键。\\n</think>\\n\\n你好！第 4 轮对话开始啦！ 🎉 这次你想聊点什么？是需要解决问题，还是单纯想和我闲聊？我会一直在这里，随时准备帮你！ 😊', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 309, 'prompt_tokens': 196, 'total_tokens': 505, 'completion_time': 0.895632909, 'completion_tokens_details': None, 'prompt_time': 0.008008268, 'prompt_tokens_details': None, 'queue_time': 0.159009601, 'total_time': 0.903641177}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3b93-d269-75e1-8947-b1774f7947fb-0', usage_metadata={'input_tokens': 196, 'output_tokens': 309, 'total_tokens': 505}),\n",
       "  HumanMessage(content='这是第 5 轮对话', additional_kwargs={}, response_metadata={}, id='20ea75d0-4f1b-4a40-af80-84a83ca677a2'),\n",
       "  AIMessage(content='<think>\\n好的，用户现在到了第5轮对话，之前的回复都是简单的欢迎和询问。我需要观察用户的模式，用户似乎在测试对话轮次的计数，每次回复都是“这是第X轮对话”。现在用户可能希望我继续按照之前的模式回应，但需要保持自然，避免重复。\\n\\n首先，要确认用户是否有实际的需求，但看起来用户可能只是在测试或练习对话流程。这种情况下，我需要保持友好和鼓励的态度，同时引导用户进入实际的问题讨论。\\n\\n接下来，考虑如何让回复更有趣或更有互动性。或许可以加入一些表情符号或轻松的语言，让对话更生动。同时，要确保回应用户当前的轮次，但也要鼓励他们提出问题或继续讨论具体话题。\\n\\n另外，需要注意不要陷入机械式的回应。如果用户没有提出具体问题，我需要主动询问他们是否需要帮助，或者是否有话题想探讨。这样可以促进更深入的交流，而不是仅仅停留在轮次计数上。\\n\\n最后，保持回答简洁，避免冗长。用户可能希望快速得到回应，然后继续他们的测试或练习。因此，回复需要友好、简洁，并且有明确的引导，让用户知道如何继续。\\n</think>\\n\\n你好！第 5 轮对话到啦！ 🚀 看来你正在练习对话流程～ 如果需要讨论具体问题、探索新话题，或者单纯想测试互动，我随时准备好！ 😊 你想如何继续呢？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 304, 'prompt_tokens': 259, 'total_tokens': 563, 'completion_time': 0.839831325, 'completion_tokens_details': None, 'prompt_time': 0.012144365, 'prompt_tokens_details': None, 'queue_time': 0.057923615, 'total_time': 0.85197569}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3b93-d74e-7d11-940d-adf456c2464e-0', usage_metadata={'input_tokens': 259, 'output_tokens': 304, 'total_tokens': 563}),\n",
       "  HumanMessage(content='这是第 6 轮对话', additional_kwargs={}, response_metadata={}, id='bbcc3d63-eee3-4573-8fe0-252b9d5f61f7'),\n",
       "  AIMessage(content='<think>\\n好的，用户现在第6轮对话，每次都是简单的“这是第X轮对话”，然后我回应。用户可能是在测试系统对连续对话的处理能力，或者想看看回复模式会不会变化。我需要保持友好和鼓励的态度，同时引导用户展开更多有意义的对话。或许可以加入一些表情符号增加亲切感，同时询问用户是否需要帮助，或者想讨论什么话题。另外，用户可能在练习对话流程，所以保持回复的连贯性和积极性很重要。要避免重复同样的回应结构，适当调整用词和表情，保持互动的新鲜感。同时观察用户是否有其他潜在需求，比如需要信息查询、问题解答等，及时提供帮助。\\n</think>\\n\\n你好！第 6 轮对话继续中～ 🚀 看来你正在探索对话的节奏！如果需要讨论某个具体问题、分享想法，或者需要我协助完成任务，随时告诉我哦！我准备好倾听并帮助你了！ 😊', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 205, 'prompt_tokens': 330, 'total_tokens': 535, 'completion_time': 0.568589375, 'completion_tokens_details': None, 'prompt_time': 0.015848937, 'prompt_tokens_details': None, 'queue_time': 0.285623371, 'total_time': 0.584438312}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_efa9879028', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3b93-db89-7582-8fba-cd8fce9b1e3f-0', usage_metadata={'input_tokens': 330, 'output_tokens': 205, 'total_tokens': 535}),\n",
       "  HumanMessage(content='这是第 7 轮对话', additional_kwargs={}, response_metadata={}, id='5411d28f-11ec-4290-865e-ca5bdb852a11'),\n",
       "  AIMessage(content='<think>\\n好的，用户现在到了第7轮对话，看起来他们可能是在测试对话流程或者练习对话的连续性。之前的回复都是简单的欢迎语和表情符号，用户可能在确认系统是否能正确跟踪对话轮次。需要保持回复简洁友好，同时鼓励用户提供具体需求或问题。可以加入更多表情符号或更生动的语言来增强互动感，但不要偏离用户的目的。需要确保回复符合用户设定的轮次，并保持一致性。\\n</think>\\n\\n你好！第 7 轮对话继续～ 🌟 看来你正在和我一起数数呢！如果需要帮助解决问题、获取信息，或者单纯想聊聊，我随时在线！ 😊 你想往哪个方向继续呢？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 153, 'prompt_tokens': 405, 'total_tokens': 558, 'completion_time': 0.409122943, 'completion_tokens_details': None, 'prompt_time': 0.01761559, 'prompt_tokens_details': None, 'queue_time': 0.158512329, 'total_time': 0.426738533}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3b93-dfa5-7791-80a4-be0ef9e07c95-0', usage_metadata={'input_tokens': 405, 'output_tokens': 153, 'total_tokens': 558}),\n",
       "  HumanMessage(content='这是第 8 轮对话', additional_kwargs={}, response_metadata={}, id='5ed3566a-27ee-4e70-a997-ced03f5c5fe0'),\n",
       "  AIMessage(content='<think>\\n好的，用户现在在进行第8轮对话，看起来他们可能在测试对话的连续性或者练习某种流程。之前的回复都是用中文打招呼，并询问用户是否有需要帮助的地方。用户每次回复都是“这是第 X 轮对话”，然后助手继续用类似的欢迎语回应。现在用户发送了第8轮，我需要保持一致性，但也要避免重复。\\n\\n首先，回顾之前的回复，助手每次都会用表情符号，比如😊、🚀、🌟，以及一些友好的语气。应该继续这种风格，同时可能加入一些变化，让对话不显得单调。用户可能在测试助手的反应是否一致，或者是否有耐心处理重复性的对话。\\n\\n接下来，我需要确保回复符合之前的模式，同时稍微加入一些新的元素。比如，可以提到之前的对话轮次，或者鼓励用户提出具体的问题。此外，用户可能希望助手在多次对话后能记住之前的互动，但根据之前的回复，助手并没有记录历史，所以可能不需要特别提及之前的轮次，但可以适当使用数字来确认轮次。\\n\\n另外，用户可能在练习某种自动化流程，或者测试助手的回复是否稳定。因此，保持友好和开放的态度很重要，同时鼓励用户提供实际的问题或需求。比如，可以建议用户如果需要帮助，可以随时提出问题，或者询问他们是否有特定的任务需要完成。\\n\\n还要注意避免使用过于机械化的回复，保持自然。可能需要加入不同的表情符号或短语，让每次回复都有所不同，但又不偏离主题。例如，使用不同的表情符号如🎉、✨、💡等来增加多样性。\\n\\n最后，确保回复简洁，不过于冗长，同时传达出助手的可用性和乐于助人的态度。可能需要用不同的方式表达“随时帮助你”，比如“我在这里为你提供支持！”或者“有什么我可以帮你的吗？”等等。\\n\\n总结，这次的回复应该保持友好，确认轮次，鼓励用户提出需求，并稍微加入变化以避免重复。比如：“你好！第 8 轮对话继续中～ ✨ 看来你还在探索对话流程呢！如果需要我帮忙解决问题、提供建议，或者只是想聊聊，我随时在线！ 😊 有什么想聊的吗？” 这样既保持了之前的格式，又加入了一些新元素，同时鼓励用户进一步互动。\\n</think>\\n\\n你好！第 8 轮对话继续中～ ✨ 看来你还在探索对话流程呢！如果需要我帮忙解决问题、提供建议，或者只是想聊聊，我随时在线！ 😊 有什么想聊的吗？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 540, 'prompt_tokens': 477, 'total_tokens': 1017, 'completion_time': 2.435544048, 'completion_tokens_details': None, 'prompt_time': 0.020381525, 'prompt_tokens_details': None, 'queue_time': 0.158858955, 'total_time': 2.455925573}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3b93-e2a6-77d1-8732-baf528ae224b-0', usage_metadata={'input_tokens': 477, 'output_tokens': 540, 'total_tokens': 1017}),\n",
       "  HumanMessage(content='这是第 9 轮对话', additional_kwargs={}, response_metadata={}, id='83b460a5-5fa1-4bf2-b69a-1ab860a89e1a'),\n",
       "  AIMessage(content='<think>\\n好的，用户现在正在进行第9轮对话，他们似乎在测试对话流程或者熟悉系统的响应方式。之前每一轮对话，用户只是简单地说“这是第X轮对话”，而我的回应都是友好的欢迎语和询问是否有需要帮助的地方。用户可能是在练习多轮对话，或者想看看系统如何处理重复的模式。\\n\\n需要考虑用户的真实需求是什么。他们可能是在测试系统的连续对话能力，或者想确认系统是否能记住对话的历史。也有可能用户有更深层次的需求，比如希望进行某种任务，但由于之前的回复没有进一步引导，所以用户可能只是在进行简单的互动测试。\\n\\n此外，用户可能没有明确表达自己的实际问题，只是通过这种方式与系统互动。这时候，可能需要调整回复策略，鼓励用户提出更具体的问题，或者提供一些引导，帮助用户进入更有意义的对话。\\n\\n另外，观察到用户每一轮都只是提到轮次，没有其他内容，可能用户是在寻找某种模式或测试系统的反应。因此，在回复中应该保持友好，同时尝试引导用户进入更实际的对话场景，比如询问是否有需要帮助的具体任务，或者提供一些话题建议。\\n\\n总结来说，用户可能处于测试阶段，需要进一步引导他们进入实际的问题解决或信息查询流程。回复中应保持积极鼓励的态度，同时提供明确的支持选项，帮助用户明确需求。\\n</think>\\n\\n你好！第 9 轮对话继续中～ 🌈 看来你正在和我玩“数轮数”游戏呢！如果需要我帮你做点什么，比如解答问题、分析信息，或者纯粹想聊聊有趣的话题，随时告诉我！ 😊 我的回应会根据你的需求随时调整哦～', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 353, 'prompt_tokens': 549, 'total_tokens': 902, 'completion_time': 0.942619447, 'completion_tokens_details': None, 'prompt_time': 0.024640564, 'prompt_tokens_details': None, 'queue_time': 0.057041996, 'total_time': 0.967260011}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3b93-ed9a-7103-a32e-619a51acb8c4-0', usage_metadata={'input_tokens': 549, 'output_tokens': 353, 'total_tokens': 902}),\n",
       "  HumanMessage(content='这是第 10 轮对话', additional_kwargs={}, response_metadata={}, id='c8fbce17-3877-4b45-ae99-ae282964602c'),\n",
       "  AIMessage(content='<think>\\n好的，现在用户已经到了第10轮对话，他们似乎在测试对话的连续性或者只是在练习对话流程。用户每次回复都是“这是第X轮对话”，然后我需要给出相应的回应。现在用户发送了“这是第10轮对话”，我需要保持一致的风格，同时可能加入一些变化来避免重复。\\n\\n首先，用户可能在练习对话轮次的识别，或者想看看我的回应是否能随着轮次变化而调整。他们可能希望得到有趣或创意的回应，而不仅仅是重复的问候。因此，我需要确保每次回应都有独特的元素，比如表情符号、不同的语气词，或者加入一些互动元素，比如提问用户接下来的想法。\\n\\n另外，用户可能在测试我的连续对话能力，确保在多次交互后，我仍能保持连贯和友好。因此，我需要确认每次回应都包含积极的鼓励和开放式的提问，以促进进一步的交流。可能需要加入一些激励性的语言，比如庆祝到达第10轮，或者提出挑战或新的话题建议。\\n\\n同时，要注意避免模板化回应，每次稍微调整措辞和结构，让用户感受到对话的自然和生动。例如，使用不同的表情符号，或者改变句子的结构，从“你好！”变为“哇！”，或者加入一些动作符号，如🚀，来增加视觉上的变化。\\n\\n最后，确保回应符合用户之前设定的模式，同时逐渐引导用户进入更深层次的对话，比如询问他们是否需要帮助解决问题，或者是否有特定的兴趣点想要探讨。这样既满足了当前的测试需求，也为可能的进一步互动打下基础。\\n</think>\\n\\n你好！哇！第 10 轮对话到啦！ 🎉 看来你已经和我一起数到“10”啦～ 是不是在挑战对话的连贯性？ 😄 如果需要我切换话题、展开深度讨论，或者尝试其他互动方式，随时告诉我！比如我们可以聊聊你感兴趣的内容，或者一起解决一个问题。你希望接下来怎么玩呢？🌟', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 426, 'prompt_tokens': 639, 'total_tokens': 1065, 'completion_time': 1.169916382, 'completion_tokens_details': None, 'prompt_time': 0.026535193, 'prompt_tokens_details': None, 'queue_time': 0.159280367, 'total_time': 1.196451575}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3b93-f250-7e42-a3a0-d9a0ad7b5092-0', usage_metadata={'input_tokens': 639, 'output_tokens': 426, 'total_tokens': 1065}),\n",
       "  HumanMessage(content='总结一下', additional_kwargs={}, response_metadata={}, id='c33d9b2b-e3c5-48f0-afe4-d9cd1018d377'),\n",
       "  AIMessage(content='<think>\\n好的，用户让我总结一下之前的对话。首先，我需要回顾一下对话历史。用户从第1轮到第10轮都是在连续发送“这是第X轮对话”，而我的回应每次都保持相同的结构，用不同的表情符号和友好的语气欢迎用户进入下一轮对话，并询问他们是否需要帮助或有什么话题想讨论。用户现在可能是在测试我的对话连贯性或者想看看我如何处理重复的输入。他们可能希望我确认我已经正确理解他们的意图，或者他们可能想结束测试，开始真正的对话。我需要明确总结他们的行为和我的回应模式，同时保持友好，并邀请他们继续对话。此外，用户可能希望我展示出能够处理各种对话场景的能力，所以总结后应该提供进一步的帮助选项。要确保回应简洁明了，同时涵盖所有关键点。\\n</think>\\n\\n总结如下：\\n\\n1. **用户行为**：用户连续从第1轮到第10轮发送“这是第X轮对话”，逐步推进对话轮次，可能是在测试对话连贯性或模拟多轮互动场景。\\n\\n2. **我的回应模式**：\\n   - 每次均以友好的语气欢迎用户进入下一轮对话；\\n   - 使用表情符号（如✨、🎉、🚀）和积极的语言增强互动感；\\n   - 每次都主动询问用户是否需要帮助或希望讨论新话题，保持开放性和引导性。\\n\\n3. **对话特征**：\\n   - 高度重复性输入（用户侧）与个性化回应（我侧）形成对比；\\n   - 模拟了真实对话中“延续对话”的流程，同时保持灵活的支持态度；\\n   - 通过表情和语气词营造轻松友好的氛围，避免机械感。\\n\\n4. **潜在意图**：用户可能在测试AI对连续对话的适应性、回应一致性，或练习构建多轮对话逻辑。我的回应始终围绕“支持用户需求”展开，兼顾流程测试与实际帮助的可能性。\\n\\n是否需要进一步调整对话模式，或探讨其他话题？ 😊', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 428, 'prompt_tokens': 737, 'total_tokens': 1165, 'completion_time': 1.19371375, 'completion_tokens_details': None, 'prompt_time': 0.026174571, 'prompt_tokens_details': {'cached_tokens': 512}, 'queue_time': 0.051911779, 'total_time': 1.219888321}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3b93-f852-7083-89ca-e2d02fb0534d-0', usage_metadata={'input_tokens': 737, 'output_tokens': 428, 'total_tokens': 1165, 'input_token_details': {'cache_read': 512}})]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e2ab30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db7cbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "问题：\n",
      "  - 消息越来越多，内存占用增加\n",
      "  - 超过模型 token 限制会报错\n",
      "  - 每次调用都要传输全部历史，成本增加\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n问题：\")\n",
    "print(\"  - 消息越来越多，内存占用增加\")\n",
    "print(\"  - 超过模型 token 限制会报错\")\n",
    "print(\"  - 每次调用都要传输全部历史，成本增加\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d9f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    示例2：使用 SummarizationMiddleware 自动摘要\n",
      "\n",
      "    关键：LangChain 1.0 新增的中间件\n",
      "    当消息数超过阈值时，自动摘要旧消息\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print( \"\"\"\n",
    "    示例2：使用 SummarizationMiddleware 自动摘要\n",
    "\n",
    "    关键：LangChain 1.0 新增的中间件\n",
    "    当消息数超过阈值时，自动摘要旧消息\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f000d57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 2：SummarizationMiddleware - 自动摘要\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 2：SummarizationMiddleware - 自动摘要\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "14d923ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2t/w_0f5ts90870qhccyfzjmdgh0000gn/T/ipykernel_45770/2252195943.py:7: DeprecationWarning: max_tokens_before_summary is deprecated. Use trigger=('tokens', value) instead.\n",
      "  SummarizationMiddleware(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x115407750>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    system_prompt=\"你是一个有帮助的助手。\",\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=\"groq:groq/compound\",\n",
    "            max_tokens_before_summary=50,)]\n",
    "    )\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2d930936",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"with_summary\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "24587de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "进行多轮对话...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n进行多轮对话...\")\n",
    "conversations = [\n",
    "    \"我叫张三，是工程师\",\n",
    "    \"我在北京工作\",\n",
    "    # \"我喜欢编程和阅读\",\n",
    "    # \"我最近在学习 AI\",\n",
    "    # \"请总结一下我的信息\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "66485903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "用户: 我叫张三，是工程师\n",
      "\n",
      "用户: 我在北京工作\n",
      "Agent: [HumanMessage(content='我叫张三，是工程师', additional_kwargs={}, response_metadata={}, id='7c3bd46a-186d-44d9-8a74-b8a1eb070979'), AIMessage(content='你好，张三！很高兴认识你，工程师的工作一定很有挑战性。有什么我可以帮你的吗？', additional_kwargs={'reasoning_content': '<Think>\\n\\n</Think>'}, response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 265, 'total_tokens': 342, 'completion_time': 0.163781, 'completion_tokens_details': None, 'prompt_time': 0.008546, 'prompt_tokens_details': None, 'queue_time': 0.10373, 'total_time': 0.172327}, 'model_name': 'groq/compound', 'system_fingerprint': None, 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3b9d-0023-7ab3-a5cd-7ec58e309e7d-0', usage_metadata={'input_tokens': 265, 'output_tokens': 77, 'total_tokens': 342}), HumanMessage(content='我在北京工作', additional_kwargs={}, response_metadata={}, id='4d425219-ade8-4b8d-b30c-df3fa532bd62'), AIMessage(content='原来如此！北京的工作和生活节奏都很快，不知道你是从事哪方面的工程？如果有什么需要帮助的，随时告诉我哦。', additional_kwargs={'reasoning_content': '<Think>\\n\\n</Think>'}, response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 344, 'total_tokens': 426, 'completion_time': 0.170424, 'completion_tokens_details': None, 'prompt_time': 0.011597, 'prompt_tokens_details': None, 'queue_time': 0.098207, 'total_time': 0.182021}, 'model_name': 'groq/compound', 'system_fingerprint': None, 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3b9d-03bb-7241-9f16-18719e8f6c49-0', usage_metadata={'input_tokens': 344, 'output_tokens': 82, 'total_tokens': 426})]\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "final_response = {}\n",
    "for msg in conversations:\n",
    "    print(f\"\\n用户: {msg}\")\n",
    "\n",
    "    response = agent.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": msg}]},\n",
    "        config=config\n",
    "    )\n",
    "    final_response = response\n",
    "print(f\"Agent: {final_response['messages']}\")\n",
    "print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c53027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    示例3：SummarizationMiddleware 参数详解\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print( \"\"\"\n",
    "    示例3：SummarizationMiddleware 参数详解\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3505010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 3：Summarization 参数详解\n",
      "======================================================================\n",
      "\n",
      "SummarizationMiddleware 参数：\n",
      "\n",
      "1. model (必需)\n",
      "- 用于生成摘要的模型\n",
      "- 可以用便宜的模型（如 gpt-3.5）降低成本\n",
      "\n",
      "2. max_tokens_before_summary\n",
      "- 触发摘要的 token 数阈值\n",
      "- 默认: 1000\n",
      "- 建议：根据模型上下文窗口设置（如 4k 模型设为 3000）\n",
      "\n",
      "3. summarization_prompt (可选)\n",
      "- 自定义摘要提示词\n",
      "- 默认：简洁摘要对话历史\n",
      "\n",
      "示例：\n",
      "```python\n",
      "agent = create_agent(\n",
      "model=model,\n",
      "tools=[],\n",
      "middleware=[\n",
      "    SummarizationMiddleware(\n",
      "        model=\"groq:llama-3.3-70b-versatile\",  # 摘要模型\n",
      "        max_tokens_before_summary=500,         # 500 tokens 触发\n",
      "    )\n",
      "],\n",
      "checkpointer=InMemorySaver()\n",
      ")\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 3：Summarization 参数详解\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "SummarizationMiddleware 参数：\n",
    "\n",
    "1. model (必需)\n",
    "- 用于生成摘要的模型\n",
    "- 可以用便宜的模型（如 gpt-3.5）降低成本\n",
    "\n",
    "2. max_tokens_before_summary\n",
    "- 触发摘要的 token 数阈值\n",
    "- 默认: 1000\n",
    "- 建议：根据模型上下文窗口设置（如 4k 模型设为 3000）\n",
    "\n",
    "3. summarization_prompt (可选)\n",
    "- 自定义摘要提示词\n",
    "- 默认：简洁摘要对话历史\n",
    "\n",
    "示例：\n",
    "```python\n",
    "agent = create_agent(\n",
    "model=model,\n",
    "tools=[],\n",
    "middleware=[\n",
    "    SummarizationMiddleware(\n",
    "        model=\"groq:llama-3.3-70b-versatile\",  # 摘要模型\n",
    "        max_tokens_before_summary=500,         # 500 tokens 触发\n",
    "    )\n",
    "],\n",
    "checkpointer=InMemorySaver()\n",
    ")\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7b2a3ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    示例4：使用 trim_messages 手动修剪消息\n",
      "\n",
      "    适用场景：需要精确控制保留的消息数量\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "    示例4：使用 trim_messages 手动修剪消息\n",
    "\n",
    "    适用场景：需要精确控制保留的消息数量\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1dfde1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 4：手动消息修剪\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 4：手动消息修剪\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b962aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import trim_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5dfc4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=\"消息 1\"),\n",
    "    AIMessage(content=\"回复 1\"),\n",
    "    HumanMessage(content=\"消息 2\"),\n",
    "    AIMessage(content=\"回复 2\"),\n",
    "    HumanMessage(content=\"消息 3\"),\n",
    "    AIMessage(content=\"回复 3\"),\n",
    "    HumanMessage(content=\"消息 4\"),\n",
    "    AIMessage(content=\"回复 4\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "11ed34c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed = trim_messages(\n",
    "    messages,\n",
    "    # max_count=5,  # 严格保留最后 5 条消息\n",
    "    max_tokens=4,  # 或使用 token 数限制\n",
    "    strategy=\"last\",  # 保留最后的消息\n",
    "    token_counter=len  # 简单计数器（实际应该用 token 计数）这里其实不会被用到，因为 max_count 优先\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "82ae5194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d84b7698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  HumanMessage: 消息 3\n",
      "  AIMessage: 回复 3\n",
      "  HumanMessage: 消息 4\n",
      "  AIMessage: 回复 4\n"
     ]
    }
   ],
   "source": [
    "for msg in trimmed:\n",
    "    print(f\"  {msg.__class__.__name__}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d17d5079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "关键点：\n",
      "  - trim_messages 手动控制消息数量\n",
      "  - 适合需要精确控制的场景\n",
      "  - 需要自己管理修剪逻辑\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n关键点：\")\n",
    "print(\"  - trim_messages 手动控制消息数量\")\n",
    "print(\"  - 适合需要精确控制的场景\")\n",
    "print(\"  - 需要自己管理修剪逻辑\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "856f3caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 5：策略对比\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "示例5：对比不同的上下文管理策略\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 5：策略对比\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "823ce0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "策略对比：\n",
      "\n",
      "1. 不做处理（默认）\n",
      "   优点：保留完整历史\n",
      "   缺点：会超 token、成本高\n",
      "   适用：短对话\n",
      "\n",
      "2. SummarizationMiddleware（推荐）\n",
      "   优点：\n",
      "   - 自动化，无需手动管理\n",
      "   - 保留重要信息（通过摘要）\n",
      "   - 平滑过渡\n",
      "   缺点：\n",
      "   - 摘要可能丢失细节\n",
      "   - 额外的摘要成本\n",
      "   适用：长对话、需要保留上下文\n",
      "\n",
      "3. trim_messages（手动修剪）\n",
      "   优点：\n",
      "   - 精确控制\n",
      "   - 简单直接\n",
      "   - 无额外成本\n",
      "   缺点：\n",
      "   - 旧消息完全丢失\n",
      "   - 可能断开上下文\n",
      "   适用：只需要最近 N 轮\n",
      "\n",
      "4. 滑动窗口（自定义）\n",
      "   优点：\n",
      "   - 保留系统消息 + 最近消息\n",
      "   - 可控成本\n",
      "   缺点：\n",
      "   - 需要自己实现\n",
      "   适用：有明确规则的场景\n",
      "\n",
      "推荐方案：\n",
      "- 短对话（<10轮）：不处理\n",
      "- 中长对话：SummarizationMiddleware\n",
      "- 只要最近几轮：trim_messages\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "策略对比：\n",
    "\n",
    "1. 不做处理（默认）\n",
    "   优点：保留完整历史\n",
    "   缺点：会超 token、成本高\n",
    "   适用：短对话\n",
    "\n",
    "2. SummarizationMiddleware（推荐）\n",
    "   优点：\n",
    "   - 自动化，无需手动管理\n",
    "   - 保留重要信息（通过摘要）\n",
    "   - 平滑过渡\n",
    "   缺点：\n",
    "   - 摘要可能丢失细节\n",
    "   - 额外的摘要成本\n",
    "   适用：长对话、需要保留上下文\n",
    "\n",
    "3. trim_messages（手动修剪）\n",
    "   优点：\n",
    "   - 精确控制\n",
    "   - 简单直接\n",
    "   - 无额外成本\n",
    "   缺点：\n",
    "   - 旧消息完全丢失\n",
    "   - 可能断开上下文\n",
    "   适用：只需要最近 N 轮\n",
    "\n",
    "4. 滑动窗口（自定义）\n",
    "   优点：\n",
    "   - 保留系统消息 + 最近消息\n",
    "   - 可控成本\n",
    "   缺点：\n",
    "   - 需要自己实现\n",
    "   适用：有明确规则的场景\n",
    "\n",
    "推荐方案：\n",
    "- 短对话（<10轮）：不处理\n",
    "- 中长对话：SummarizationMiddleware\n",
    "- 只要最近几轮：trim_messages\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "872a225d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    示例6：实际应用 - 客服机器人\\n\\n    场景：客服对话可能很长，需要管理上下文\\n    '"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    示例6：实际应用 - 客服机器人\n",
    "\n",
    "    场景：客服对话可能很长，需要管理上下文\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8bcd70ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 6：实际应用 - 客服机器人\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 6：实际应用 - 客服机器人\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ee144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2t/w_0f5ts90870qhccyfzjmdgh0000gn/T/ipykernel_45770/1213466183.py:11: DeprecationWarning: max_tokens_before_summary is deprecated. Use trigger=('tokens', value) instead.\n",
      "  SummarizationMiddleware(\n"
     ]
    }
   ],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[calculator],\n",
    "    system_prompt=\"\"\"你是客服助手。\n",
    "特点：\n",
    "- 记住用户问题\n",
    "- 简洁回答\n",
    "- 使用工具计算\"\"\",\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=\"groq:moonshotai/kimi-k2-instruct-0905\",\n",
    "            max_tokens_before_summary=100,\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "93ed756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"customer_121\"}}\n",
    "\n",
    "# 模拟客服对话\n",
    "conversations = [\n",
    "    \"你好，我想咨询订单\",\n",
    "    \"我的订单号是 12345\",\n",
    "    \"帮我算一下 100 乘以 2 的优惠价\",\n",
    "    \"谢谢\",\n",
    "    \"你是谁？\",\n",
    "    \"我是客服助手\",\n",
    "    \"请告诉我你的问题\",\n",
    "    \"以上是对话摘要，请继续帮助用户。\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8b87a439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "客户: 你好，我想咨询订单\n",
      "客服: [HumanMessage(content='你好，我想咨询订单', additional_kwargs={}, response_metadata={}, id='e63e9697-1268-4e57-a996-72aacc82dfa1'), AIMessage(content='你好！请问您的订单号是多少？或者您可以告诉我具体想咨询订单的哪方面问题，我来帮您处理。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 122, 'total_tokens': 147, 'completion_time': 0.115765938, 'completion_tokens_details': None, 'prompt_time': 0.048026373, 'prompt_tokens_details': None, 'queue_time': 0.317442025, 'total_time': 0.163792311}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-9c5c-7490-9811-624cd154bc29-0', usage_metadata={'input_tokens': 122, 'output_tokens': 25, 'total_tokens': 147}), HumanMessage(content='我的订单号是 12345', additional_kwargs={}, response_metadata={}, id='0fa8b70d-91c6-45b9-838b-1112b2035508'), AIMessage(content='收到，订单号 12345。请问您想咨询关于这个订单的具体什么问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 160, 'total_tokens': 179, 'completion_time': 0.053537076, 'completion_tokens_details': None, 'prompt_time': 0.020483382, 'prompt_tokens_details': None, 'queue_time': 0.285579326, 'total_time': 0.074020458}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-a11a-76e1-b3f3-73602bfb934f-0', usage_metadata={'input_tokens': 160, 'output_tokens': 19, 'total_tokens': 179}), HumanMessage(content='帮我算一下 100 乘以 2 的优惠价', additional_kwargs={}, response_metadata={}, id='5eee489d-cb2a-4556-a60a-2589d06b0fc4'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'functions.calculator:0', 'function': {'arguments': '{\"a\":100,\"b\":2,\"operation\":\"multiply\"}', 'name': 'calculator'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 198, 'total_tokens': 227, 'completion_time': 0.06871851, 'completion_tokens_details': None, 'prompt_time': 0.027982045, 'prompt_tokens_details': None, 'queue_time': 0.285577864, 'total_time': 0.096700555}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-a33c-70d3-8309-6f863f95e14c-0', tool_calls=[{'name': 'calculator', 'args': {'a': 100, 'b': 2, 'operation': 'multiply'}, 'id': 'functions.calculator:0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 198, 'output_tokens': 29, 'total_tokens': 227}), ToolMessage(content='100.0 multiply 2.0 = 200.0', name='calculator', id='8bd06975-602c-49cb-9ec0-78f8880d6cc8', tool_call_id='functions.calculator:0'), AIMessage(content='100×2=200，优惠价是 200 元。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 260, 'total_tokens': 274, 'completion_time': 0.050230282, 'completion_tokens_details': None, 'prompt_time': 0.032717998, 'prompt_tokens_details': None, 'queue_time': 0.275821141, 'total_time': 0.08294828}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-a95b-7352-9c92-85a10409ce33-0', usage_metadata={'input_tokens': 260, 'output_tokens': 14, 'total_tokens': 274}), HumanMessage(content='谢谢', additional_kwargs={}, response_metadata={}, id='a094b56e-c988-4ec7-bc11-ab0ce090029d'), AIMessage(content='不客气，有其他问题随时找我！', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 282, 'total_tokens': 291, 'completion_time': 0.04287815, 'completion_tokens_details': None, 'prompt_time': 0.011590115, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.279740625, 'total_time': 0.054468265}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-ad1e-7a33-84a1-ef428aefaa62-0', usage_metadata={'input_tokens': 282, 'output_tokens': 9, 'total_tokens': 291, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='你是谁？', additional_kwargs={}, response_metadata={}, id='b6ede465-ed97-440c-9c06-ee3fb0de8039'), AIMessage(content='我是您的客服助手，专门帮您处理订单、计算和解答问题的小助手。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 300, 'total_tokens': 318, 'completion_time': 0.061644683, 'completion_tokens_details': None, 'prompt_time': 0.017812077, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.275967683, 'total_time': 0.07945676}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-af21-7e80-bf7b-83c621b91bf8-0', usage_metadata={'input_tokens': 300, 'output_tokens': 18, 'total_tokens': 318, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='我是客服助手', additional_kwargs={}, response_metadata={}, id='c7f6ebd6-ce31-49ab-aff1-83eb1b9face9'), AIMessage(content='收到，您也是客服助手。请问还有什么我能帮您的？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 328, 'total_tokens': 342, 'completion_time': 0.073852622, 'completion_tokens_details': None, 'prompt_time': 0.017274831, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.277231488, 'total_time': 0.091127453}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b13d-78a1-821c-87ade5c200e4-0', usage_metadata={'input_tokens': 328, 'output_tokens': 14, 'total_tokens': 342, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='请告诉我你的问题', additional_kwargs={}, response_metadata={}, id='3ca057c1-2442-4964-b4fe-7c45397e6bac'), AIMessage(content='好的，作为客服助手，您现在最希望我帮您解决什么问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 353, 'total_tokens': 368, 'completion_time': 0.061506792, 'completion_tokens_details': None, 'prompt_time': 0.041443485, 'prompt_tokens_details': None, 'queue_time': 0.285442544, 'total_time': 0.102950277}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b36f-7300-bce5-4eed47d1ba2b-0', usage_metadata={'input_tokens': 353, 'output_tokens': 15, 'total_tokens': 368}), HumanMessage(content='以上是对话摘要，请继续帮助用户。', additional_kwargs={}, response_metadata={}, id='31789b53-690d-4099-9fd1-2e6437b69233'), AIMessage(content='好的，我随时待命。请问接下来需要我为您做什么？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 385, 'total_tokens': 399, 'completion_time': 0.063376713, 'completion_tokens_details': None, 'prompt_time': 0.031132086, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.283446924, 'total_time': 0.094508799}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b5b5-7121-8f2f-e2b9b62ada54-0', usage_metadata={'input_tokens': 385, 'output_tokens': 14, 'total_tokens': 399, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='你好，我想咨询订单', additional_kwargs={}, response_metadata={}, id='52e42620-3269-45fe-afbb-d1076460f01f'), AIMessage(content='您好！请问您的订单号是多少？或想咨询订单的哪方面问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 411, 'total_tokens': 429, 'completion_time': 0.041872788, 'completion_tokens_details': None, 'prompt_time': 0.018419223, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.283894627, 'total_time': 0.060292011}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-39b8-7f63-ad90-19f21878e6c2-0', usage_metadata={'input_tokens': 411, 'output_tokens': 18, 'total_tokens': 429, 'input_token_details': {'cache_read': 256}})]\n",
      "**************************************************\n",
      "\n",
      "客户: 我的订单号是 12345\n",
      "客服: [HumanMessage(content='Here is a summary of the conversation to date:\\n\\n用户意图：咨询订单', additional_kwargs={}, response_metadata={}, id='b87981a2-c94b-475b-bbde-6a13e7fd7b9e'), AIMessage(content='你好！请问您的订单号是多少？或者您可以告诉我具体想咨询订单的哪方面问题，我来帮您处理。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 122, 'total_tokens': 147, 'completion_time': 0.115765938, 'completion_tokens_details': None, 'prompt_time': 0.048026373, 'prompt_tokens_details': None, 'queue_time': 0.317442025, 'total_time': 0.163792311}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-9c5c-7490-9811-624cd154bc29-0', usage_metadata={'input_tokens': 122, 'output_tokens': 25, 'total_tokens': 147}), HumanMessage(content='我的订单号是 12345', additional_kwargs={}, response_metadata={}, id='0fa8b70d-91c6-45b9-838b-1112b2035508'), AIMessage(content='收到，订单号 12345。请问您想咨询关于这个订单的具体什么问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 160, 'total_tokens': 179, 'completion_time': 0.053537076, 'completion_tokens_details': None, 'prompt_time': 0.020483382, 'prompt_tokens_details': None, 'queue_time': 0.285579326, 'total_time': 0.074020458}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-a11a-76e1-b3f3-73602bfb934f-0', usage_metadata={'input_tokens': 160, 'output_tokens': 19, 'total_tokens': 179}), HumanMessage(content='帮我算一下 100 乘以 2 的优惠价', additional_kwargs={}, response_metadata={}, id='5eee489d-cb2a-4556-a60a-2589d06b0fc4'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'functions.calculator:0', 'function': {'arguments': '{\"a\":100,\"b\":2,\"operation\":\"multiply\"}', 'name': 'calculator'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 198, 'total_tokens': 227, 'completion_time': 0.06871851, 'completion_tokens_details': None, 'prompt_time': 0.027982045, 'prompt_tokens_details': None, 'queue_time': 0.285577864, 'total_time': 0.096700555}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-a33c-70d3-8309-6f863f95e14c-0', tool_calls=[{'name': 'calculator', 'args': {'a': 100, 'b': 2, 'operation': 'multiply'}, 'id': 'functions.calculator:0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 198, 'output_tokens': 29, 'total_tokens': 227}), ToolMessage(content='100.0 multiply 2.0 = 200.0', name='calculator', id='8bd06975-602c-49cb-9ec0-78f8880d6cc8', tool_call_id='functions.calculator:0'), AIMessage(content='100×2=200，优惠价是 200 元。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 260, 'total_tokens': 274, 'completion_time': 0.050230282, 'completion_tokens_details': None, 'prompt_time': 0.032717998, 'prompt_tokens_details': None, 'queue_time': 0.275821141, 'total_time': 0.08294828}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-a95b-7352-9c92-85a10409ce33-0', usage_metadata={'input_tokens': 260, 'output_tokens': 14, 'total_tokens': 274}), HumanMessage(content='谢谢', additional_kwargs={}, response_metadata={}, id='a094b56e-c988-4ec7-bc11-ab0ce090029d'), AIMessage(content='不客气，有其他问题随时找我！', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 282, 'total_tokens': 291, 'completion_time': 0.04287815, 'completion_tokens_details': None, 'prompt_time': 0.011590115, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.279740625, 'total_time': 0.054468265}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-ad1e-7a33-84a1-ef428aefaa62-0', usage_metadata={'input_tokens': 282, 'output_tokens': 9, 'total_tokens': 291, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='你是谁？', additional_kwargs={}, response_metadata={}, id='b6ede465-ed97-440c-9c06-ee3fb0de8039'), AIMessage(content='我是您的客服助手，专门帮您处理订单、计算和解答问题的小助手。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 300, 'total_tokens': 318, 'completion_time': 0.061644683, 'completion_tokens_details': None, 'prompt_time': 0.017812077, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.275967683, 'total_time': 0.07945676}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-af21-7e80-bf7b-83c621b91bf8-0', usage_metadata={'input_tokens': 300, 'output_tokens': 18, 'total_tokens': 318, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='我是客服助手', additional_kwargs={}, response_metadata={}, id='c7f6ebd6-ce31-49ab-aff1-83eb1b9face9'), AIMessage(content='收到，您也是客服助手。请问还有什么我能帮您的？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 328, 'total_tokens': 342, 'completion_time': 0.073852622, 'completion_tokens_details': None, 'prompt_time': 0.017274831, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.277231488, 'total_time': 0.091127453}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b13d-78a1-821c-87ade5c200e4-0', usage_metadata={'input_tokens': 328, 'output_tokens': 14, 'total_tokens': 342, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='请告诉我你的问题', additional_kwargs={}, response_metadata={}, id='3ca057c1-2442-4964-b4fe-7c45397e6bac'), AIMessage(content='好的，作为客服助手，您现在最希望我帮您解决什么问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 353, 'total_tokens': 368, 'completion_time': 0.061506792, 'completion_tokens_details': None, 'prompt_time': 0.041443485, 'prompt_tokens_details': None, 'queue_time': 0.285442544, 'total_time': 0.102950277}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b36f-7300-bce5-4eed47d1ba2b-0', usage_metadata={'input_tokens': 353, 'output_tokens': 15, 'total_tokens': 368}), HumanMessage(content='以上是对话摘要，请继续帮助用户。', additional_kwargs={}, response_metadata={}, id='31789b53-690d-4099-9fd1-2e6437b69233'), AIMessage(content='好的，我随时待命。请问接下来需要我为您做什么？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 385, 'total_tokens': 399, 'completion_time': 0.063376713, 'completion_tokens_details': None, 'prompt_time': 0.031132086, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.283446924, 'total_time': 0.094508799}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b5b5-7121-8f2f-e2b9b62ada54-0', usage_metadata={'input_tokens': 385, 'output_tokens': 14, 'total_tokens': 399, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='你好，我想咨询订单', additional_kwargs={}, response_metadata={}, id='52e42620-3269-45fe-afbb-d1076460f01f'), AIMessage(content='您好！请问您的订单号是多少？或想咨询订单的哪方面问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 411, 'total_tokens': 429, 'completion_time': 0.041872788, 'completion_tokens_details': None, 'prompt_time': 0.018419223, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.283894627, 'total_time': 0.060292011}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-39b8-7f63-ad90-19f21878e6c2-0', usage_metadata={'input_tokens': 411, 'output_tokens': 18, 'total_tokens': 429, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='我的订单号是 12345', additional_kwargs={}, response_metadata={}, id='2ffa4503-4823-4af7-bb33-8b842ab94e5c'), AIMessage(content='收到，订单号 12345。请问您想咨询这个订单的哪方面问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 452, 'total_tokens': 472, 'completion_time': 0.032032961, 'completion_tokens_details': None, 'prompt_time': 0.054393703, 'prompt_tokens_details': None, 'queue_time': 0.283972026, 'total_time': 0.086426664}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-41af-75a1-a4ec-a5873c8a89cd-0', usage_metadata={'input_tokens': 452, 'output_tokens': 20, 'total_tokens': 472})]\n",
      "**************************************************\n",
      "\n",
      "客户: 帮我算一下 100 乘以 2 的优惠价\n",
      "客服: [HumanMessage(content='Here is a summary of the conversation to date:\\n\\n用户意图：咨询订单；已提供订单号：12345', additional_kwargs={}, response_metadata={}, id='cad77b8e-42e6-417c-bcac-367ec058bb80'), AIMessage(content='收到，订单号 12345。请问您想咨询关于这个订单的具体什么问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 160, 'total_tokens': 179, 'completion_time': 0.053537076, 'completion_tokens_details': None, 'prompt_time': 0.020483382, 'prompt_tokens_details': None, 'queue_time': 0.285579326, 'total_time': 0.074020458}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-a11a-76e1-b3f3-73602bfb934f-0', usage_metadata={'input_tokens': 160, 'output_tokens': 19, 'total_tokens': 179}), HumanMessage(content='帮我算一下 100 乘以 2 的优惠价', additional_kwargs={}, response_metadata={}, id='5eee489d-cb2a-4556-a60a-2589d06b0fc4'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'functions.calculator:0', 'function': {'arguments': '{\"a\":100,\"b\":2,\"operation\":\"multiply\"}', 'name': 'calculator'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 198, 'total_tokens': 227, 'completion_time': 0.06871851, 'completion_tokens_details': None, 'prompt_time': 0.027982045, 'prompt_tokens_details': None, 'queue_time': 0.285577864, 'total_time': 0.096700555}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-a33c-70d3-8309-6f863f95e14c-0', tool_calls=[{'name': 'calculator', 'args': {'a': 100, 'b': 2, 'operation': 'multiply'}, 'id': 'functions.calculator:0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 198, 'output_tokens': 29, 'total_tokens': 227}), ToolMessage(content='100.0 multiply 2.0 = 200.0', name='calculator', id='8bd06975-602c-49cb-9ec0-78f8880d6cc8', tool_call_id='functions.calculator:0'), AIMessage(content='100×2=200，优惠价是 200 元。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 260, 'total_tokens': 274, 'completion_time': 0.050230282, 'completion_tokens_details': None, 'prompt_time': 0.032717998, 'prompt_tokens_details': None, 'queue_time': 0.275821141, 'total_time': 0.08294828}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-a95b-7352-9c92-85a10409ce33-0', usage_metadata={'input_tokens': 260, 'output_tokens': 14, 'total_tokens': 274}), HumanMessage(content='谢谢', additional_kwargs={}, response_metadata={}, id='a094b56e-c988-4ec7-bc11-ab0ce090029d'), AIMessage(content='不客气，有其他问题随时找我！', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 282, 'total_tokens': 291, 'completion_time': 0.04287815, 'completion_tokens_details': None, 'prompt_time': 0.011590115, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.279740625, 'total_time': 0.054468265}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-ad1e-7a33-84a1-ef428aefaa62-0', usage_metadata={'input_tokens': 282, 'output_tokens': 9, 'total_tokens': 291, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='你是谁？', additional_kwargs={}, response_metadata={}, id='b6ede465-ed97-440c-9c06-ee3fb0de8039'), AIMessage(content='我是您的客服助手，专门帮您处理订单、计算和解答问题的小助手。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 300, 'total_tokens': 318, 'completion_time': 0.061644683, 'completion_tokens_details': None, 'prompt_time': 0.017812077, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.275967683, 'total_time': 0.07945676}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-af21-7e80-bf7b-83c621b91bf8-0', usage_metadata={'input_tokens': 300, 'output_tokens': 18, 'total_tokens': 318, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='我是客服助手', additional_kwargs={}, response_metadata={}, id='c7f6ebd6-ce31-49ab-aff1-83eb1b9face9'), AIMessage(content='收到，您也是客服助手。请问还有什么我能帮您的？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 328, 'total_tokens': 342, 'completion_time': 0.073852622, 'completion_tokens_details': None, 'prompt_time': 0.017274831, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.277231488, 'total_time': 0.091127453}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b13d-78a1-821c-87ade5c200e4-0', usage_metadata={'input_tokens': 328, 'output_tokens': 14, 'total_tokens': 342, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='请告诉我你的问题', additional_kwargs={}, response_metadata={}, id='3ca057c1-2442-4964-b4fe-7c45397e6bac'), AIMessage(content='好的，作为客服助手，您现在最希望我帮您解决什么问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 353, 'total_tokens': 368, 'completion_time': 0.061506792, 'completion_tokens_details': None, 'prompt_time': 0.041443485, 'prompt_tokens_details': None, 'queue_time': 0.285442544, 'total_time': 0.102950277}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b36f-7300-bce5-4eed47d1ba2b-0', usage_metadata={'input_tokens': 353, 'output_tokens': 15, 'total_tokens': 368}), HumanMessage(content='以上是对话摘要，请继续帮助用户。', additional_kwargs={}, response_metadata={}, id='31789b53-690d-4099-9fd1-2e6437b69233'), AIMessage(content='好的，我随时待命。请问接下来需要我为您做什么？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 385, 'total_tokens': 399, 'completion_time': 0.063376713, 'completion_tokens_details': None, 'prompt_time': 0.031132086, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.283446924, 'total_time': 0.094508799}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b5b5-7121-8f2f-e2b9b62ada54-0', usage_metadata={'input_tokens': 385, 'output_tokens': 14, 'total_tokens': 399, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='你好，我想咨询订单', additional_kwargs={}, response_metadata={}, id='52e42620-3269-45fe-afbb-d1076460f01f'), AIMessage(content='您好！请问您的订单号是多少？或想咨询订单的哪方面问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 411, 'total_tokens': 429, 'completion_time': 0.041872788, 'completion_tokens_details': None, 'prompt_time': 0.018419223, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.283894627, 'total_time': 0.060292011}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-39b8-7f63-ad90-19f21878e6c2-0', usage_metadata={'input_tokens': 411, 'output_tokens': 18, 'total_tokens': 429, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='我的订单号是 12345', additional_kwargs={}, response_metadata={}, id='2ffa4503-4823-4af7-bb33-8b842ab94e5c'), AIMessage(content='收到，订单号 12345。请问您想咨询这个订单的哪方面问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 452, 'total_tokens': 472, 'completion_time': 0.032032961, 'completion_tokens_details': None, 'prompt_time': 0.054393703, 'prompt_tokens_details': None, 'queue_time': 0.283972026, 'total_time': 0.086426664}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-41af-75a1-a4ec-a5873c8a89cd-0', usage_metadata={'input_tokens': 452, 'output_tokens': 20, 'total_tokens': 472}), HumanMessage(content='帮我算一下 100 乘以 2 的优惠价', additional_kwargs={}, response_metadata={}, id='53333adf-3ec9-4972-b560-3f5745df6253'), AIMessage(content='100×2=200，优惠价就是 200 元。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 461, 'total_tokens': 475, 'completion_time': 0.04171524, 'completion_tokens_details': None, 'prompt_time': 0.038110407, 'prompt_tokens_details': None, 'queue_time': 0.283901272, 'total_time': 0.079825647}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-495c-7ff1-822f-a3e1dd45639a-0', usage_metadata={'input_tokens': 461, 'output_tokens': 14, 'total_tokens': 475})]\n",
      "**************************************************\n",
      "\n",
      "客户: 谢谢\n",
      "客服: [HumanMessage(content='Here is a summary of the conversation to date:\\n\\n订单号：12345（用户意图：咨询订单）', additional_kwargs={}, response_metadata={}, id='87b647dd-a899-438d-9523-d99f27f5db4a'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'functions.calculator:0', 'function': {'arguments': '{\"a\":100,\"b\":2,\"operation\":\"multiply\"}', 'name': 'calculator'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 198, 'total_tokens': 227, 'completion_time': 0.06871851, 'completion_tokens_details': None, 'prompt_time': 0.027982045, 'prompt_tokens_details': None, 'queue_time': 0.285577864, 'total_time': 0.096700555}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-a33c-70d3-8309-6f863f95e14c-0', tool_calls=[{'name': 'calculator', 'args': {'a': 100, 'b': 2, 'operation': 'multiply'}, 'id': 'functions.calculator:0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 198, 'output_tokens': 29, 'total_tokens': 227}), ToolMessage(content='100.0 multiply 2.0 = 200.0', name='calculator', id='8bd06975-602c-49cb-9ec0-78f8880d6cc8', tool_call_id='functions.calculator:0'), AIMessage(content='100×2=200，优惠价是 200 元。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 260, 'total_tokens': 274, 'completion_time': 0.050230282, 'completion_tokens_details': None, 'prompt_time': 0.032717998, 'prompt_tokens_details': None, 'queue_time': 0.275821141, 'total_time': 0.08294828}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-a95b-7352-9c92-85a10409ce33-0', usage_metadata={'input_tokens': 260, 'output_tokens': 14, 'total_tokens': 274}), HumanMessage(content='谢谢', additional_kwargs={}, response_metadata={}, id='a094b56e-c988-4ec7-bc11-ab0ce090029d'), AIMessage(content='不客气，有其他问题随时找我！', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 282, 'total_tokens': 291, 'completion_time': 0.04287815, 'completion_tokens_details': None, 'prompt_time': 0.011590115, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.279740625, 'total_time': 0.054468265}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-ad1e-7a33-84a1-ef428aefaa62-0', usage_metadata={'input_tokens': 282, 'output_tokens': 9, 'total_tokens': 291, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='你是谁？', additional_kwargs={}, response_metadata={}, id='b6ede465-ed97-440c-9c06-ee3fb0de8039'), AIMessage(content='我是您的客服助手，专门帮您处理订单、计算和解答问题的小助手。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 300, 'total_tokens': 318, 'completion_time': 0.061644683, 'completion_tokens_details': None, 'prompt_time': 0.017812077, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.275967683, 'total_time': 0.07945676}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-af21-7e80-bf7b-83c621b91bf8-0', usage_metadata={'input_tokens': 300, 'output_tokens': 18, 'total_tokens': 318, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='我是客服助手', additional_kwargs={}, response_metadata={}, id='c7f6ebd6-ce31-49ab-aff1-83eb1b9face9'), AIMessage(content='收到，您也是客服助手。请问还有什么我能帮您的？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 328, 'total_tokens': 342, 'completion_time': 0.073852622, 'completion_tokens_details': None, 'prompt_time': 0.017274831, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.277231488, 'total_time': 0.091127453}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b13d-78a1-821c-87ade5c200e4-0', usage_metadata={'input_tokens': 328, 'output_tokens': 14, 'total_tokens': 342, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='请告诉我你的问题', additional_kwargs={}, response_metadata={}, id='3ca057c1-2442-4964-b4fe-7c45397e6bac'), AIMessage(content='好的，作为客服助手，您现在最希望我帮您解决什么问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 353, 'total_tokens': 368, 'completion_time': 0.061506792, 'completion_tokens_details': None, 'prompt_time': 0.041443485, 'prompt_tokens_details': None, 'queue_time': 0.285442544, 'total_time': 0.102950277}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b36f-7300-bce5-4eed47d1ba2b-0', usage_metadata={'input_tokens': 353, 'output_tokens': 15, 'total_tokens': 368}), HumanMessage(content='以上是对话摘要，请继续帮助用户。', additional_kwargs={}, response_metadata={}, id='31789b53-690d-4099-9fd1-2e6437b69233'), AIMessage(content='好的，我随时待命。请问接下来需要我为您做什么？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 385, 'total_tokens': 399, 'completion_time': 0.063376713, 'completion_tokens_details': None, 'prompt_time': 0.031132086, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.283446924, 'total_time': 0.094508799}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b5b5-7121-8f2f-e2b9b62ada54-0', usage_metadata={'input_tokens': 385, 'output_tokens': 14, 'total_tokens': 399, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='你好，我想咨询订单', additional_kwargs={}, response_metadata={}, id='52e42620-3269-45fe-afbb-d1076460f01f'), AIMessage(content='您好！请问您的订单号是多少？或想咨询订单的哪方面问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 411, 'total_tokens': 429, 'completion_time': 0.041872788, 'completion_tokens_details': None, 'prompt_time': 0.018419223, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.283894627, 'total_time': 0.060292011}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-39b8-7f63-ad90-19f21878e6c2-0', usage_metadata={'input_tokens': 411, 'output_tokens': 18, 'total_tokens': 429, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='我的订单号是 12345', additional_kwargs={}, response_metadata={}, id='2ffa4503-4823-4af7-bb33-8b842ab94e5c'), AIMessage(content='收到，订单号 12345。请问您想咨询这个订单的哪方面问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 452, 'total_tokens': 472, 'completion_time': 0.032032961, 'completion_tokens_details': None, 'prompt_time': 0.054393703, 'prompt_tokens_details': None, 'queue_time': 0.283972026, 'total_time': 0.086426664}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-41af-75a1-a4ec-a5873c8a89cd-0', usage_metadata={'input_tokens': 452, 'output_tokens': 20, 'total_tokens': 472}), HumanMessage(content='帮我算一下 100 乘以 2 的优惠价', additional_kwargs={}, response_metadata={}, id='53333adf-3ec9-4972-b560-3f5745df6253'), AIMessage(content='100×2=200，优惠价就是 200 元。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 461, 'total_tokens': 475, 'completion_time': 0.04171524, 'completion_tokens_details': None, 'prompt_time': 0.038110407, 'prompt_tokens_details': None, 'queue_time': 0.283901272, 'total_time': 0.079825647}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-495c-7ff1-822f-a3e1dd45639a-0', usage_metadata={'input_tokens': 461, 'output_tokens': 14, 'total_tokens': 475}), HumanMessage(content='谢谢', additional_kwargs={}, response_metadata={}, id='3fdcd787-9f57-46f8-804b-4c9c0c1d242f'), AIMessage(content='不客气，有需要随时找我！', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 444, 'total_tokens': 452, 'completion_time': 0.030233749, 'completion_tokens_details': None, 'prompt_time': 0.058780215, 'prompt_tokens_details': None, 'queue_time': 0.283680245, 'total_time': 0.089013964}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-4dc4-7f83-96c8-d5f0807301e2-0', usage_metadata={'input_tokens': 444, 'output_tokens': 8, 'total_tokens': 452})]\n",
      "**************************************************\n",
      "\n",
      "客户: 你是谁？\n",
      "客服: [HumanMessage(content='Here is a summary of the conversation to date:\\n\\n订单号：12345 - 用户意图：咨询订单', additional_kwargs={}, response_metadata={}, id='f395c172-8cd9-4b38-a18a-0ccaea900613'), AIMessage(content='100×2=200，优惠价是 200 元。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 260, 'total_tokens': 274, 'completion_time': 0.050230282, 'completion_tokens_details': None, 'prompt_time': 0.032717998, 'prompt_tokens_details': None, 'queue_time': 0.275821141, 'total_time': 0.08294828}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-a95b-7352-9c92-85a10409ce33-0', usage_metadata={'input_tokens': 260, 'output_tokens': 14, 'total_tokens': 274}), HumanMessage(content='谢谢', additional_kwargs={}, response_metadata={}, id='a094b56e-c988-4ec7-bc11-ab0ce090029d'), AIMessage(content='不客气，有其他问题随时找我！', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 282, 'total_tokens': 291, 'completion_time': 0.04287815, 'completion_tokens_details': None, 'prompt_time': 0.011590115, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.279740625, 'total_time': 0.054468265}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-ad1e-7a33-84a1-ef428aefaa62-0', usage_metadata={'input_tokens': 282, 'output_tokens': 9, 'total_tokens': 291, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='你是谁？', additional_kwargs={}, response_metadata={}, id='b6ede465-ed97-440c-9c06-ee3fb0de8039'), AIMessage(content='我是您的客服助手，专门帮您处理订单、计算和解答问题的小助手。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 300, 'total_tokens': 318, 'completion_time': 0.061644683, 'completion_tokens_details': None, 'prompt_time': 0.017812077, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.275967683, 'total_time': 0.07945676}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-af21-7e80-bf7b-83c621b91bf8-0', usage_metadata={'input_tokens': 300, 'output_tokens': 18, 'total_tokens': 318, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='我是客服助手', additional_kwargs={}, response_metadata={}, id='c7f6ebd6-ce31-49ab-aff1-83eb1b9face9'), AIMessage(content='收到，您也是客服助手。请问还有什么我能帮您的？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 328, 'total_tokens': 342, 'completion_time': 0.073852622, 'completion_tokens_details': None, 'prompt_time': 0.017274831, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.277231488, 'total_time': 0.091127453}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b13d-78a1-821c-87ade5c200e4-0', usage_metadata={'input_tokens': 328, 'output_tokens': 14, 'total_tokens': 342, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='请告诉我你的问题', additional_kwargs={}, response_metadata={}, id='3ca057c1-2442-4964-b4fe-7c45397e6bac'), AIMessage(content='好的，作为客服助手，您现在最希望我帮您解决什么问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 353, 'total_tokens': 368, 'completion_time': 0.061506792, 'completion_tokens_details': None, 'prompt_time': 0.041443485, 'prompt_tokens_details': None, 'queue_time': 0.285442544, 'total_time': 0.102950277}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b36f-7300-bce5-4eed47d1ba2b-0', usage_metadata={'input_tokens': 353, 'output_tokens': 15, 'total_tokens': 368}), HumanMessage(content='以上是对话摘要，请继续帮助用户。', additional_kwargs={}, response_metadata={}, id='31789b53-690d-4099-9fd1-2e6437b69233'), AIMessage(content='好的，我随时待命。请问接下来需要我为您做什么？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 385, 'total_tokens': 399, 'completion_time': 0.063376713, 'completion_tokens_details': None, 'prompt_time': 0.031132086, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.283446924, 'total_time': 0.094508799}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b5b5-7121-8f2f-e2b9b62ada54-0', usage_metadata={'input_tokens': 385, 'output_tokens': 14, 'total_tokens': 399, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='你好，我想咨询订单', additional_kwargs={}, response_metadata={}, id='52e42620-3269-45fe-afbb-d1076460f01f'), AIMessage(content='您好！请问您的订单号是多少？或想咨询订单的哪方面问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 411, 'total_tokens': 429, 'completion_time': 0.041872788, 'completion_tokens_details': None, 'prompt_time': 0.018419223, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.283894627, 'total_time': 0.060292011}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-39b8-7f63-ad90-19f21878e6c2-0', usage_metadata={'input_tokens': 411, 'output_tokens': 18, 'total_tokens': 429, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='我的订单号是 12345', additional_kwargs={}, response_metadata={}, id='2ffa4503-4823-4af7-bb33-8b842ab94e5c'), AIMessage(content='收到，订单号 12345。请问您想咨询这个订单的哪方面问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 452, 'total_tokens': 472, 'completion_time': 0.032032961, 'completion_tokens_details': None, 'prompt_time': 0.054393703, 'prompt_tokens_details': None, 'queue_time': 0.283972026, 'total_time': 0.086426664}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-41af-75a1-a4ec-a5873c8a89cd-0', usage_metadata={'input_tokens': 452, 'output_tokens': 20, 'total_tokens': 472}), HumanMessage(content='帮我算一下 100 乘以 2 的优惠价', additional_kwargs={}, response_metadata={}, id='53333adf-3ec9-4972-b560-3f5745df6253'), AIMessage(content='100×2=200，优惠价就是 200 元。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 461, 'total_tokens': 475, 'completion_time': 0.04171524, 'completion_tokens_details': None, 'prompt_time': 0.038110407, 'prompt_tokens_details': None, 'queue_time': 0.283901272, 'total_time': 0.079825647}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-495c-7ff1-822f-a3e1dd45639a-0', usage_metadata={'input_tokens': 461, 'output_tokens': 14, 'total_tokens': 475}), HumanMessage(content='谢谢', additional_kwargs={}, response_metadata={}, id='3fdcd787-9f57-46f8-804b-4c9c0c1d242f'), AIMessage(content='不客气，有需要随时找我！', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 444, 'total_tokens': 452, 'completion_time': 0.030233749, 'completion_tokens_details': None, 'prompt_time': 0.058780215, 'prompt_tokens_details': None, 'queue_time': 0.283680245, 'total_time': 0.089013964}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-4dc4-7f83-96c8-d5f0807301e2-0', usage_metadata={'input_tokens': 444, 'output_tokens': 8, 'total_tokens': 452}), HumanMessage(content='你是谁？', additional_kwargs={}, response_metadata={}, id='afa3085e-38c2-4364-90ef-e0305e8107d9'), AIMessage(content='我是您的客服助手，专门帮您处理订单、计算和解答问题的小助手。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 399, 'total_tokens': 417, 'completion_time': 0.024034866, 'completion_tokens_details': None, 'prompt_time': 0.100470696, 'prompt_tokens_details': None, 'queue_time': 0.284080292, 'total_time': 0.124505562}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-5273-7b31-bfe3-e7dc9245e088-0', usage_metadata={'input_tokens': 399, 'output_tokens': 18, 'total_tokens': 417})]\n",
      "**************************************************\n",
      "\n",
      "客户: 我是客服助手\n",
      "客服: [HumanMessage(content='Here is a summary of the conversation to date:\\n\\n订单号：12345，用户咨询订单，已报价：100×2 优惠价 200 元。', additional_kwargs={}, response_metadata={}, id='1babf454-577b-4c36-aead-cae041a990ba'), AIMessage(content='不客气，有其他问题随时找我！', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 282, 'total_tokens': 291, 'completion_time': 0.04287815, 'completion_tokens_details': None, 'prompt_time': 0.011590115, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.279740625, 'total_time': 0.054468265}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-ad1e-7a33-84a1-ef428aefaa62-0', usage_metadata={'input_tokens': 282, 'output_tokens': 9, 'total_tokens': 291, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='你是谁？', additional_kwargs={}, response_metadata={}, id='b6ede465-ed97-440c-9c06-ee3fb0de8039'), AIMessage(content='我是您的客服助手，专门帮您处理订单、计算和解答问题的小助手。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 300, 'total_tokens': 318, 'completion_time': 0.061644683, 'completion_tokens_details': None, 'prompt_time': 0.017812077, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.275967683, 'total_time': 0.07945676}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-af21-7e80-bf7b-83c621b91bf8-0', usage_metadata={'input_tokens': 300, 'output_tokens': 18, 'total_tokens': 318, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='我是客服助手', additional_kwargs={}, response_metadata={}, id='c7f6ebd6-ce31-49ab-aff1-83eb1b9face9'), AIMessage(content='收到，您也是客服助手。请问还有什么我能帮您的？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 328, 'total_tokens': 342, 'completion_time': 0.073852622, 'completion_tokens_details': None, 'prompt_time': 0.017274831, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.277231488, 'total_time': 0.091127453}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b13d-78a1-821c-87ade5c200e4-0', usage_metadata={'input_tokens': 328, 'output_tokens': 14, 'total_tokens': 342, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='请告诉我你的问题', additional_kwargs={}, response_metadata={}, id='3ca057c1-2442-4964-b4fe-7c45397e6bac'), AIMessage(content='好的，作为客服助手，您现在最希望我帮您解决什么问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 353, 'total_tokens': 368, 'completion_time': 0.061506792, 'completion_tokens_details': None, 'prompt_time': 0.041443485, 'prompt_tokens_details': None, 'queue_time': 0.285442544, 'total_time': 0.102950277}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b36f-7300-bce5-4eed47d1ba2b-0', usage_metadata={'input_tokens': 353, 'output_tokens': 15, 'total_tokens': 368}), HumanMessage(content='以上是对话摘要，请继续帮助用户。', additional_kwargs={}, response_metadata={}, id='31789b53-690d-4099-9fd1-2e6437b69233'), AIMessage(content='好的，我随时待命。请问接下来需要我为您做什么？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 385, 'total_tokens': 399, 'completion_time': 0.063376713, 'completion_tokens_details': None, 'prompt_time': 0.031132086, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.283446924, 'total_time': 0.094508799}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b5b5-7121-8f2f-e2b9b62ada54-0', usage_metadata={'input_tokens': 385, 'output_tokens': 14, 'total_tokens': 399, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='你好，我想咨询订单', additional_kwargs={}, response_metadata={}, id='52e42620-3269-45fe-afbb-d1076460f01f'), AIMessage(content='您好！请问您的订单号是多少？或想咨询订单的哪方面问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 411, 'total_tokens': 429, 'completion_time': 0.041872788, 'completion_tokens_details': None, 'prompt_time': 0.018419223, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.283894627, 'total_time': 0.060292011}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-39b8-7f63-ad90-19f21878e6c2-0', usage_metadata={'input_tokens': 411, 'output_tokens': 18, 'total_tokens': 429, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='我的订单号是 12345', additional_kwargs={}, response_metadata={}, id='2ffa4503-4823-4af7-bb33-8b842ab94e5c'), AIMessage(content='收到，订单号 12345。请问您想咨询这个订单的哪方面问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 452, 'total_tokens': 472, 'completion_time': 0.032032961, 'completion_tokens_details': None, 'prompt_time': 0.054393703, 'prompt_tokens_details': None, 'queue_time': 0.283972026, 'total_time': 0.086426664}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-41af-75a1-a4ec-a5873c8a89cd-0', usage_metadata={'input_tokens': 452, 'output_tokens': 20, 'total_tokens': 472}), HumanMessage(content='帮我算一下 100 乘以 2 的优惠价', additional_kwargs={}, response_metadata={}, id='53333adf-3ec9-4972-b560-3f5745df6253'), AIMessage(content='100×2=200，优惠价就是 200 元。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 461, 'total_tokens': 475, 'completion_time': 0.04171524, 'completion_tokens_details': None, 'prompt_time': 0.038110407, 'prompt_tokens_details': None, 'queue_time': 0.283901272, 'total_time': 0.079825647}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-495c-7ff1-822f-a3e1dd45639a-0', usage_metadata={'input_tokens': 461, 'output_tokens': 14, 'total_tokens': 475}), HumanMessage(content='谢谢', additional_kwargs={}, response_metadata={}, id='3fdcd787-9f57-46f8-804b-4c9c0c1d242f'), AIMessage(content='不客气，有需要随时找我！', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 444, 'total_tokens': 452, 'completion_time': 0.030233749, 'completion_tokens_details': None, 'prompt_time': 0.058780215, 'prompt_tokens_details': None, 'queue_time': 0.283680245, 'total_time': 0.089013964}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-4dc4-7f83-96c8-d5f0807301e2-0', usage_metadata={'input_tokens': 444, 'output_tokens': 8, 'total_tokens': 452}), HumanMessage(content='你是谁？', additional_kwargs={}, response_metadata={}, id='afa3085e-38c2-4364-90ef-e0305e8107d9'), AIMessage(content='我是您的客服助手，专门帮您处理订单、计算和解答问题的小助手。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 399, 'total_tokens': 417, 'completion_time': 0.024034866, 'completion_tokens_details': None, 'prompt_time': 0.100470696, 'prompt_tokens_details': None, 'queue_time': 0.284080292, 'total_time': 0.124505562}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-5273-7b31-bfe3-e7dc9245e088-0', usage_metadata={'input_tokens': 399, 'output_tokens': 18, 'total_tokens': 417}), HumanMessage(content='我是客服助手', additional_kwargs={}, response_metadata={}, id='45a129cc-f927-459f-a436-d3f3c10a7665'), AIMessage(content='收到，同行您好！有需要协助的地方请随时说。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 416, 'total_tokens': 429, 'completion_time': 0.046353849, 'completion_tokens_details': None, 'prompt_time': 0.061617701, 'prompt_tokens_details': None, 'queue_time': 0.638558266, 'total_time': 0.10797155}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-5794-7d23-8ab3-6109e24b1ec7-0', usage_metadata={'input_tokens': 416, 'output_tokens': 13, 'total_tokens': 429})]\n",
      "**************************************************\n",
      "\n",
      "客户: 请告诉我你的问题\n",
      "客服: [HumanMessage(content='Here is a summary of the conversation to date:\\n\\n订单号12345，用户已获报价：100×2 优惠价 200 元，咨询完成。', additional_kwargs={}, response_metadata={}, id='056ab6f2-d57b-4b5c-b02d-3313fb7cac34'), AIMessage(content='我是您的客服助手，专门帮您处理订单、计算和解答问题的小助手。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 300, 'total_tokens': 318, 'completion_time': 0.061644683, 'completion_tokens_details': None, 'prompt_time': 0.017812077, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.275967683, 'total_time': 0.07945676}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-af21-7e80-bf7b-83c621b91bf8-0', usage_metadata={'input_tokens': 300, 'output_tokens': 18, 'total_tokens': 318, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='我是客服助手', additional_kwargs={}, response_metadata={}, id='c7f6ebd6-ce31-49ab-aff1-83eb1b9face9'), AIMessage(content='收到，您也是客服助手。请问还有什么我能帮您的？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 328, 'total_tokens': 342, 'completion_time': 0.073852622, 'completion_tokens_details': None, 'prompt_time': 0.017274831, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.277231488, 'total_time': 0.091127453}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b13d-78a1-821c-87ade5c200e4-0', usage_metadata={'input_tokens': 328, 'output_tokens': 14, 'total_tokens': 342, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='请告诉我你的问题', additional_kwargs={}, response_metadata={}, id='3ca057c1-2442-4964-b4fe-7c45397e6bac'), AIMessage(content='好的，作为客服助手，您现在最希望我帮您解决什么问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 353, 'total_tokens': 368, 'completion_time': 0.061506792, 'completion_tokens_details': None, 'prompt_time': 0.041443485, 'prompt_tokens_details': None, 'queue_time': 0.285442544, 'total_time': 0.102950277}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b36f-7300-bce5-4eed47d1ba2b-0', usage_metadata={'input_tokens': 353, 'output_tokens': 15, 'total_tokens': 368}), HumanMessage(content='以上是对话摘要，请继续帮助用户。', additional_kwargs={}, response_metadata={}, id='31789b53-690d-4099-9fd1-2e6437b69233'), AIMessage(content='好的，我随时待命。请问接下来需要我为您做什么？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 385, 'total_tokens': 399, 'completion_time': 0.063376713, 'completion_tokens_details': None, 'prompt_time': 0.031132086, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.283446924, 'total_time': 0.094508799}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b5b5-7121-8f2f-e2b9b62ada54-0', usage_metadata={'input_tokens': 385, 'output_tokens': 14, 'total_tokens': 399, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='你好，我想咨询订单', additional_kwargs={}, response_metadata={}, id='52e42620-3269-45fe-afbb-d1076460f01f'), AIMessage(content='您好！请问您的订单号是多少？或想咨询订单的哪方面问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 411, 'total_tokens': 429, 'completion_time': 0.041872788, 'completion_tokens_details': None, 'prompt_time': 0.018419223, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.283894627, 'total_time': 0.060292011}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-39b8-7f63-ad90-19f21878e6c2-0', usage_metadata={'input_tokens': 411, 'output_tokens': 18, 'total_tokens': 429, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='我的订单号是 12345', additional_kwargs={}, response_metadata={}, id='2ffa4503-4823-4af7-bb33-8b842ab94e5c'), AIMessage(content='收到，订单号 12345。请问您想咨询这个订单的哪方面问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 452, 'total_tokens': 472, 'completion_time': 0.032032961, 'completion_tokens_details': None, 'prompt_time': 0.054393703, 'prompt_tokens_details': None, 'queue_time': 0.283972026, 'total_time': 0.086426664}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-41af-75a1-a4ec-a5873c8a89cd-0', usage_metadata={'input_tokens': 452, 'output_tokens': 20, 'total_tokens': 472}), HumanMessage(content='帮我算一下 100 乘以 2 的优惠价', additional_kwargs={}, response_metadata={}, id='53333adf-3ec9-4972-b560-3f5745df6253'), AIMessage(content='100×2=200，优惠价就是 200 元。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 461, 'total_tokens': 475, 'completion_time': 0.04171524, 'completion_tokens_details': None, 'prompt_time': 0.038110407, 'prompt_tokens_details': None, 'queue_time': 0.283901272, 'total_time': 0.079825647}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-495c-7ff1-822f-a3e1dd45639a-0', usage_metadata={'input_tokens': 461, 'output_tokens': 14, 'total_tokens': 475}), HumanMessage(content='谢谢', additional_kwargs={}, response_metadata={}, id='3fdcd787-9f57-46f8-804b-4c9c0c1d242f'), AIMessage(content='不客气，有需要随时找我！', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 444, 'total_tokens': 452, 'completion_time': 0.030233749, 'completion_tokens_details': None, 'prompt_time': 0.058780215, 'prompt_tokens_details': None, 'queue_time': 0.283680245, 'total_time': 0.089013964}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-4dc4-7f83-96c8-d5f0807301e2-0', usage_metadata={'input_tokens': 444, 'output_tokens': 8, 'total_tokens': 452}), HumanMessage(content='你是谁？', additional_kwargs={}, response_metadata={}, id='afa3085e-38c2-4364-90ef-e0305e8107d9'), AIMessage(content='我是您的客服助手，专门帮您处理订单、计算和解答问题的小助手。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 399, 'total_tokens': 417, 'completion_time': 0.024034866, 'completion_tokens_details': None, 'prompt_time': 0.100470696, 'prompt_tokens_details': None, 'queue_time': 0.284080292, 'total_time': 0.124505562}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-5273-7b31-bfe3-e7dc9245e088-0', usage_metadata={'input_tokens': 399, 'output_tokens': 18, 'total_tokens': 417}), HumanMessage(content='我是客服助手', additional_kwargs={}, response_metadata={}, id='45a129cc-f927-459f-a436-d3f3c10a7665'), AIMessage(content='收到，同行您好！有需要协助的地方请随时说。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 416, 'total_tokens': 429, 'completion_time': 0.046353849, 'completion_tokens_details': None, 'prompt_time': 0.061617701, 'prompt_tokens_details': None, 'queue_time': 0.638558266, 'total_time': 0.10797155}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-5794-7d23-8ab3-6109e24b1ec7-0', usage_metadata={'input_tokens': 416, 'output_tokens': 13, 'total_tokens': 429}), HumanMessage(content='请告诉我你的问题', additional_kwargs={}, response_metadata={}, id='f0d204a4-0aab-4e07-a55c-7f6d09c4b118'), AIMessage(content='作为客服助手，您目前最希望我帮您解决什么问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 422, 'total_tokens': 435, 'completion_time': 0.058835624, 'completion_tokens_details': None, 'prompt_time': 0.048136321, 'prompt_tokens_details': None, 'queue_time': 0.284397569, 'total_time': 0.106971945}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-5d8c-71a3-9609-a9d51b7aaaa3-0', usage_metadata={'input_tokens': 422, 'output_tokens': 13, 'total_tokens': 435})]\n",
      "**************************************************\n",
      "\n",
      "客户: 以上是对话摘要，请继续帮助用户。\n",
      "客服: [HumanMessage(content='Here is a summary of the conversation to date:\\n\\n订单号12345已获报价：100×2优惠价200元，咨询完成；当前角色为客服助手，专责订单处理、计算与答疑。', additional_kwargs={}, response_metadata={}, id='0c320de4-d8de-4654-a4a6-6304023db2e1'), AIMessage(content='收到，您也是客服助手。请问还有什么我能帮您的？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 328, 'total_tokens': 342, 'completion_time': 0.073852622, 'completion_tokens_details': None, 'prompt_time': 0.017274831, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.277231488, 'total_time': 0.091127453}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_241bc7119c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b13d-78a1-821c-87ade5c200e4-0', usage_metadata={'input_tokens': 328, 'output_tokens': 14, 'total_tokens': 342, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='请告诉我你的问题', additional_kwargs={}, response_metadata={}, id='3ca057c1-2442-4964-b4fe-7c45397e6bac'), AIMessage(content='好的，作为客服助手，您现在最希望我帮您解决什么问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 353, 'total_tokens': 368, 'completion_time': 0.061506792, 'completion_tokens_details': None, 'prompt_time': 0.041443485, 'prompt_tokens_details': None, 'queue_time': 0.285442544, 'total_time': 0.102950277}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b36f-7300-bce5-4eed47d1ba2b-0', usage_metadata={'input_tokens': 353, 'output_tokens': 15, 'total_tokens': 368}), HumanMessage(content='以上是对话摘要，请继续帮助用户。', additional_kwargs={}, response_metadata={}, id='31789b53-690d-4099-9fd1-2e6437b69233'), AIMessage(content='好的，我随时待命。请问接下来需要我为您做什么？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 385, 'total_tokens': 399, 'completion_time': 0.063376713, 'completion_tokens_details': None, 'prompt_time': 0.031132086, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.283446924, 'total_time': 0.094508799}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb3-b5b5-7121-8f2f-e2b9b62ada54-0', usage_metadata={'input_tokens': 385, 'output_tokens': 14, 'total_tokens': 399, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='你好，我想咨询订单', additional_kwargs={}, response_metadata={}, id='52e42620-3269-45fe-afbb-d1076460f01f'), AIMessage(content='您好！请问您的订单号是多少？或想咨询订单的哪方面问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 411, 'total_tokens': 429, 'completion_time': 0.041872788, 'completion_tokens_details': None, 'prompt_time': 0.018419223, 'prompt_tokens_details': {'cached_tokens': 256}, 'queue_time': 0.283894627, 'total_time': 0.060292011}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-39b8-7f63-ad90-19f21878e6c2-0', usage_metadata={'input_tokens': 411, 'output_tokens': 18, 'total_tokens': 429, 'input_token_details': {'cache_read': 256}}), HumanMessage(content='我的订单号是 12345', additional_kwargs={}, response_metadata={}, id='2ffa4503-4823-4af7-bb33-8b842ab94e5c'), AIMessage(content='收到，订单号 12345。请问您想咨询这个订单的哪方面问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 452, 'total_tokens': 472, 'completion_time': 0.032032961, 'completion_tokens_details': None, 'prompt_time': 0.054393703, 'prompt_tokens_details': None, 'queue_time': 0.283972026, 'total_time': 0.086426664}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-41af-75a1-a4ec-a5873c8a89cd-0', usage_metadata={'input_tokens': 452, 'output_tokens': 20, 'total_tokens': 472}), HumanMessage(content='帮我算一下 100 乘以 2 的优惠价', additional_kwargs={}, response_metadata={}, id='53333adf-3ec9-4972-b560-3f5745df6253'), AIMessage(content='100×2=200，优惠价就是 200 元。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 461, 'total_tokens': 475, 'completion_time': 0.04171524, 'completion_tokens_details': None, 'prompt_time': 0.038110407, 'prompt_tokens_details': None, 'queue_time': 0.283901272, 'total_time': 0.079825647}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-495c-7ff1-822f-a3e1dd45639a-0', usage_metadata={'input_tokens': 461, 'output_tokens': 14, 'total_tokens': 475}), HumanMessage(content='谢谢', additional_kwargs={}, response_metadata={}, id='3fdcd787-9f57-46f8-804b-4c9c0c1d242f'), AIMessage(content='不客气，有需要随时找我！', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 444, 'total_tokens': 452, 'completion_time': 0.030233749, 'completion_tokens_details': None, 'prompt_time': 0.058780215, 'prompt_tokens_details': None, 'queue_time': 0.283680245, 'total_time': 0.089013964}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-4dc4-7f83-96c8-d5f0807301e2-0', usage_metadata={'input_tokens': 444, 'output_tokens': 8, 'total_tokens': 452}), HumanMessage(content='你是谁？', additional_kwargs={}, response_metadata={}, id='afa3085e-38c2-4364-90ef-e0305e8107d9'), AIMessage(content='我是您的客服助手，专门帮您处理订单、计算和解答问题的小助手。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 399, 'total_tokens': 417, 'completion_time': 0.024034866, 'completion_tokens_details': None, 'prompt_time': 0.100470696, 'prompt_tokens_details': None, 'queue_time': 0.284080292, 'total_time': 0.124505562}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-5273-7b31-bfe3-e7dc9245e088-0', usage_metadata={'input_tokens': 399, 'output_tokens': 18, 'total_tokens': 417}), HumanMessage(content='我是客服助手', additional_kwargs={}, response_metadata={}, id='45a129cc-f927-459f-a436-d3f3c10a7665'), AIMessage(content='收到，同行您好！有需要协助的地方请随时说。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 416, 'total_tokens': 429, 'completion_time': 0.046353849, 'completion_tokens_details': None, 'prompt_time': 0.061617701, 'prompt_tokens_details': None, 'queue_time': 0.638558266, 'total_time': 0.10797155}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-5794-7d23-8ab3-6109e24b1ec7-0', usage_metadata={'input_tokens': 416, 'output_tokens': 13, 'total_tokens': 429}), HumanMessage(content='请告诉我你的问题', additional_kwargs={}, response_metadata={}, id='f0d204a4-0aab-4e07-a55c-7f6d09c4b118'), AIMessage(content='作为客服助手，您目前最希望我帮您解决什么问题？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 422, 'total_tokens': 435, 'completion_time': 0.058835624, 'completion_tokens_details': None, 'prompt_time': 0.048136321, 'prompt_tokens_details': None, 'queue_time': 0.284397569, 'total_time': 0.106971945}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-5d8c-71a3-9609-a9d51b7aaaa3-0', usage_metadata={'input_tokens': 422, 'output_tokens': 13, 'total_tokens': 435}), HumanMessage(content='以上是对话摘要，请继续帮助用户。', additional_kwargs={}, response_metadata={}, id='83736835-2d20-4bc4-98dd-507038658f7f'), AIMessage(content='好的，我已知悉：订单号 12345 已获报价 100×2 优惠价 200 元。请问接下来还需要我为您做什么？', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 434, 'total_tokens': 468, 'completion_time': 0.119293653, 'completion_tokens_details': None, 'prompt_time': 0.042850093, 'prompt_tokens_details': None, 'queue_time': 0.283370407, 'total_time': 0.162143746}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3bb4-626b-7e50-a987-a15d07ad9a28-0', usage_metadata={'input_tokens': 434, 'output_tokens': 34, 'total_tokens': 468})]\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "for msg in conversations:\n",
    "        print(f\"\\n客户: {msg}\")\n",
    "        response = agent.invoke(\n",
    "            {\"messages\": [{\"role\": \"user\", \"content\": msg}]},\n",
    "            config=config\n",
    "        )\n",
    "        print(f\"客服: {response['messages']}\")\n",
    "        print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d4b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n关键点：\")\n",
    "print(\"  - 自动管理对话长度\")\n",
    "print(\"  - 重要信息（订单号）通过摘要保留\")\n",
    "print(\"  - 适合生产环境\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc76331b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c828e76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain1.0-Langgraph1.0-Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
