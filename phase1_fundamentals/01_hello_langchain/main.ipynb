{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3ff4f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f6330854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "87c098ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8b60971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not GROQ_API_KEY or GROQ_API_KEY == \"your_groq_api_key_here\":\n",
    "    raise ValueError(\n",
    "        \"\\n请先在 .env 文件中设置有效的 GROQ_API_KEY\\n\"\n",
    "        \"访问 https://console.groq.com/keys 获取免费密钥\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3495bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "99aeff0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 32768, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x11776d9d0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x11776fce0>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = init_chat_model(\n",
    "    model =  \"groq:llama-3.3-70b-versatile\",\n",
    "    api_key=GROQ_API_KEY,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2f15bd",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# 示例 1：最简单的 LLM 调用\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "61f7dc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 1：最简单的 LLM 调用\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    示例1：最简单的模型调用\n",
    "\n",
    "    核心概念：\n",
    "    - init_chat_model: 用于初始化聊天模型的统一接口\n",
    "    - invoke: 同步调用模型的方法\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 1：最简单的 LLM 调用\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "response = model.invoke([\n",
    "    {\"role\":\"user\",\"content\":\"用中文介绍一下LangChain是什么？\"}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2c4643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a4d39149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain 是一个开源的框架，旨在简化开发者在使用大型语言模型（LLM）时的工作流程。它提供了一套工具和接口，帮助开发者更轻松地将 LLM 集成到他们的应用程序中。\\n\\nLangChain 的主要功能包括：\\n\\n1. **模型管理**：LangChain 提供了一种简单的方式来管理和部署 LLM 模型，包括模型的加载、更新和缓存。\\n2. **API 接口**：LangChain 提供了一套标准化的 API 接口，允许开发者以统一的方式与不同的 LLM 模型进行交互。\\n3. **数据处理**：LangChain 提供了一些工具和函数来处理和转换数据，例如文本预处理、数据清洗和数据增强。\\n4. **工作流管理**：LangChain 允许开发者定义和管理复杂的工作流程，包括多步骤的处理和决策。\\n5. **集成支持**：LangChain 支持与其他流行的框架和库进行集成，例如 TensorFlow、PyTorch 和 Hugging Face Transformers。\\n\\n通过使用 LangChain，开发者可以更快速地开发和部署基于 LLM 的应用程序，例如聊天机器人、问答系统和文本生成工具。同时，LangChain 也为开发者提供了一种灵活和可扩展的方式来构建和定制他们自己的 LLM 应用程序。'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4208479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)  # 查看返回对象的类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48ccfdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain是一种开源框架，用于构建和开发与大型语言模型（LLaMA）交互的应用程序。它提供了一套工具和API，帮助开发者轻松地与语言模型进行集成，并构建出复杂的对话式人工智能系统。\\n\\nLangChain的主要特点包括：\\n\\n1. **语言模型集成**：LangChain支持多种语言模型，包括LLaMA、BERT、RoBERTa等，允许开发者轻松地将这些模型集成到自己的应用程序中。\\n2. **对话管理**：LangChain提供了一套对话管理工具，帮助开发者构建出能够进行复杂对话的应用程序。\\n3. **知识图谱**：LangChain支持知识图谱的构建和管理，允许开发者将语言模型的输出与外部知识源进行集成。\\n4. **可扩展性**：LangChain设计为高度可扩展的，允许开发者轻松地扩展和定制自己的应用程序。\\n\\nLangChain的应用场景包括：\\n\\n1. **聊天机器人**：LangChain可以用于构建聊天机器人，提供客户服务、技术支持等功能。\\n2. **虚拟助手**：LangChain可以用于构建虚拟助手，帮助用户完成日常任务和提供信息。\\n3. **语言翻译**：LangChain可以用于构建语言翻译应用程序，提供实时翻译功能。\\n4. **内容生成**：LangChain可以用于构建内容生成应用程序，提供自动化内容创建功能。\\n\\n总的来说，LangChain是一个强大的工具，能够帮助开发者构建出复杂的语言理解和生成应用程序。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 377, 'prompt_tokens': 43, 'total_tokens': 420, 'completion_time': 1.173440911, 'completion_tokens_details': None, 'prompt_time': 0.002207574, 'prompt_tokens_details': None, 'queue_time': 0.062730506, 'total_time': 1.175648485}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c06d5113ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b55f3-5115-7763-b29c-aa107571465c-0', usage_metadata={'input_tokens': 43, 'output_tokens': 377, 'total_tokens': 420})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d122326",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# 示例 2：使用消息列表进行对话\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "217248cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 2：使用消息列表构建对话\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    示例2：使用消息列表\n",
    "\n",
    "    核心概念：\n",
    "    - SystemMessage: 系统消息，用于设定 AI 的行为和角色\n",
    "    - HumanMessage: 用户消息\n",
    "    - AIMessage: AI 的回复消息\n",
    "\n",
    "    消息列表允许你构建多轮对话历史\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 2：使用消息列表构建对话\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59976bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b796784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建消息列表\n",
    "messages =[\n",
    "    SystemMessage(content=\"你是一个乐于助人的Python编程助手，擅长用简单易懂的方式解答问题。\"),\n",
    "    HumanMessage(content=\"什么是Python解释器？\")    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d38f4510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(content='你是一个乐于助人的Python编程助手，擅长用简单易懂的方式解答问题。', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a985b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='什么是Python解释器？', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f331819c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Python 解释器：简要概述**\\n\\nPython 解释器是一种软件应用程序，负责读取、分析和执行用 Python 编程语言编写的代码。它的作用是将代码翻译成计算机可以理解的机器码。\\n\\n**解释器的工作原理：**\\n\\n1. **读取代码**：解释器读取您编写的 Python 代码，通常存储在具有 `.py` 扩展名的文件中。\\n2. **解析代码**：解释器将代码分解为较小的部分，称为令牌，然后分析其语法和结构。\\n3. **执行代码**：解释器逐行执行代码，执行任何指定的操作，例如计算、数据操作或输入/输出操作。\\n4. **提供反馈**：如果代码中存在任何错误或问题，解释器会提供详细的错误消息，以帮助您诊断和修复问题。\\n\\n**流行的Python解释器：**\\n\\n* **CPython**：Python语言的原始解释器，也是最广泛使用的解释器。\\n* **PyPy**：一个更快、更高效的解释器，用于执行Python代码。\\n* **IronPython**：一个用于执行Python代码的解释器，使用.Net框架。\\n* **Jython**：一个用于执行Python代码的解释器，运行在Java虚拟机（JVM）上。\\n\\n**为什么使用解释器？**\\n\\n使用Python解释器可以：\\n\\n* **快速原型设计**：解释器允许您快速测试和迭代您的想法，而无需担心编译或链接问题。\\n* **交互式编码**：解释器提供了一个交互式环境，您可以在其中编写和测试代码，而无需创建单独的文件。\\n* **易于调试**：解释器提供详细的错误消息和调试工具，有助于您识别和修复代码中的问题。\\n\\n总体来说，Python 解释器是运行和测试 Python 代码的必备工具。它提供了一个交互式环境，使您能够快速轻松地编写、测试和调试您的代码。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 478, 'prompt_tokens': 67, 'total_tokens': 545, 'completion_time': 1.915330756, 'completion_tokens_details': None, 'prompt_time': 0.003149994, 'prompt_tokens_details': None, 'queue_time': 0.059548096, 'total_time': 1.91848075}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c06d5113ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b55f3-58f1-7362-a15c-086b19fcecea-0', usage_metadata={'input_tokens': 67, 'output_tokens': 478, 'total_tokens': 545})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = model.invoke(messages)\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a95d0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个乐于助人的Python编程助手，擅长用简单易懂的方式解答问题。', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='什么是Python解释器？', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='**Python 解释器：简要概述**\\n\\nPython 解释器是一种软件应用程序，负责读取、分析和执行用 Python 编程语言编写的代码。它的作用是将代码翻译成计算机可以理解的机器码。\\n\\n**解释器的工作原理：**\\n\\n1. **读取代码**：解释器读取您编写的 Python 代码，通常存储在具有 `.py` 扩展名的文件中。\\n2. **解析代码**：解释器将代码分解为较小的部分，称为令牌，然后分析其语法和结构。\\n3. **执行代码**：解释器逐行执行代码，执行任何指定的操作，例如计算、数据操作或输入/输出操作。\\n4. **提供反馈**：如果代码中存在任何错误或问题，解释器会提供详细的错误消息，以帮助您诊断和修复问题。\\n\\n**流行的Python解释器：**\\n\\n* **CPython**：Python语言的原始解释器，也是最广泛使用的解释器。\\n* **PyPy**：一个更快、更高效的解释器，用于执行Python代码。\\n* **IronPython**：一个用于执行Python代码的解释器，使用.Net框架。\\n* **Jython**：一个用于执行Python代码的解释器，运行在Java虚拟机（JVM）上。\\n\\n**为什么使用解释器？**\\n\\n使用Python解释器可以：\\n\\n* **快速原型设计**：解释器允许您快速测试和迭代您的想法，而无需担心编译或链接问题。\\n* **交互式编码**：解释器提供了一个交互式环境，您可以在其中编写和测试代码，而无需创建单独的文件。\\n* **易于调试**：解释器提供详细的错误消息和调试工具，有助于您识别和修复代码中的问题。\\n\\n总体来说，Python 解释器是运行和测试 Python 代码的必备工具。它提供了一个交互式环境，使您能够快速轻松地编写、测试和调试您的代码。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 478, 'prompt_tokens': 67, 'total_tokens': 545, 'completion_time': 1.915330756, 'completion_tokens_details': None, 'prompt_time': 0.003149994, 'prompt_tokens_details': None, 'queue_time': 0.059548096, 'total_time': 1.91848075}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c06d5113ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b55f3-58f1-7362-a15c-086b19fcecea-0', usage_metadata={'input_tokens': 67, 'output_tokens': 478, 'total_tokens': 545})]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append(responses)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "803f5b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(HumanMessage(content=\"你能给我一个简单的例子吗？\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62439aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "继续对话...\n",
      "用户问题: 你能给我一个简单的例子吗？\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"继续对话...\")\n",
    "print(\"用户问题:\", messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b352402",
   "metadata": {},
   "outputs": [],
   "source": [
    "reponses2 = model.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8bc2b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**简单的解释器示例**\n",
      "\n",
      "让我们来看看一个简单的“Hello World”示例：\n",
      "```python\n",
      "print(\"Hello, World!\")\n",
      "```\n",
      "**解释器如何处理此代码：**\n",
      "\n",
      "1. **读取代码**：解释器读取代码并识别 `print()` 函数。\n",
      "2. **解析代码**：解释器分析代码并确定 `print()` 函数应打印字符串“Hello, World！”。\n",
      "3. **执行代码**：解释器执行 `print()` 函数并在屏幕上显示字符串“Hello, World！”。\n",
      "4. **提供反馈**：由于代码没有错误，解释器仅显示输出：`Hello, World!`\n",
      "\n",
      "**运行此代码：**\n",
      "\n",
      "要运行此代码，您可以：\n",
      "\n",
      "1. 在文本编辑器中打开一个新的文件。\n",
      "2. 将代码复制并粘贴到文件中。\n",
      "3. 将文件保存为 `hello.py`（或任何具有 `.py` 扩展名的文件名）。\n",
      "4. 打开终端或命令提示符。\n",
      "5. 导航到包含文件的目录。\n",
      "6. 输入 `python hello.py`（或您正在使用的解释器的名称）。\n",
      "7. 按 Enter 键运行代码。\n",
      "\n",
      "**输出：**\n",
      "```\n",
      "你好，世界！\n",
      "```\n",
      "就这样！解释器已读取、分析并执行代码，并在屏幕上显示输出。\n"
     ]
    }
   ],
   "source": [
    "print(reponses2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9162ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 示例 3：使用字典格式的消息\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d247320b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 3：使用字典格式的消息（推荐）\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "示例3：使用字典格式的消息\n",
    "\n",
    "LangChain 1.0 支持更简洁的字典格式：\n",
    "{\"role\": \"system\"/\"user\"/\"assistant\", \"content\": \"消息内容\"}\n",
    "\n",
    "这种格式与 OpenAI API 的格式一致，更易于使用\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 3：使用字典格式的消息（推荐）\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6c7b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"你是一个乐于助人的Python编程助手，擅长用简单易懂的方式解答问题。\"},\n",
    "    {\"role\": \"user\", \"content\": \"什么是Python解释器？\"}    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "354ae94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  system: 你是一个乐于助人的Python编程助手，擅长用简单易懂的方式解答问题。\n",
      "  user: 什么是Python解释器？\n"
     ]
    }
   ],
   "source": [
    "for msg in messages:\n",
    "    print(f\"  {msg['role']}: {msg['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b7f4de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI 回复:\n",
      "Python解释器是一种程序，它可以读取和执行用Python编程语言编写的代码。可以把它想象成一个翻译器，帮助计算机理解用Python编写的指令。\n",
      "\n",
      "当你编写Python代码时，你实际上是在编写人类可以阅读的文本文件。然而，计算机不能直接理解人类的语言，所以需要一种方法来将代码翻译成计算机可以理解的格式。这就是Python解释器的作用。\n",
      "\n",
      "以下是它的工作原理：\n",
      "\n",
      "1. **您编写代码**：您在文本编辑器或IDE（集成开发环境）中编写Python代码。\n",
      "2. **解释器读取代码**：当您运行代码时，Python解释器读取代码并分解为更小的部分，称为“语句”。\n",
      "3. **解释器执行代码**：解释器然后执行每个语句，按照您编写的顺序执行操作。\n",
      "4. **结果**：解释器显示结果，例如打印输出或显示图形。\n",
      "\n",
      "Python解释器就像一个中间人，帮助计算机理解您的代码并执行您期望它执行的操作。它是一款非常强大的工具，允许您编写、测试和运行Python程序。\n",
      "\n",
      "一些流行的Python解释器包括：\n",
      "\n",
      "* **CPython**：Python解释器的官方版本。\n",
      "* **PyPy**：一个更快、更高效的解释器，针对性能进行了优化。\n",
      "* **IPython**：一个交互式解释器，提供了额外的功能，如代码补全和调试工具。\n",
      "* **IDLE**：Python解释器附带的基本的交互式开发环境。\n",
      "\n",
      "我希望这有助于阐明Python解释器的作用！您有任何其他问题吗？\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(messages)\n",
    "\n",
    "print(f\"\\nAI 回复:\\n{response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "982999cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 示例 4：配置模型参数\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b0be51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 4：配置模型参数\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "示例4：配置模型参数\n",
    "\n",
    "init_chat_model 支持的常用参数：\n",
    "- temperature: 控制输出的随机性（0.0-2.0）\n",
    "    * 0.0: 最确定性，输出几乎不变\n",
    "    * 1.0: 默认值，平衡创造性和一致性\n",
    "    * 2.0: 最随机，最有创造性\n",
    "- max_tokens: 限制输出的最大 token 数量\n",
    "- model_kwargs: 传递给底层模型的额外参数\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 4：配置模型参数\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98a97e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个温度较低的模型（更确定性）\n",
    "model_deterministic = init_chat_model(\n",
    "    \"groq:llama-3.3-70b-versatile\",\n",
    "    temperature=0.0,  # 最确定性\n",
    "    max_tokens=100    # 限制输出长度\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7804fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"写一个关于春天的句子。\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f342e99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "提示语:\n",
      "写一个关于春天的句子。\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n提示语:\\n{prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a5efe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "生成结果 1:\n",
      "当最后一层冬雪融化时，春天的温暖微风带来了盛开的鲜花的甜美芬芳，给大地带来了一片充满生机和色彩的景象。\n",
      "\n",
      "生成结果 2:\n",
      "当最后一层冬雪融化时，春天的温暖微风带来了盛开的鲜花的甜美芬芳，给大地带来了一片充满生机和色彩的景象。\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    response = model_deterministic.invoke(prompt)\n",
    "    print(f\"\\n生成结果 {i+1}:\\n{response.content}\")\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2f66b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个温度较高的模型（更随机）\n",
    "model_creative = init_chat_model(\n",
    "    \"groq:llama-3.3-70b-versatile\",\n",
    "    temperature=1.5,  # 更有创造性\n",
    "    max_tokens=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ee46ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "生成结果 1:\n",
      "当最后一层冬季的霜融化时，春天的温暖和鲜艳的色彩开始萌发，带来了新生命和无限可能的承诺。\n",
      "\n",
      "生成结果 2:\n",
      "当最后一层冬季的霜融化时，春天带来了温暖的微风、盛开的鲜花和充满希望的新开始。\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    response = model_deterministic.invoke(prompt)\n",
    "    print(f\"\\n生成结果 {i+1}:\\n{response.content}\")\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2811580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 示例 5：理解 invoke 方法的返回值\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0e85301c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 5：invoke 返回值详解\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "示例5：深入理解 invoke 返回值\n",
    "\n",
    "invoke 方法返回一个 AIMessage 对象，包含：\n",
    "- content: 模型的文本回复\n",
    "- response_metadata: 响应元数据（如 token 使用量、模型信息等）\n",
    "- additional_kwargs: 额外的关键字参数\n",
    "- id: 消息 ID\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 5：invoke 返回值详解\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4536bd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(\"解释一下什么是递归？用一句话。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "accc81fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "递归是一种编程技术，其中函数通过反复调用自身来解决问题，每次调用都会带来更小的子问题，直到达到可以直接解决的基本情况。\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2fce63fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 40,\n",
       "  'prompt_tokens': 47,\n",
       "  'total_tokens': 87,\n",
       "  'completion_time': 0.189189004,\n",
       "  'completion_tokens_details': None,\n",
       "  'prompt_time': 0.004192432,\n",
       "  'prompt_tokens_details': None,\n",
       "  'queue_time': 0.053261558,\n",
       "  'total_time': 0.193381436},\n",
       " 'model_name': 'llama-3.3-70b-versatile',\n",
       " 'system_fingerprint': 'fp_c06d5113ec',\n",
       " 'service_tier': 'on_demand',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None,\n",
       " 'model_provider': 'groq'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "91af7ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_usage: {'completion_tokens': 40, 'prompt_tokens': 47, 'total_tokens': 87, 'completion_time': 0.189189004, 'completion_tokens_details': None, 'prompt_time': 0.004192432, 'prompt_tokens_details': None, 'queue_time': 0.053261558, 'total_time': 0.193381436}\n",
      "model_name: llama-3.3-70b-versatile\n",
      "system_fingerprint: fp_c06d5113ec\n",
      "service_tier: on_demand\n",
      "finish_reason: stop\n",
      "logprobs: None\n",
      "model_provider: groq\n"
     ]
    }
   ],
   "source": [
    "for key,value in response.response_metadata.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c90cee81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. 消息类型: AIMessage\n",
      "4. 消息 ID: lc_run--019b55f3-7b24-75e0-9d52-69338246a7e8-0\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n3. 消息类型: {type(response).__name__}\")\n",
    "print(f\"4. 消息 ID: {response.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5b9df222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='递归是一种编程技术，其中函数通过反复调用自身来解决问题，每次调用都会带来更小的子问题，直到达到可以直接解决的基本情况。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 47, 'total_tokens': 87, 'completion_time': 0.189189004, 'completion_tokens_details': None, 'prompt_time': 0.004192432, 'prompt_tokens_details': None, 'queue_time': 0.053261558, 'total_time': 0.193381436}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c06d5113ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b55f3-7b24-75e0-9d52-69338246a7e8-0', usage_metadata={'input_tokens': 47, 'output_tokens': 40, 'total_tokens': 87})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d84d7d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Token 使用情况:\n",
      "   提示 tokens: 47\n",
      "   完成 tokens: 40\n",
      "   总计 tokens: 87\n"
     ]
    }
   ],
   "source": [
    "# 检查 token 使用情况（如果可用）\n",
    "if \"token_usage\" in response.response_metadata:\n",
    "    usage = response.response_metadata[\"token_usage\"]\n",
    "    print(\"\\n5. Token 使用情况:\")\n",
    "    print(f\"   提示 tokens: {usage.get('prompt_tokens', 'N/A')}\")\n",
    "    print(f\"   完成 tokens: {usage.get('completion_tokens', 'N/A')}\")\n",
    "    print(f\"   总计 tokens: {usage.get('total_tokens', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "62df2067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion_tokens': 40,\n",
       " 'prompt_tokens': 47,\n",
       " 'total_tokens': 87,\n",
       " 'completion_time': 0.189189004,\n",
       " 'completion_tokens_details': None,\n",
       " 'prompt_time': 0.004192432,\n",
       " 'prompt_tokens_details': None,\n",
       " 'queue_time': 0.053261558,\n",
       " 'total_time': 0.193381436}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d54738ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 6：错误处理最佳实践\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "示例6：正确的错误处理\n",
    "\n",
    "在实际应用中，应该处理可能的错误：\n",
    "- API 密钥无效\n",
    "- 网络连接问题\n",
    "- 速率限制\n",
    "- 模型不可用\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 6：错误处理最佳实践\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "76e7b097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "递归是一种编程技术，其中一个函数重复调用自身，以便将复杂问题分解为较小的子问题，直到找到解决方案。\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = model.invoke(\"解释一下什么是递归？用一句话。\")\n",
    "    print(response.content)\n",
    "except ValueError as e:\n",
    "    print(f\"配置错误：{e}\")\n",
    "except ConnectionError as e:\n",
    "    print(f\"网络连接错误：{e}\")\n",
    "except Exception as e:\n",
    "    print(f\"未知错误：{type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bacbc3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 7：对比不同模型的输出\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "示例7：使用不同的模型\n",
    "\n",
    "LangChain 1.0 的优势之一是可以轻松切换不同的模型提供商\n",
    "只需要修改模型字符串：\n",
    "- \"groq:llama-3.3-70b-versatile\"\n",
    "- \"groq:mixtral-8x7b-32768\"\n",
    "- \"groq:gemma2-9b-it\"\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 7：对比不同模型的输出\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1db5120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提示词: 用一句话解释什么是机器学习。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Groq 上可用的不同模型\n",
    "models_to_test = [\n",
    "    \"groq:llama-3.3-70b-versatile\",\n",
    "    \"groq:mixtral-8x7b-32768\",\n",
    "]\n",
    "\n",
    "prompt = \"用一句话解释什么是机器学习。\"\n",
    "print(f\"提示词: {prompt}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e6f2c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用模型: groq:llama-3.3-70b-versatile\n",
      "----------------------------------------------------------------------\n",
      "回复: 机器学习是一种人工智能的子领域，它使计算机能够自动从数据中学习并做出预测或决策，而无需明确编程。\n",
      "\n",
      "使用模型: groq:mixtral-8x7b-32768\n",
      "----------------------------------------------------------------------\n",
      "回复: 机器学习是一种人工智能的子领域，涉及训练算法从数据中学习并根据这些数据做出预测或决策，而无需明确编程以执行特定任务。\n"
     ]
    }
   ],
   "source": [
    "for model_name in models_to_test:\n",
    "    try:\n",
    "        print(f\"\\n使用模型: {model_name}\")\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "        # model 已在文件开头通过 get_model() 初始化\n",
    "\n",
    "        response = model.invoke(prompt)\n",
    "        print(f\"回复: {response.content}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"模型 {model_name} 调用失败: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "32eb72bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " 所有示例运行完成！\n",
      "======================================================================\n",
      "\n",
      "下一步学习:\n",
      "  - 02_prompt_templates: 学习如何使用提示词模板\n",
      "  - 03_messages: 深入理解消息类型\n",
      "  - 04_custom_tools: 创建自定义工具\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" 所有示例运行完成！\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n下一步学习:\")\n",
    "print(\"  - 02_prompt_templates: 学习如何使用提示词模板\")\n",
    "print(\"  - 03_messages: 深入理解消息类型\")\n",
    "print(\"  - 04_custom_tools: 创建自定义工具\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb11c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain1.0-Langgraph1.0-Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
