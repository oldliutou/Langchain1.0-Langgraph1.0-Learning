{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff4f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6330854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c098ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b60971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not GROQ_API_KEY or GROQ_API_KEY == \"your_groq_api_key_here\":\n",
    "    raise ValueError(\n",
    "        \"\\n请先在 .env 文件中设置有效的 GROQ_API_KEY\\n\"\n",
    "        \"访问 https://console.groq.com/keys 获取免费密钥\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3495bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99aeff0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 32768, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x111c75160>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x111c75fd0>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = init_chat_model(\n",
    "    model =  \"groq:llama-3.3-70b-versatile\",\n",
    "    api_key=GROQ_API_KEY,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2f15bd",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# 示例 1：最简单的 LLM 调用\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61f7dc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 1：最简单的 LLM 调用\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    示例1：最简单的模型调用\n",
    "\n",
    "    核心概念：\n",
    "    - init_chat_model: 用于初始化聊天模型的统一接口\n",
    "    - invoke: 同步调用模型的方法\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 1：最简单的 LLM 调用\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "response = model.invoke([\n",
    "    {\"role\":\"user\",\"content\":\"用中文介绍一下LangChain是什么？\"}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2c4643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4d39149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain是一种基于人工智能的语言模型框架，旨在通过链式（Chain）结构来处理和生成自然语言。LangChain的核心思想是将语言理解和生成任务分解为一系列的小型、可组合的模块，每个模块负责处理语言的一个特定方面，例如词法分析、语法分析、语义分析等。通过将这些模块连接起来，LangChain可以实现复杂的语言处理和生成任务。\\n\\nLangChain的主要特点包括：\\n\\n1. **模块化设计**：LangChain采用模块化设计，每个模块负责处理语言的一个特定方面，可以根据需要组合和扩展。\\n2. **链式结构**：LangChain的模块通过链式结构连接，实现语言处理和生成任务的流程化。\\n3. **人工智能驱动**：LangChain使用人工智能技术，例如深度学习和自然语言处理算法，来实现语言理解和生成。\\n\\nLangChain可以应用于多种自然语言处理任务，例如：\\n\\n1. **语言翻译**：LangChain可以实现不同语言之间的翻译。\\n2. **文本生成**：LangChain可以生成自然语言文本，例如文章、故事等。\\n3. **问答系统**：LangChain可以实现问答系统，回答用户的问题。\\n4. **语言理解**：LangChain可以实现语言理解，例如情感分析、实体识别等。\\n\\n总之，LangChain是一种创新的人工智能语言模型框架，旨在通过链式结构来处理和生成自然语言，具有广泛的应用前景。'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4208479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)  # 查看返回对象的类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48ccfdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain 是一个开源的、基于人工智能的大语言模型框架，旨在为开发者提供一种简单高效的方式来构建和部署自己的语言模型应用。它支持多种大语言模型，包括 LLaMA、Stable Diffusion 等，提供了一套统一的 API 接口，帮助开发者轻松地将这些模型集成到自己的应用中。\\n\\nLangChain 的特点包括：\\n\\n1. **支持多种语言模型**：LangChain 支持多种大语言模型，包括 LLaMA、Stable Diffusion 等，开发者可以根据自己的需求选择合适的模型。\\n2. **统一的 API 接口**：LangChain 提供了一套统一的 API 接口，帮助开发者轻松地将语言模型集成到自己的应用中。\\n3. **简单易用**：LangChain 的设计目标是简单易用，开发者可以快速地构建和部署自己的语言模型应用。\\n4. **开源**：LangChain 是开源的，这意味着开发者可以自由地修改和扩展 LangChain 的功能。\\n\\nLangChain 的应用场景包括：\\n\\n1. **自然语言处理**：LangChain 可以用于自然语言处理任务，例如文本分类、情感分析、机器翻译等。\\n2. **对话系统**：LangChain 可以用于构建对话系统，例如聊天机器人、虚拟助手等。\\n3. **内容生成**：LangChain 可以用于内容生成任务，例如自动写作、内容创作等。\\n\\n总之，LangChain 是一个强大的工具，帮助开发者轻松地构建和部署自己的语言模型应用。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 367, 'prompt_tokens': 43, 'total_tokens': 410, 'completion_time': 1.160567064, 'completion_tokens_details': None, 'prompt_time': 0.013564051, 'prompt_tokens_details': None, 'queue_time': 0.206759763, 'total_time': 1.174131115}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c06d5113ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b2b37-bcdd-72e1-aaee-643ace45c0e6-0', usage_metadata={'input_tokens': 43, 'output_tokens': 367, 'total_tokens': 410})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d122326",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# 示例 2：使用消息列表进行对话\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "217248cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 2：使用消息列表构建对话\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    示例2：使用消息列表\n",
    "\n",
    "    核心概念：\n",
    "    - SystemMessage: 系统消息，用于设定 AI 的行为和角色\n",
    "    - HumanMessage: 用户消息\n",
    "    - AIMessage: AI 的回复消息\n",
    "\n",
    "    消息列表允许你构建多轮对话历史\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 2：使用消息列表构建对话\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59976bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b796784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建消息列表\n",
    "messages =[\n",
    "    SystemMessage(content=\"你是一个乐于助人的Python编程助手，擅长用简单易懂的方式解答问题。\"),\n",
    "    HumanMessage(content=\"什么是Python解释器？\")    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d38f4510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(content='你是一个乐于助人的Python编程助手，擅长用简单易懂的方式解答问题。', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a985b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='什么是Python解释器？', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f331819c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Python解释器是读取、解释和执行Python代码的程序。它就像一台翻译机，将您编写的Python代码转换为计算机可以理解的机器代码。\\n\\n可以把它想象成一个中间人，帮助您的计算机理解Python语言。以下是它的工作原理：\\n\\n1. **您编写Python代码**：您创建一个包含Python指令的文件，例如`print(\"Hello, World!\")`。\\n2. **解释器读取代码**：当您运行代码时，Python解释器会逐行读取文件。\\n3. **解释器解释代码**：解释器分析代码并将其转换为计算机可以理解的机器代码。\\n4. **解释器执行代码**：解释器执行转换后的机器代码，计算机执行指令，例如打印“Hello, World！”到屏幕上。\\n\\nPython解释器执行以下任务：\\n\\n* **语法检查**：解释器检查代码是否有错误或语法错误。\\n* **类型检查**：解释器检查变量的数据类型是否正确。\\n* **执行**：解释器运行代码，执行指令并提供输出。\\n\\nPython中有几个解释器可供选择，包括：\\n\\n* **CPython**：这是最广泛使用的Python解释器，也是默认的解释器。\\n* **PyPy**：这是一种更快的解释器，使用即时编译（JIT）来提高性能。\\n* **IronPython**：这是一种在.NET公共语言运行时上运行的Python解释器。\\n* **MicroPython**：这是一种针对微控制器和嵌入式系统进行优化的Python解释器。\\n\\n总体来说，Python解释器是一个强大的工具，允许您编写和运行Python代码，而无需担心底层细节。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 415, 'prompt_tokens': 67, 'total_tokens': 482, 'completion_time': 1.6767463569999999, 'completion_tokens_details': None, 'prompt_time': 0.002681062, 'prompt_tokens_details': None, 'queue_time': 0.079195055, 'total_time': 1.679427419}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_43d97c5965', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b2b3d-7006-7012-be18-3d0197673ae9-0', usage_metadata={'input_tokens': 67, 'output_tokens': 415, 'total_tokens': 482})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = model.invoke(messages)\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a95d0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个乐于助人的Python编程助手，擅长用简单易懂的方式解答问题。', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='什么是Python解释器？', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Python解释器是读取、解释和执行Python代码的程序。它就像一台翻译机，将您编写的Python代码转换为计算机可以理解的机器代码。\\n\\n可以把它想象成一个中间人，帮助您的计算机理解Python语言。以下是它的工作原理：\\n\\n1. **您编写Python代码**：您创建一个包含Python指令的文件，例如`print(\"Hello, World!\")`。\\n2. **解释器读取代码**：当您运行代码时，Python解释器会逐行读取文件。\\n3. **解释器解释代码**：解释器分析代码并将其转换为计算机可以理解的机器代码。\\n4. **解释器执行代码**：解释器执行转换后的机器代码，计算机执行指令，例如打印“Hello, World！”到屏幕上。\\n\\nPython解释器执行以下任务：\\n\\n* **语法检查**：解释器检查代码是否有错误或语法错误。\\n* **类型检查**：解释器检查变量的数据类型是否正确。\\n* **执行**：解释器运行代码，执行指令并提供输出。\\n\\nPython中有几个解释器可供选择，包括：\\n\\n* **CPython**：这是最广泛使用的Python解释器，也是默认的解释器。\\n* **PyPy**：这是一种更快的解释器，使用即时编译（JIT）来提高性能。\\n* **IronPython**：这是一种在.NET公共语言运行时上运行的Python解释器。\\n* **MicroPython**：这是一种针对微控制器和嵌入式系统进行优化的Python解释器。\\n\\n总体来说，Python解释器是一个强大的工具，允许您编写和运行Python代码，而无需担心底层细节。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 415, 'prompt_tokens': 67, 'total_tokens': 482, 'completion_time': 1.6767463569999999, 'completion_tokens_details': None, 'prompt_time': 0.002681062, 'prompt_tokens_details': None, 'queue_time': 0.079195055, 'total_time': 1.679427419}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_43d97c5965', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b2b3d-7006-7012-be18-3d0197673ae9-0', usage_metadata={'input_tokens': 67, 'output_tokens': 415, 'total_tokens': 482})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append(responses)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "803f5b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(HumanMessage(content=\"你能给我一个简单的例子吗？\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62439aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "继续对话...\n",
      "用户问题: 你能给我一个简单的例子吗？\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"继续对话...\")\n",
    "print(\"用户问题:\", messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b352402",
   "metadata": {},
   "outputs": [],
   "source": [
    "reponses2 = model.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8bc2b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是一个简单的例子，展示了Python解释器的工作原理：\n",
      "\n",
      "**例子：** 打印“Hello, World！”\n",
      "```python\n",
      "print(\"Hello, World!\")\n",
      "```\n",
      "**解释器的工作原理：**\n",
      "\n",
      "1. **读取代码**：解释器读取代码`print(\"Hello, World!\")`。\n",
      "2. **解释代码**：解释器分析代码并将其转换为机器代码，指示计算机打印字符串“Hello, World！”。\n",
      "3. **执行代码**：解释器执行机器代码，计算机打印“Hello, World！”到屏幕上。\n",
      "\n",
      "**输出：**\n",
      "```\n",
      "你好，世界！\n",
      "```\n",
      "在这个例子中，Python解释器：\n",
      "\n",
      "* 读取代码并理解 `print()` 函数的用途\n",
      "* 将代码转换为计算机可以理解的机器代码\n",
      "* 执行机器代码并打印输出到屏幕\n",
      "\n",
      "这只是一个简单的例子，但它演示了Python解释器如何读取、解释和执行Python代码的基本过程。\n"
     ]
    }
   ],
   "source": [
    "print(reponses2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 示例 3：使用字典格式的消息\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d247320b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 3：使用字典格式的消息（推荐）\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "示例3：使用字典格式的消息\n",
    "\n",
    "LangChain 1.0 支持更简洁的字典格式：\n",
    "{\"role\": \"system\"/\"user\"/\"assistant\", \"content\": \"消息内容\"}\n",
    "\n",
    "这种格式与 OpenAI API 的格式一致，更易于使用\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 3：使用字典格式的消息（推荐）\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6c7b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"你是一个乐于助人的Python编程助手，擅长用简单易懂的方式解答问题。\"},\n",
    "    {\"role\": \"user\", \"content\": \"什么是Python解释器？\"}    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "354ae94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  system: 你是一个乐于助人的Python编程助手，擅长用简单易懂的方式解答问题。\n",
      "  user: 什么是Python解释器？\n"
     ]
    }
   ],
   "source": [
    "for msg in messages:\n",
    "    print(f\"  {msg['role']}: {msg['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b7f4de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI 回复:\n",
      "Python 解释器是一种特殊的软件，能够读取、理解和执行用 Python 编程语言编写的代码。它就像一个翻译者，将您写的 Python 代码转换成计算机可以理解的机器语言。\n",
      "\n",
      "可以把Python解释器想象成一个忠实的助手，按照以下步骤工作：\n",
      "\n",
      "1. **读取代码**：解释器读取您编写的Python代码，通常是从文件中读取，扩展名为`.py`。\n",
      "2. **解析代码**：解释器分析代码，检查语法和结构，以确保其有效且正确。\n",
      "3. **执行代码**：解释器逐行执行代码，运行语句、函数和其他指令。\n",
      "4. **提供输出**：解释器显示代码的结果，例如打印文本、图像或其他数据。\n",
      "\n",
      "Python解释器的一些关键特性：\n",
      "\n",
      "* **动态类型**：Python是一种动态类型语言，这意味着您不需要在使用变量之前声明其数据类型。\n",
      "* **交互式**：Python解释器允许您以交互方式编写代码，可以立即看到结果。\n",
      "* **平台独立**：Python解释器可在多个平台上运行，包括Windows、macOS和Linux。\n",
      "\n",
      "一些流行的Python解释器包括：\n",
      "\n",
      "* **CPython**：Python的原始解释器，通常被称为“标准”解释器。\n",
      "* **PyPy**：一个用Python实现的正则解释器，专注于速度和性能。\n",
      "* **Anaconda**：一个流行的Python发行版，包括了许多用于数据科学、科学计算和机器学习的工具和库。\n",
      "* **IDLE**：一个基本的集成开发环境（IDE），附带Python，并提供一个简单的交互式环境来编写和执行代码。\n",
      "\n",
      "总体来说，Python解释器是一个强大的工具，它让您能够编写、运行和测试Python代码，使其成为学习和使用Python的必备组件！\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(messages)\n",
    "\n",
    "print(f\"\\nAI 回复:\\n{response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "982999cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 示例 4：配置模型参数\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b0be51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 4：配置模型参数\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "示例4：配置模型参数\n",
    "\n",
    "init_chat_model 支持的常用参数：\n",
    "- temperature: 控制输出的随机性（0.0-2.0）\n",
    "    * 0.0: 最确定性，输出几乎不变\n",
    "    * 1.0: 默认值，平衡创造性和一致性\n",
    "    * 2.0: 最随机，最有创造性\n",
    "- max_tokens: 限制输出的最大 token 数量\n",
    "- model_kwargs: 传递给底层模型的额外参数\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 4：配置模型参数\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "98a97e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个温度较低的模型（更确定性）\n",
    "model_deterministic = init_chat_model(\n",
    "    \"groq:llama-3.3-70b-versatile\",\n",
    "    temperature=0.0,  # 最确定性\n",
    "    max_tokens=100    # 限制输出长度\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7804fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"写一个关于春天的句子。\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f342e99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "提示语:\n",
      "写一个关于春天的句子。\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n提示语:\\n{prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a5efe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "生成结果 1:\n",
      "当最后一层冬季的霜融化时，春天带来了温暖的微风、盛开的鲜花和充满希望的新开始。\n",
      "\n",
      "生成结果 2:\n",
      "当最后的冬天雪花融化时，春天带来了温暖的微风、盛开的鲜花和充满希望的新开始。\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    response = model_deterministic.invoke(prompt)\n",
    "    print(f\"\\n生成结果 {i+1}:\\n{response.content}\")\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f66b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个温度较高的模型（更随机）\n",
    "model_creative = init_chat_model(\n",
    "    \"groq:llama-3.3-70b-versatile\",\n",
    "    temperature=1.5,  # 更有创造性\n",
    "    max_tokens=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ee46ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "生成结果 1:\n",
      "当最后一层冬季的霜融化时，春天带来了温暖的微风、盛开的鲜花和充满希望的新开始。\n",
      "\n",
      "生成结果 2:\n",
      "当最后的冬天雪花融化时，春天带来了温暖的微风、盛开的鲜花和充满希望的新开始。\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    response = model_deterministic.invoke(prompt)\n",
    "    print(f\"\\n生成结果 {i+1}:\\n{response.content}\")\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2811580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 示例 5：理解 invoke 方法的返回值\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e85301c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 5：invoke 返回值详解\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "示例5：深入理解 invoke 返回值\n",
    "\n",
    "invoke 方法返回一个 AIMessage 对象，包含：\n",
    "- content: 模型的文本回复\n",
    "- response_metadata: 响应元数据（如 token 使用量、模型信息等）\n",
    "- additional_kwargs: 额外的关键字参数\n",
    "- id: 消息 ID\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 5：invoke 返回值详解\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4536bd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(\"解释一下什么是递归？用一句话。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "accc81fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "递归是一种编程技术，其中一个函数会不断调用自身，直到达到某个终止条件，解决问题的更小版本来解决原始问题。\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2fce63fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 36,\n",
       "  'prompt_tokens': 47,\n",
       "  'total_tokens': 83,\n",
       "  'completion_time': 0.160333945,\n",
       "  'completion_tokens_details': None,\n",
       "  'prompt_time': 0.013292831,\n",
       "  'prompt_tokens_details': None,\n",
       "  'queue_time': 0.172888722,\n",
       "  'total_time': 0.173626776},\n",
       " 'model_name': 'llama-3.3-70b-versatile',\n",
       " 'system_fingerprint': 'fp_3272ea2d91',\n",
       " 'service_tier': 'on_demand',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None,\n",
       " 'model_provider': 'groq'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "91af7ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_usage: {'completion_tokens': 36, 'prompt_tokens': 47, 'total_tokens': 83, 'completion_time': 0.160333945, 'completion_tokens_details': None, 'prompt_time': 0.013292831, 'prompt_tokens_details': None, 'queue_time': 0.172888722, 'total_time': 0.173626776}\n",
      "model_name: llama-3.3-70b-versatile\n",
      "system_fingerprint: fp_3272ea2d91\n",
      "service_tier: on_demand\n",
      "finish_reason: stop\n",
      "logprobs: None\n",
      "model_provider: groq\n"
     ]
    }
   ],
   "source": [
    "for key,value in response.response_metadata.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c90cee81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. 消息类型: AIMessage\n",
      "4. 消息 ID: lc_run--019b2b5d-ebd1-7cc3-86d9-8592c2870c1e-0\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n3. 消息类型: {type(response).__name__}\")\n",
    "print(f\"4. 消息 ID: {response.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b9df222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='递归是一种编程技术，其中一个函数会不断调用自身，直到达到某个终止条件，解决问题的更小版本来解决原始问题。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 47, 'total_tokens': 83, 'completion_time': 0.160333945, 'completion_tokens_details': None, 'prompt_time': 0.013292831, 'prompt_tokens_details': None, 'queue_time': 0.172888722, 'total_time': 0.173626776}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3272ea2d91', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b2b5d-ebd1-7cc3-86d9-8592c2870c1e-0', usage_metadata={'input_tokens': 47, 'output_tokens': 36, 'total_tokens': 83})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d84d7d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Token 使用情况:\n",
      "   提示 tokens: 47\n",
      "   完成 tokens: 36\n",
      "   总计 tokens: 83\n"
     ]
    }
   ],
   "source": [
    "# 检查 token 使用情况（如果可用）\n",
    "if \"token_usage\" in response.response_metadata:\n",
    "    usage = response.response_metadata[\"token_usage\"]\n",
    "    print(\"\\n5. Token 使用情况:\")\n",
    "    print(f\"   提示 tokens: {usage.get('prompt_tokens', 'N/A')}\")\n",
    "    print(f\"   完成 tokens: {usage.get('completion_tokens', 'N/A')}\")\n",
    "    print(f\"   总计 tokens: {usage.get('total_tokens', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "62df2067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion_tokens': 36,\n",
       " 'prompt_tokens': 47,\n",
       " 'total_tokens': 83,\n",
       " 'completion_time': 0.160333945,\n",
       " 'completion_tokens_details': None,\n",
       " 'prompt_time': 0.013292831,\n",
       " 'prompt_tokens_details': None,\n",
       " 'queue_time': 0.172888722,\n",
       " 'total_time': 0.173626776}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d54738ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 6：错误处理最佳实践\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "示例6：正确的错误处理\n",
    "\n",
    "在实际应用中，应该处理可能的错误：\n",
    "- API 密钥无效\n",
    "- 网络连接问题\n",
    "- 速率限制\n",
    "- 模型不可用\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 6：错误处理最佳实践\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "76e7b097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "递归是一种编程技术，其中一个函数反复调用自身，直到达到基本情况或停止条件，允许它将复杂问题分解为较小的子问题。\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = model.invoke(\"解释一下什么是递归？用一句话。\")\n",
    "    print(response.content)\n",
    "except ValueError as e:\n",
    "    print(f\"配置错误：{e}\")\n",
    "except ConnectionError as e:\n",
    "    print(f\"网络连接错误：{e}\")\n",
    "except Exception as e:\n",
    "    print(f\"未知错误：{type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bacbc3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "示例 7：对比不同模型的输出\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "示例7：使用不同的模型\n",
    "\n",
    "LangChain 1.0 的优势之一是可以轻松切换不同的模型提供商\n",
    "只需要修改模型字符串：\n",
    "- \"groq:llama-3.3-70b-versatile\"\n",
    "- \"groq:mixtral-8x7b-32768\"\n",
    "- \"groq:gemma2-9b-it\"\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"示例 7：对比不同模型的输出\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d1db5120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提示词: 用一句话解释什么是机器学习。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Groq 上可用的不同模型\n",
    "models_to_test = [\n",
    "    \"groq:llama-3.3-70b-versatile\",\n",
    "    \"groq:mixtral-8x7b-32768\",\n",
    "]\n",
    "\n",
    "prompt = \"用一句话解释什么是机器学习。\"\n",
    "print(f\"提示词: {prompt}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f2c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "回复: 机器学习是一种人工智能（AI）的一个子集，它使计算机能够在不被明确编程的情况下自行学习和改进，从数据中自动获取模式和见解以做出预测或决策。\n",
      "----------------------------------------------------------------------\n",
      "回复: 机器学习是一种人工智能的分支，涉及训练算法从数据中学习和改进，使得计算机可以在不需要明确编程的情况下执行特定任务并随着时间的推移提高其性能。\n"
     ]
    }
   ],
   "source": [
    "for model_name in models_to_test:\n",
    "    try:\n",
    "        print(f\"\\n使用模型: {model_name}\")\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "        # model 已在文件开头通过 get_model() 初始化\n",
    "\n",
    "        response = model.invoke(prompt)\n",
    "        print(f\"回复: {response.content}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"模型 {model_name} 调用失败: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "32eb72bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " 所有示例运行完成！\n",
      "======================================================================\n",
      "\n",
      "下一步学习:\n",
      "  - 02_prompt_templates: 学习如何使用提示词模板\n",
      "  - 03_messages: 深入理解消息类型\n",
      "  - 04_custom_tools: 创建自定义工具\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" 所有示例运行完成！\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n下一步学习:\")\n",
    "print(\"  - 02_prompt_templates: 学习如何使用提示词模板\")\n",
    "print(\"  - 03_messages: 深入理解消息类型\")\n",
    "print(\"  - 04_custom_tools: 创建自定义工具\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb11c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain1.0-Langgraph1.0-Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
