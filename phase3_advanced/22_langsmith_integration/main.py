"""
æ¨¡å— 22ï¼šLangSmith é›†æˆ
å­¦ä¹ å¦‚ä½•è¿½è¸ªã€ç›‘æ§å’Œè°ƒè¯• LLM åº”ç”¨
"""

import os
import time
from typing import Optional
from dotenv import load_dotenv
from functools import wraps

from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.runnables import RunnableConfig

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

if not GROQ_API_KEY or GROQ_API_KEY == "your_groq_api_key_here":
    raise ValueError(
        "\nè¯·å…ˆåœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®æœ‰æ•ˆçš„ GROQ_API_KEY\n"
        "è®¿é—® https://console.groq.com/keys è·å–å…è´¹å¯†é’¥"
    )

# åˆå§‹åŒ–æ¨¡å‹
model = init_chat_model("groq:llama-3.3-70b-versatile", api_key=GROQ_API_KEY)

# ============================================================
# LangSmith é…ç½®
# ============================================================

def setup_langsmith(project_name: str = "langchain-study"):
    """é…ç½® LangSmith è¿½è¸ª"""
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ API Key
    api_key = os.environ.get("LANGSMITH_API_KEY")
    
    if api_key:
        os.environ["LANGSMITH_TRACING"] = "true"
        os.environ["LANGSMITH_PROJECT"] = project_name
        print(f"âœ… LangSmith å·²å¯ç”¨ (é¡¹ç›®: {project_name})")
        return True
    else:
        print("âš ï¸ æœªé…ç½® LANGSMITH_API_KEYï¼Œè¿½è¸ªåŠŸèƒ½æœªå¯ç”¨")
        print("   è¯·åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ ï¼šLANGSMITH_API_KEY=your_key")
        return False

# å°è¯•è®¾ç½® LangSmith
LANGSMITH_ENABLED = setup_langsmith()

# åˆå§‹åŒ–æ¨¡å‹

# ============================================================
# ç¤ºä¾‹ 1ï¼šåŸºæœ¬è¿½è¸ª
# ============================================================

def basic_tracing():
    """
    åŸºæœ¬çš„ LangSmith è¿½è¸ª
    å¯ç”¨è¿½è¸ªåï¼Œæ‰€æœ‰ LLM è°ƒç”¨è‡ªåŠ¨è®°å½•
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 1ï¼šåŸºæœ¬è¿½è¸ª")
    print("=" * 60)

    # ç®€å•è°ƒç”¨ - è‡ªåŠ¨è¿½è¸ª
    response = model.invoke("ä»€ä¹ˆæ˜¯ Pythonï¼Ÿç”¨ä¸€å¥è¯å›ç­”ã€‚")
    
    print(f"å“åº”: {response.content}")
    
    if LANGSMITH_ENABLED:
        print("\nğŸ“Š è¿½è¸ªæ•°æ®å·²å‘é€åˆ° LangSmith")
        print("   è®¿é—® https://smith.langchain.com æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯")
    
    return response

# ============================================================
# ç¤ºä¾‹ 2ï¼šå¸¦å…ƒæ•°æ®çš„è¿½è¸ª
# ============================================================

def tracing_with_metadata():
    """
    æ·»åŠ è‡ªå®šä¹‰å…ƒæ•°æ®åˆ°è¿½è¸ª
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 2ï¼šå¸¦å…ƒæ•°æ®çš„è¿½è¸ª")
    print("=" * 60)

    # åˆ›å»ºå¸¦å…ƒæ•°æ®çš„é…ç½®
    config = RunnableConfig(
        metadata={
            "user_id": "user_12345",
            "session_id": "session_67890",
            "request_type": "question",
            "app_version": "1.0.0"
        },
        tags=["study", "module_22", "demo"]
    )

    messages = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ã€‚ç”¨ä¸­æ–‡ç®€æ´å›ç­”ã€‚"),
        HumanMessage(content="LangSmith æœ‰ä»€ä¹ˆç”¨ï¼Ÿ")
    ]

    response = model.invoke(messages, config=config)
    
    print(f"å“åº”: {response.content}")
    print("\næ·»åŠ çš„å…ƒæ•°æ®:")
    print("  - user_id: user_12345")
    print("  - session_id: session_67890")
    print("  - tags: study, module_22, demo")
    
    return response

# ============================================================
# ç¤ºä¾‹ 3ï¼šæ€§èƒ½ç›‘æ§
# ============================================================

def performance_monitoring():
    """
    ç›‘æ§ LLM è°ƒç”¨çš„æ€§èƒ½æŒ‡æ ‡
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 3ï¼šæ€§èƒ½ç›‘æ§")
    print("=" * 60)

    questions = [
        "1+1ç­‰äºå‡ ï¼Ÿ",
        "è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Œç”¨100å­—ä»¥å†…ã€‚",
        "å†™ä¸€ä¸ªç®€çŸ­çš„ Python å‡½æ•°æ¥è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—ã€‚"
    ]

    results = []
    
    for i, question in enumerate(questions, 1):
        print(f"\næµ‹è¯• {i}: {question[:30]}...")
        
        start_time = time.time()
        
        # å¸¦æ€§èƒ½å…ƒæ•°æ®çš„è°ƒç”¨
        config = RunnableConfig(
            metadata={
                "test_id": f"perf_test_{i}",
                "complexity": "low" if i == 1 else ("medium" if i == 2 else "high")
            },
            tags=["performance_test"]
        )
        
        response = model.invoke(question, config=config)
        
        elapsed_time = time.time() - start_time
        
        # æå– token ä½¿ç”¨æƒ…å†µï¼ˆå¦‚æœæœ‰ï¼‰
        token_usage = getattr(response, 'usage_metadata', None)
        
        result = {
            "question": question[:30],
            "response_length": len(response.content),
            "elapsed_time": elapsed_time,
            "token_usage": token_usage
        }
        results.append(result)
        
        print(f"  å“åº”é•¿åº¦: {result['response_length']} å­—ç¬¦")
        print(f"  è€—æ—¶: {elapsed_time:.2f} ç§’")
        if token_usage:
            print(f"  Token ä½¿ç”¨: {token_usage}")

    # æ±‡æ€»
    print("\nğŸ“Š æ€§èƒ½æ±‡æ€»:")
    total_time = sum(r["elapsed_time"] for r in results)
    avg_time = total_time / len(results)
    print(f"  æ€»è€—æ—¶: {total_time:.2f} ç§’")
    print(f"  å¹³å‡è€—æ—¶: {avg_time:.2f} ç§’")
    
    return results

# ============================================================
# ç¤ºä¾‹ 4ï¼šé”™è¯¯è¿½è¸ª
# ============================================================

def error_tracking():
    """
    è¿½è¸ªå’Œè®°å½•é”™è¯¯
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 4ï¼šé”™è¯¯è¿½è¸ª")
    print("=" * 60)

    def risky_operation(query: str, should_fail: bool = False):
        """æ¨¡æ‹Ÿå¯èƒ½å¤±è´¥çš„æ“ä½œ"""
        config = RunnableConfig(
            metadata={
                "operation_type": "risky",
                "should_fail": should_fail
            },
            tags=["error_test"]
        )
        
        if should_fail:
            raise ValueError("æ¨¡æ‹Ÿçš„é”™è¯¯ï¼šè¯·æ±‚å‚æ•°æ— æ•ˆ")
        
        return model.invoke(query, config=config)

    # æˆåŠŸçš„è°ƒç”¨
    print("\næµ‹è¯• 1: æ­£å¸¸è°ƒç”¨")
    try:
        response = risky_operation("ä½ å¥½ï¼")
        print(f"  æˆåŠŸ: {response.content}")
    except Exception as e:
        print(f"  å¤±è´¥: {e}")

    # å¤±è´¥çš„è°ƒç”¨
    print("\næµ‹è¯• 2: ä¼šå¤±è´¥çš„è°ƒç”¨")
    try:
        response = risky_operation("ä½ å¥½ï¼", should_fail=True)
        print(f"  æˆåŠŸ: {response.content}")
    except Exception as e:
        print(f"  æ•è·é”™è¯¯: {e}")
        print("  ğŸ’¡ é”™è¯¯ä¿¡æ¯å·²è®°å½•åˆ° LangSmithï¼ˆå¦‚å·²å¯ç”¨ï¼‰")

# ============================================================
# ç¤ºä¾‹ 5ï¼šè‡ªå®šä¹‰è¿½è¸ªè£…é¥°å™¨
# ============================================================

def custom_traceable(name: str = None, tags: list = None):
    """
    è‡ªå®šä¹‰è¿½è¸ªè£…é¥°å™¨
    åœ¨æ²¡æœ‰ LangSmith çš„æƒ…å†µä¸‹ä¹Ÿæä¾›æœ¬åœ°è¿½è¸ª
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            func_name = name or func.__name__
            func_tags = tags or []
            
            start_time = time.time()
            print(f"  ğŸ” å¼€å§‹è¿½è¸ª: {func_name}")
            
            try:
                result = func(*args, **kwargs)
                elapsed = time.time() - start_time
                print(f"  âœ… å®Œæˆ: {func_name} ({elapsed:.2f}s)")
                return result
            except Exception as e:
                elapsed = time.time() - start_time
                print(f"  âŒ å¤±è´¥: {func_name} ({elapsed:.2f}s) - {e}")
                raise
        
        return wrapper
    return decorator

@custom_traceable(name="summarize_text", tags=["demo", "summarization"])
def summarize_text(text: str) -> str:
    """å¸¦è¿½è¸ªçš„æ–‡æœ¬æ‘˜è¦å‡½æ•°"""
    response = model.invoke(f"è¯·ç”¨ä¸€å¥è¯æ€»ç»“ï¼š{text}")
    return response.content

def custom_decorator_demo():
    """
    æ¼”ç¤ºè‡ªå®šä¹‰è¿½è¸ªè£…é¥°å™¨
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 5ï¼šè‡ªå®šä¹‰è¿½è¸ªè£…é¥°å™¨")
    print("=" * 60)

    text = "Python æ˜¯ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½è‘—ç§°ã€‚"
    
    summary = summarize_text(text)
    print(f"\nåŸæ–‡: {text}")
    print(f"æ‘˜è¦: {summary}")

# ============================================================
# ç¤ºä¾‹ 6ï¼šå¤šæ­¥éª¤è¿½è¸ª
# ============================================================

def multi_step_tracing():
    """
    è¿½è¸ªå¤šæ­¥éª¤å·¥ä½œæµ
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 6ï¼šå¤šæ­¥éª¤è¿½è¸ª")
    print("=" * 60)

    # æ¨¡æ‹Ÿä¸€ä¸ªå¤šæ­¥éª¤çš„ AI å·¥ä½œæµ
    parent_config = RunnableConfig(
        metadata={"workflow": "content_creation"},
        tags=["multi_step", "workflow"]
    )

    print("\nå¼€å§‹å†…å®¹åˆ›ä½œå·¥ä½œæµ...")

    # æ­¥éª¤ 1: ç”Ÿæˆå¤§çº²
    print("\n  æ­¥éª¤ 1: ç”Ÿæˆå¤§çº²")
    step1_config = RunnableConfig(
        metadata={**parent_config.get("metadata", {}), "step": "outline"},
        tags=["step_1"]
    )
    outline = model.invoke(
        "ä¸ºä¸€ç¯‡å…³äº'AI çš„æœªæ¥'çš„æ–‡ç« ç”Ÿæˆ3ç‚¹å¤§çº²ã€‚",
        config=step1_config
    )
    print(f"  å¤§çº²: {outline.content[:100]}...")

    # æ­¥éª¤ 2: æ‰©å±•ç¬¬ä¸€ç‚¹
    print("\n  æ­¥éª¤ 2: æ‰©å±•å†…å®¹")
    step2_config = RunnableConfig(
        metadata={**parent_config.get("metadata", {}), "step": "expand"},
        tags=["step_2"]
    )
    expanded = model.invoke(
        f"åŸºäºä»¥ä¸‹å¤§çº²ï¼Œæ‰©å±•ç¬¬ä¸€ç‚¹ï¼ˆ50å­—ä»¥å†…ï¼‰ï¼š\n{outline.content}",
        config=step2_config
    )
    print(f"  æ‰©å±•å†…å®¹: {expanded.content[:100]}...")

    # æ­¥éª¤ 3: æ¶¦è‰²
    print("\n  æ­¥éª¤ 3: æ¶¦è‰²æ–‡å­—")
    step3_config = RunnableConfig(
        metadata={**parent_config.get("metadata", {}), "step": "polish"},
        tags=["step_3"]
    )
    polished = model.invoke(
        f"è¯·æ¶¦è‰²ä»¥ä¸‹æ–‡å­—ï¼Œä½¿å…¶æ›´ä¸“ä¸šï¼š\n{expanded.content}",
        config=step3_config
    )
    print(f"  æœ€ç»ˆå†…å®¹: {polished.content}")

    print("\nâœ… å·¥ä½œæµå®Œæˆï¼æ‰€æœ‰æ­¥éª¤å·²è¿½è¸ªè®°å½•ã€‚")
    
    return polished.content

# ============================================================
# ä¸»ç¨‹åº
# ============================================================

if __name__ == "__main__":
    print("LangSmith é›†æˆæ•™ç¨‹")
    print("=" * 60)
    
    if not LANGSMITH_ENABLED:
        print("\nâš ï¸ æç¤ºï¼šé…ç½® LANGSMITH_API_KEY ä»¥å¯ç”¨å®Œæ•´çš„è¿½è¸ªåŠŸèƒ½")
        print("   æœ¬åœ°æ¼”ç¤ºä»å¯è¿è¡Œï¼Œä½†æ•°æ®ä¸ä¼šå‘é€åˆ° LangSmith\n")
    
    # è¿è¡Œç¤ºä¾‹
    basic_tracing()
    tracing_with_metadata()
    performance_monitoring()
    error_tracking()
    custom_decorator_demo()
    multi_step_tracing()
    
    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    if LANGSMITH_ENABLED:
        print("ğŸ“Š è®¿é—® https://smith.langchain.com æŸ¥çœ‹è¿½è¸ªæ•°æ®")
    print("=" * 60)
