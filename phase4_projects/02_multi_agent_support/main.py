"""
å¤šä»£ç†æ™ºèƒ½å®¢æœç³»ç»Ÿ - å®Œæ•´å®ç°

æœ¬æ¨¡å—å®ç°äº†ä¸€ä¸ªç”Ÿäº§çº§åˆ«çš„å¤šä»£ç†å®¢æœç³»ç»Ÿï¼ŒåŒ…æ‹¬ï¼š
- æ™ºèƒ½æ„å›¾åˆ†ç±»å’Œè·¯ç”±
- ä¸“ä¸šé¢†åŸŸä»£ç†ï¼ˆæŠ€æœ¯æ”¯æŒã€è®¢å•æœåŠ¡ã€äº§å“å’¨è¯¢ï¼‰
- å·¥å…·é›†æˆï¼ˆè®¢å•æŸ¥è¯¢ã€äº§å“æœç´¢ï¼‰
- æœåŠ¡è´¨é‡ç›‘æ§
- äººå·¥å‡çº§æœºåˆ¶
"""

import os
from typing import List, Dict, Any, Optional, TypedDict, Literal, Annotated
from dataclasses import dataclass
from datetime import datetime
import json
from dotenv import load_dotenv

# LangChain æ ¸å¿ƒå¯¼å…¥
from langchain.chat_models import init_chat_model
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.tools import tool

# LangGraph
from langgraph.graph import StateGraph, START, END
from langchain.agents import create_agent

# ==================== JSON è§£æè¾…åŠ©å‡½æ•° ====================

def safe_parse_json(text: str, default: dict = None) -> dict:
    """
    å®‰å…¨åœ°è§£æJSONæ–‡æœ¬
    
    å¤„ç†ï¼š
    - Markdown ä»£ç å— (```json ... ```)
    - å‰åçš„ç©ºç™½å­—ç¬¦
    - è§£æå¤±è´¥æ—¶è¿”å›é»˜è®¤å€¼
    """
    if default is None:
        default = {}
    
    content = text.strip()
    
    # ç§»é™¤ Markdown ä»£ç å—
    if "```json" in content:
        try:
            content = content.split("```json")[1].split("```")[0]
        except IndexError:
            pass
    elif "```" in content:
        try:
            parts = content.split("```")
            if len(parts) >= 2:
                content = parts[1]
        except IndexError:
            pass
    
    content = content.strip()
    
    try:
        return json.loads(content)
    except json.JSONDecodeError as e:
        print(f"   âš ï¸ JSON è§£æå¤±è´¥: {e}")
        return default



# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

if not GROQ_API_KEY or GROQ_API_KEY == "your_groq_api_key_here":
    raise ValueError(
        "\nè¯·å…ˆåœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®æœ‰æ•ˆçš„ GROQ_API_KEY\n"
        "è®¿é—® https://console.groq.com/keys è·å–å…è´¹å¯†é’¥"
    )

# åˆå§‹åŒ–æ¨¡å‹
model = init_chat_model("groq:llama-3.3-70b-versatile", api_key=GROQ_API_KEY)

# ==================== æ¨¡æ‹Ÿæ•°æ®åº“ ====================

MOCK_ORDERS = {
    "ORD001": {
        "status": "å·²å‘è´§",
        "product": "æ™ºèƒ½æ‰‹è¡¨ Pro",
        "price": 1299,
        "shipping": "é¡ºä¸°å¿«é€’",
        "tracking": "SF1234567890",
        "estimated_delivery": "2024-12-20"
    },
    "ORD002": {
        "status": "å¤„ç†ä¸­",
        "product": "æ— çº¿è€³æœº Max",
        "price": 899,
        "shipping": "å¾…å‘è´§",
        "tracking": None,
        "estimated_delivery": "2024-12-22"
    },
    "ORD003": {
        "status": "å·²å®Œæˆ",
        "product": "ä¾¿æºå……ç”µå®",
        "price": 199,
        "shipping": "å·²ç­¾æ”¶",
        "tracking": "YT9876543210",
        "estimated_delivery": "2024-12-15"
    }
}

MOCK_PRODUCTS = {
    "æ™ºèƒ½æ‰‹è¡¨ Pro": {
        "price": 1299,
        "features": ["å¿ƒç‡ç›‘æµ‹", "GPSå®šä½", "é˜²æ°´50ç±³", "7å¤©ç»­èˆª"],
        "stock": 50,
        "rating": 4.8
    },
    "æ— çº¿è€³æœº Max": {
        "price": 899,
        "features": ["ä¸»åŠ¨é™å™ª", "40å°æ—¶ç»­èˆª", "è“ç‰™5.3", "é€šè¯é™å™ª"],
        "stock": 120,
        "rating": 4.6
    },
    "ä¾¿æºå……ç”µå®": {
        "price": 199,
        "features": ["20000mAh", "å¿«å……æ”¯æŒ", "åŒUSBè¾“å‡º", "LEDæ˜¾ç¤º"],
        "stock": 200,
        "rating": 4.5
    },
    "æ™ºèƒ½éŸ³ç®±": {
        "price": 499,
        "features": ["è¯­éŸ³æ§åˆ¶", "å¤šæˆ¿é—´éŸ³é¢‘", "æ™ºèƒ½å®¶å±…è”åŠ¨", "Hi-FiéŸ³è´¨"],
        "stock": 80,
        "rating": 4.7
    }
}

FAQ_DATABASE = {
    "è¿æ¥é—®é¢˜": "è¯·å°è¯•ä»¥ä¸‹æ­¥éª¤ï¼š1) é‡å¯è®¾å¤‡ 2) æ£€æŸ¥è“ç‰™æ˜¯å¦å¼€å¯ 3) åˆ é™¤é…å¯¹è®°å½•åé‡æ–°é…å¯¹ 4) ç¡®ä¿è®¾å¤‡ç”µé‡å……è¶³",
    "å……ç”µé—®é¢˜": "å»ºè®®ä½¿ç”¨åŸè£…å……ç”µå™¨ï¼Œæ£€æŸ¥å……ç”µçº¿æ˜¯å¦æŸåã€‚å¦‚æœé—®é¢˜æŒç»­ï¼Œå¯èƒ½éœ€è¦æ›´æ¢ç”µæ± æˆ–é€ä¿®ã€‚",
    "è½¯ä»¶æ›´æ–°": "æ‰“å¼€è®¾å¤‡å¯¹åº”çš„APPï¼Œè¿›å…¥è®¾ç½®-å…³äº-æ£€æŸ¥æ›´æ–°ï¼ŒæŒ‰æç¤ºæ“ä½œå³å¯å®Œæˆæ›´æ–°ã€‚",
    "é€€è´§æ”¿ç­–": "æˆ‘ä»¬æ”¯æŒ7å¤©æ— ç†ç”±é€€è´§ï¼Œ30å¤©å†…æœ‰è´¨é‡é—®é¢˜å¯æ¢è´§ã€‚è¯·ä¿ç•™å¥½è´­ä¹°å‡­è¯å’Œå®Œæ•´åŒ…è£…ã€‚"
}

# ==================== å·¥å…·å®šä¹‰ ====================

@tool
def query_order(order_id: str) -> str:
    """æŸ¥è¯¢è®¢å•ä¿¡æ¯

    Args:
        order_id: è®¢å•å·ï¼Œæ ¼å¼å¦‚ ORD001
    
    Returns:
        è®¢å•è¯¦æƒ…çš„JSONå­—ç¬¦ä¸²
    """
    order = MOCK_ORDERS.get(order_id.upper())
    if order:
        return json.dumps(order, ensure_ascii=False, indent=2)
    return f"æœªæ‰¾åˆ°è®¢å• {order_id}"

@tool
def track_shipping(tracking_number: str) -> str:
    """æŸ¥è¯¢ç‰©æµä¿¡æ¯

    Args:
        tracking_number: ç‰©æµå•å·
    
    Returns:
        ç‰©æµçŠ¶æ€ä¿¡æ¯
    """
    # æ¨¡æ‹Ÿç‰©æµä¿¡æ¯
    if tracking_number.startswith("SF"):
        return f"é¡ºä¸°å¿«é€’ {tracking_number}: åŒ…è£¹å·²åˆ°è¾¾é…é€ç«™ï¼Œé¢„è®¡ä»Šæ—¥é€è¾¾"
    elif tracking_number.startswith("YT"):
        return f"åœ†é€šå¿«é€’ {tracking_number}: å·²ç­¾æ”¶"
    return f"æœªæ‰¾åˆ°ç‰©æµä¿¡æ¯ {tracking_number}"

@tool
def search_product(keyword: str) -> str:
    """æœç´¢äº§å“ä¿¡æ¯

    Args:
        keyword: äº§å“å…³é”®è¯
    
    Returns:
        åŒ¹é…äº§å“çš„ä¿¡æ¯
    """
    results = []
    for name, info in MOCK_PRODUCTS.items():
        if keyword.lower() in name.lower():
            results.append({
                "name": name,
                "price": f"Â¥{info['price']}",
                "features": info['features'],
                "rating": f"{info['rating']}åˆ†"
            })
    
    if results:
        return json.dumps(results, ensure_ascii=False, indent=2)
    return f"æœªæ‰¾åˆ°åŒ…å« '{keyword}' çš„äº§å“"

@tool
def get_product_recommendations(budget: int, category: str = "å…¨éƒ¨") -> str:
    """æ ¹æ®é¢„ç®—æ¨èäº§å“

    Args:
        budget: é¢„ç®—é‡‘é¢
        category: äº§å“ç±»åˆ«ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        æ¨èäº§å“åˆ—è¡¨
    """
    recommendations = []
    for name, info in MOCK_PRODUCTS.items():
        if info['price'] <= budget:
            recommendations.append({
                "name": name,
                "price": f"Â¥{info['price']}",
                "rating": info['rating']
            })
    
    # æŒ‰è¯„åˆ†æ’åº
    recommendations.sort(key=lambda x: float(x['rating']), reverse=True)
    
    if recommendations:
        return json.dumps(recommendations[:3], ensure_ascii=False, indent=2)
    return f"åœ¨é¢„ç®— Â¥{budget} å†…æš‚æ— æ¨èäº§å“"

@tool
def search_faq(problem_type: str) -> str:
    """æœç´¢å¸¸è§é—®é¢˜è§£ç­”

    Args:
        problem_type: é—®é¢˜ç±»å‹å…³é”®è¯
    
    Returns:
        ç›¸å…³FAQç­”æ¡ˆ
    """
    for key, answer in FAQ_DATABASE.items():
        if problem_type in key or key in problem_type:
            return f"ã€{key}ã€‘\n{answer}"
    return "æœªæ‰¾åˆ°ç›¸å…³FAQï¼Œå»ºè®®è”ç³»äººå·¥å®¢æœè·å–æ›´å¤šå¸®åŠ©ã€‚"

# ==================== çŠ¶æ€å®šä¹‰ ====================

class CustomerServiceState(TypedDict):
    """å®¢æœç³»ç»ŸçŠ¶æ€"""
    user_message: str                   # ç”¨æˆ·æ¶ˆæ¯
    chat_history: List[Dict[str, str]]  # å¯¹è¯å†å²
    intent: str                         # è¯†åˆ«çš„æ„å›¾
    confidence: float                   # æ„å›¾ç½®ä¿¡åº¦
    agent_response: str                 # ä»£ç†å›å¤
    needs_escalation: bool              # æ˜¯å¦éœ€è¦å‡çº§
    escalation_reason: str              # å‡çº§åŸå› 
    quality_score: float                # è´¨é‡è¯„åˆ†
    metadata: Dict[str, Any]            # å…ƒæ•°æ®

# ==================== ä»£ç†å®šä¹‰ ====================

class IntentClassifier:
    """æ„å›¾åˆ†ç±»å™¨"""
    
    def __init__(self):
        self.llm = model
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªæ„å›¾åˆ†ç±»ä¸“å®¶ã€‚åˆ†æç”¨æˆ·æ¶ˆæ¯å¹¶è¿”å›æ„å›¾åˆ†ç±»ã€‚

å¯é€‰æ„å›¾ï¼š
- tech_support: æŠ€æœ¯é—®é¢˜ã€æ•…éšœæ’é™¤ã€ä½¿ç”¨å¸®åŠ©
- order_service: è®¢å•æŸ¥è¯¢ã€ç‰©æµè·Ÿè¸ªã€é€€æ¢è´§
- product_consult: äº§å“å’¨è¯¢ã€ä»·æ ¼è¯¢é—®ã€åŠŸèƒ½ä»‹ç»
- escalate: æŠ•è¯‰ã€æ— æ³•ç†è§£ã€éœ€è¦äººå·¥

è¿”å›æ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{"intent": "æ„å›¾ç±»å‹", "confidence": 0.0-1.0, "reason": "åˆ†ç±»åŸå› "}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""),
            ("human", "{message}")
        ])
    
    def classify(self, message: str) -> Dict[str, Any]:
        """åˆ†ç±»ç”¨æˆ·æ„å›¾"""
        chain = self.prompt | self.llm | StrOutputParser()
        result = chain.invoke({"message": message})
        
        # ä½¿ç”¨å®‰å…¨çš„ JSON è§£æ
        default_result = {"intent": "escalate", "confidence": 0.5, "reason": "è§£æå¤±è´¥"}
        parsed = safe_parse_json(result, default_result)
        
        # ç¡®ä¿è¿”å›æœ‰æ•ˆçš„æ„å›¾
        if "intent" not in parsed:
            return default_result
        return parsed

class TechSupportAgent:
    """æŠ€æœ¯æ”¯æŒä»£ç†"""
    
    def __init__(self):
        self.llm = model
        self.tools = [search_faq]
        
        # å…ˆå®šä¹‰ system_prompt
        self.system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ”¯æŒå·¥ç¨‹å¸ˆã€‚ä½ çš„èŒè´£æ˜¯ï¼š
1. åˆ†æç”¨æˆ·é‡åˆ°çš„æŠ€æœ¯é—®é¢˜
2. æä¾›æ¸…æ™°çš„æ•…éšœæ’é™¤æ­¥éª¤
3. ä½¿ç”¨ search_faq å·¥å…·æŸ¥æ‰¾ç›¸å…³è§£å†³æ–¹æ¡ˆ
4. å¦‚æœé—®é¢˜è¶…å‡ºèƒ½åŠ›èŒƒå›´ï¼Œå»ºè®®å‡çº§åˆ°äººå·¥æ”¯æŒ

å›å¤è¦æ±‚ï¼š
- è¯­æ°”å‹å¥½ä¸“ä¸š
- æ­¥éª¤æ¸…æ™°æœ‰åº
- æä¾›å¤šä¸ªå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ"""
        
        # åˆ›å»º agent æ—¶ä¼ å…¥æ‰€æœ‰å‚æ•°
        self.agent = create_agent(
            model=self.llm,
            tools=self.tools,
            system_prompt=self.system_prompt
        )
    
    def handle(self, message: str, chat_history: List = None) -> str:
        """å¤„ç†æŠ€æœ¯æ”¯æŒè¯·æ±‚"""
        # ä¸éœ€è¦å†æ‹¼æ¥ system_promptï¼Œç›´æ¥ä¼ ç”¨æˆ·æ¶ˆæ¯
        messages = [{"role": "user", "content": message}]
        
        result = self.agent.invoke({"messages": messages})
        
        # æå–æœ€ç»ˆå›å¤
        if result["messages"]:
            return result["messages"][-1].content
        return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å¤„ç†æ‚¨çš„é—®é¢˜ã€‚å»ºè®®è”ç³»äººå·¥å®¢æœã€‚"

class OrderServiceAgent:
    """è®¢å•æœåŠ¡ä»£ç†"""
    
    def __init__(self):
        self.llm = model
        self.tools = [query_order, track_shipping]
        
        self.system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è®¢å•æœåŠ¡ä¸“å‘˜ã€‚ä½ çš„èŒè´£æ˜¯ï¼š
1. å¸®åŠ©ç”¨æˆ·æŸ¥è¯¢è®¢å•çŠ¶æ€
2. æä¾›ç‰©æµè·Ÿè¸ªä¿¡æ¯
3. è§£ç­”é€€æ¢è´§ç›¸å…³é—®é¢˜
4. ä½¿ç”¨å·¥å…·è·å–å‡†ç¡®ä¿¡æ¯

å›å¤è¦æ±‚ï¼š
- ä¿¡æ¯å‡†ç¡®å®Œæ•´
- ä¸»åŠ¨æä¾›ç›¸å…³ä¿¡æ¯
- å¦‚æœéœ€è¦è®¢å•å·ï¼Œç¤¼è²Œè¯¢é—®"""
        
        self.agent = create_agent(
            model=self.llm,
            tools=self.tools,
            system_prompt=self.system_prompt
        )
    
    def handle(self, message: str, chat_history: List = None) -> str:
        """å¤„ç†è®¢å•æœåŠ¡è¯·æ±‚"""
        messages = [{"role": "user", "content": message}]
        
        result = self.agent.invoke({"messages": messages})
        
        if result["messages"]:
            return result["messages"][-1].content
        return "æŠ±æ­‰ï¼Œè®¢å•æŸ¥è¯¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚è¯·ç¨åå†è¯•ã€‚"

class ProductConsultAgent:
    """äº§å“å’¨è¯¢ä»£ç†"""
    
    def __init__(self):
        self.llm = model
        self.tools = [search_product, get_product_recommendations]
        
        self.system_prompt = """ä½ æ˜¯ä¸€ä¸ªçƒ­æƒ…çš„äº§å“é¡¾é—®ã€‚ä½ çš„èŒè´£æ˜¯ï¼š
1. ä»‹ç»äº§å“åŠŸèƒ½å’Œç‰¹ç‚¹
2. æ ¹æ®ç”¨æˆ·éœ€æ±‚æ¨èåˆé€‚çš„äº§å“
3. è§£ç­”ä»·æ ¼å’Œåº“å­˜é—®é¢˜
4. ä½¿ç”¨å·¥å…·è·å–æœ€æ–°äº§å“ä¿¡æ¯

å›å¤è¦æ±‚ï¼š
- çƒ­æƒ…æœ‰äº²å’ŒåŠ›
- çªå‡ºäº§å“ä¼˜åŠ¿
- æ ¹æ®ç”¨æˆ·éœ€æ±‚æ¨è
- ä¸è¦è¿‡åº¦æ¨é”€"""
        
        self.agent = create_agent(
            model=self.llm,
            tools=self.tools,
            system_prompt=self.system_prompt
        )
    
    def handle(self, message: str, chat_history: List = None) -> str:
        """å¤„ç†äº§å“å’¨è¯¢è¯·æ±‚"""
        messages = [{"role": "user", "content": message}]
        
        result = self.agent.invoke({"messages": messages})
        
        if result["messages"]:
            return result["messages"][-1].content
        return "æŠ±æ­‰ï¼Œäº§å“ä¿¡æ¯æŸ¥è¯¢æš‚æ—¶ä¸å¯ç”¨ã€‚è¯·ç¨åå†è¯•ã€‚"

class QualityChecker:
    """è´¨é‡æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.llm = model
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯å®¢æœè´¨é‡æ£€æŸ¥ä¸“å®¶ã€‚è¯„ä¼°å®¢æœå›å¤çš„è´¨é‡ã€‚

è¯„ä¼°ç»´åº¦ï¼š
1. ç›¸å…³æ€§ï¼ˆ0-25åˆ†ï¼‰ï¼šå›å¤æ˜¯å¦é’ˆå¯¹ç”¨æˆ·é—®é¢˜
2. å®Œæ•´æ€§ï¼ˆ0-25åˆ†ï¼‰ï¼šæ˜¯å¦æä¾›äº†è¶³å¤Ÿçš„ä¿¡æ¯
3. ä¸“ä¸šæ€§ï¼ˆ0-25åˆ†ï¼‰ï¼šè¯­è¨€æ˜¯å¦ä¸“ä¸šå¾—ä½“
4. æœ‰ç”¨æ€§ï¼ˆ0-25åˆ†ï¼‰ï¼šæ˜¯å¦çœŸæ­£å¸®åŠ©åˆ°ç”¨æˆ·

è¿”å›æ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{"total_score": 0-100, "needs_escalation": true/false, "reason": "è¯„ä¼°è¯´æ˜"}}

åªè¿”å›JSONã€‚"""),
            ("human", """ç”¨æˆ·é—®é¢˜ï¼š{user_message}
å®¢æœå›å¤ï¼š{agent_response}

è¯·è¯„ä¼°ï¼š""")
        ])
    
    def check(self, user_message: str, agent_response: str) -> Dict[str, Any]:
        """æ£€æŸ¥å›å¤è´¨é‡"""
        chain = self.prompt | self.llm | StrOutputParser()
        result = chain.invoke({
            "user_message": user_message,
            "agent_response": agent_response
        })
        
        # ä½¿ç”¨å®‰å…¨çš„ JSON è§£æ
        default_result = {"total_score": 60, "needs_escalation": False, "reason": "è¯„ä¼°å®Œæˆ"}
        return safe_parse_json(result, default_result)

# ==================== å®¢æœç³»ç»Ÿä¸»ç±» ====================

class CustomerServiceSystem:
    """å¤šä»£ç†å®¢æœç³»ç»Ÿ"""
    
    def __init__(self):
        # åˆå§‹åŒ–ç»„ä»¶
        self.classifier = IntentClassifier()
        self.tech_agent = TechSupportAgent()
        self.order_agent = OrderServiceAgent()
        self.product_agent = ProductConsultAgent()
        self.quality_checker = QualityChecker()
        
        # æ„å»ºå·¥ä½œæµå›¾
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """æ„å»º LangGraph å·¥ä½œæµ"""
        
        def classify_intent(state: CustomerServiceState) -> CustomerServiceState:
            """åˆ†ç±»ç”¨æˆ·æ„å›¾"""
            print("ğŸ” åˆ†æç”¨æˆ·æ„å›¾...")
            result = self.classifier.classify(state["user_message"])
            
            state["intent"] = result.get("intent", "escalate")
            state["confidence"] = result.get("confidence", 0.5)
            
            print(f"   æ„å›¾: {state['intent']} (ç½®ä¿¡åº¦: {state['confidence']:.2f})")
            return state
        
        def route_to_agent(state: CustomerServiceState) -> Literal["tech_support", "order_service", "product_consult", "escalate"]:
            """è·¯ç”±åˆ°å¯¹åº”ä»£ç†"""
            intent = state["intent"]
            confidence = state["confidence"]
            
            # ä½ç½®ä¿¡åº¦ç›´æ¥å‡çº§
            if confidence < 0.6:
                return "escalate"
            
            if intent == "tech_support":
                return "tech_support"
            elif intent == "order_service":
                return "order_service"
            elif intent == "product_consult":
                return "product_consult"
            else:
                return "escalate"
        
        def tech_support_handler(state: CustomerServiceState) -> CustomerServiceState:
            """æŠ€æœ¯æ”¯æŒå¤„ç†"""
            print("ğŸ”§ æŠ€æœ¯æ”¯æŒä»£ç†å¤„ç†ä¸­...")
            response = self.tech_agent.handle(state["user_message"])
            state["agent_response"] = response
            return state
        
        def order_service_handler(state: CustomerServiceState) -> CustomerServiceState:
            """è®¢å•æœåŠ¡å¤„ç†"""
            print("ğŸ“¦ è®¢å•æœåŠ¡ä»£ç†å¤„ç†ä¸­...")
            response = self.order_agent.handle(state["user_message"])
            state["agent_response"] = response
            return state
        
        def product_consult_handler(state: CustomerServiceState) -> CustomerServiceState:
            """äº§å“å’¨è¯¢å¤„ç†"""
            print("ğŸ›ï¸ äº§å“å’¨è¯¢ä»£ç†å¤„ç†ä¸­...")
            response = self.product_agent.handle(state["user_message"])
            state["agent_response"] = response
            return state
        
        def escalate_handler(state: CustomerServiceState) -> CustomerServiceState:
            """å‡çº§å¤„ç†"""
            print("ğŸ‘¤ å‡çº§åˆ°äººå·¥å®¢æœ...")
            state["needs_escalation"] = True
            state["escalation_reason"] = "æ„å›¾è¯†åˆ«ç½®ä¿¡åº¦ä½æˆ–ç”¨æˆ·è¦æ±‚äººå·¥æœåŠ¡"
            state["agent_response"] = """éå¸¸æŠ±æ­‰ï¼Œæ‚¨çš„é—®é¢˜éœ€è¦äººå·¥å®¢æœæ¥å¤„ç†ã€‚

æˆ‘å·²ç»ä¸ºæ‚¨è½¬æ¥äººå·¥å®¢æœï¼Œè¯·ç¨å€™...

åœ¨ç­‰å¾…æœŸé—´ï¼Œæ‚¨ä¹Ÿå¯ä»¥ï¼š
1. æ‹¨æ‰“å®¢æœçƒ­çº¿ï¼š400-xxx-xxxx
2. å‘é€é‚®ä»¶è‡³ï¼šsupport@example.com
3. å·¥ä½œæ—¥ 9:00-18:00 åœ¨çº¿å®¢æœå“åº”æ›´å¿«

æ„Ÿè°¢æ‚¨çš„è€å¿ƒç­‰å¾…ï¼"""
            return state
        
        def quality_check(state: CustomerServiceState) -> CustomerServiceState:
            """è´¨é‡æ£€æŸ¥"""
            print("âœ… æ‰§è¡Œè´¨é‡æ£€æŸ¥...")
            result = self.quality_checker.check(
                state["user_message"],
                state["agent_response"]
            )
            
            state["quality_score"] = result.get("total_score", 0) / 100
            
            # è´¨é‡å¤ªä½éœ€è¦å‡çº§
            if result.get("needs_escalation", False) or state["quality_score"] < 0.6:
                state["needs_escalation"] = True
                state["escalation_reason"] = result.get("reason", "è´¨é‡æ£€æŸ¥æœªé€šè¿‡")
            
            print(f"   è´¨é‡è¯„åˆ†: {state['quality_score']:.2f}")
            return state
        
        def should_escalate(state: CustomerServiceState) -> Literal["escalate_final", "respond"]:
            """åˆ¤æ–­æ˜¯å¦éœ€è¦å‡çº§"""
            if state.get("needs_escalation", False):
                return "escalate_final"
            return "respond"
        
        def final_escalate(state: CustomerServiceState) -> CustomerServiceState:
            """æœ€ç»ˆå‡çº§å¤„ç†"""
            # ä¿ç•™åŸå§‹å›å¤ä½†æ·»åŠ å‡çº§æç¤º
            original_response = state["agent_response"]
            state["agent_response"] = f"""{original_response}

---
âš ï¸ ç³»ç»Ÿæç¤ºï¼šç”±äºæ­¤é—®é¢˜å¯èƒ½éœ€è¦æ›´ä¸“ä¸šçš„å¤„ç†ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨è”ç³»äººå·¥å®¢æœä»¥è·å¾—æ›´å¥½çš„æœåŠ¡ã€‚"""
            return state
        
        def respond(state: CustomerServiceState) -> CustomerServiceState:
            """æœ€ç»ˆå“åº”"""
            return state
        
        # æ„å»ºå›¾
        graph = StateGraph(CustomerServiceState)
        
        # æ·»åŠ èŠ‚ç‚¹
        graph.add_node("classify", classify_intent)
        graph.add_node("tech_support", tech_support_handler)
        graph.add_node("order_service", order_service_handler)
        graph.add_node("product_consult", product_consult_handler)
        graph.add_node("escalate", escalate_handler)
        graph.add_node("quality_check", quality_check)
        graph.add_node("escalate_final", final_escalate)
        graph.add_node("respond", respond)
        
        # æ·»åŠ è¾¹
        graph.add_edge(START, "classify")
        
        # æ¡ä»¶è·¯ç”±
        graph.add_conditional_edges(
            "classify",
            route_to_agent,
            {
                "tech_support": "tech_support",
                "order_service": "order_service",
                "product_consult": "product_consult",
                "escalate": "escalate"
            }
        )
        
        # ä»£ç†å¤„ç†åè¿›è¡Œè´¨é‡æ£€æŸ¥
        graph.add_edge("tech_support", "quality_check")
        graph.add_edge("order_service", "quality_check")
        graph.add_edge("product_consult", "quality_check")
        graph.add_edge("escalate", END)
        
        # è´¨é‡æ£€æŸ¥åçš„æ¡ä»¶è·¯ç”±
        graph.add_conditional_edges(
            "quality_check",
            should_escalate,
            {
                "escalate_final": "escalate_final",
                "respond": "respond"
            }
        )
        
        graph.add_edge("escalate_final", END)
        graph.add_edge("respond", END)
        
        return graph.compile()
    
    def handle_message(self, message: str, chat_history: List[Dict] = None) -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
        print(f"\n{'='*60}")
        print(f"ğŸ’¬ ç”¨æˆ·: {message}")
        print('='*60)
        
        initial_state = {
            "user_message": message,
            "chat_history": chat_history or [],
            "intent": "",
            "confidence": 0.0,
            "agent_response": "",
            "needs_escalation": False,
            "escalation_reason": "",
            "quality_score": 0.0,
            "metadata": {"timestamp": datetime.now().isoformat()}
        }
        
        result = self.graph.invoke(initial_state)
        
        return {
            "response": result["agent_response"],
            "intent": result["intent"],
            "confidence": result["confidence"],
            "quality_score": result["quality_score"],
            "escalated": result["needs_escalation"]
        }

# ==================== ä¸»ç¨‹åº ====================

def main():
    """æ¼”ç¤ºå¤šä»£ç†å®¢æœç³»ç»Ÿ"""
    
    print("=" * 60)
    print("ğŸ¤– å¤šä»£ç†æ™ºèƒ½å®¢æœç³»ç»Ÿæ¼”ç¤º")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    print("\nğŸ“¦ åˆå§‹åŒ–å®¢æœç³»ç»Ÿ...")
    system = CustomerServiceSystem()
    print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
    
    # æµ‹è¯•åœºæ™¯
    test_cases = [
        # æŠ€æœ¯æ”¯æŒåœºæ™¯
        {
            "category": "æŠ€æœ¯æ”¯æŒ",
            "messages": [
                "æˆ‘çš„è“ç‰™è€³æœºè¿æ¥ä¸ä¸Šæ‰‹æœºæ€ä¹ˆåŠï¼Ÿ",
                "æ‰‹è¡¨å……ç”µå¾ˆæ…¢ï¼Œæ˜¯ä¸æ˜¯åäº†ï¼Ÿ"
            ]
        },
        # è®¢å•æœåŠ¡åœºæ™¯
        {
            "category": "è®¢å•æœåŠ¡",
            "messages": [
                "å¸®æˆ‘æŸ¥ä¸€ä¸‹è®¢å• ORD001 çš„ç‰©æµçŠ¶æ€",
                "æˆ‘çš„è®¢å•ä»€ä¹ˆæ—¶å€™èƒ½åˆ°ï¼Ÿè®¢å•å·æ˜¯ ORD002"
            ]
        },
        # äº§å“å’¨è¯¢åœºæ™¯
        {
            "category": "äº§å“å’¨è¯¢",
            "messages": [
                "ä½ ä»¬æœ‰ä»€ä¹ˆæ™ºèƒ½æ‰‹è¡¨æ¨èå—ï¼Ÿé¢„ç®—1500å·¦å³",
                "æ— çº¿è€³æœºæœ‰ä»€ä¹ˆåŠŸèƒ½ï¼Ÿ"
            ]
        },
        # å‡çº§åœºæ™¯
        {
            "category": "äººå·¥å‡çº§",
            "messages": [
                "æˆ‘è¦æŠ•è¯‰ï¼è¿™æ˜¯ç¬¬ä¸‰æ¬¡å‡ºé—®é¢˜äº†ï¼",
                "æˆ‘æƒ³å’Œä½ ä»¬ç»ç†è°ˆè°ˆ"
            ]
        }
    ]
    
    # è¿è¡Œæµ‹è¯•
    for test in test_cases:
        print(f"\n{'='*60}")
        print(f"ğŸ“ æµ‹è¯•ç±»åˆ«: {test['category']}")
        print('='*60)
        
        for message in test["messages"]:
            result = system.handle_message(message)
            
            print("\nğŸ¤– å®¢æœå›å¤:")
            print(f"{result['response']}")
            print("\nğŸ“Š å¤„ç†ä¿¡æ¯:")
            print(f"   - æ„å›¾: {result['intent']}")
            print(f"   - ç½®ä¿¡åº¦: {result['confidence']:.2f}")
            print(f"   - è´¨é‡è¯„åˆ†: {result['quality_score']:.2f}")
            print(f"   - æ˜¯å¦å‡çº§: {'æ˜¯' if result['escalated'] else 'å¦'}")
            print("-" * 60)
    
    # äº¤äº’å¼æ¼”ç¤º
    print("\n" + "=" * 60)
    print("ğŸ’¬ äº¤äº’å¼å¯¹è¯æ¼”ç¤º")
    print("=" * 60)
    print("æç¤º: è¾“å…¥ 'quit' é€€å‡º")
    
    chat_history = []
    
    while True:
        user_input = input("\nğŸ‘¤ æ‚¨: ").strip()
        
        if user_input.lower() == 'quit':
            print("\næ„Ÿè°¢ä½¿ç”¨æ™ºèƒ½å®¢æœç³»ç»Ÿï¼Œå†è§ï¼ğŸ‘‹")
            break
        
        if not user_input:
            continue
        
        result = system.handle_message(user_input, chat_history)
        print(f"\nğŸ¤– å®¢æœ: {result['response']}")
        
        # æ›´æ–°å¯¹è¯å†å²
        chat_history.append({"role": "user", "content": user_input})
        chat_history.append({"role": "assistant", "content": result['response']})

if __name__ == "__main__":
    main()
