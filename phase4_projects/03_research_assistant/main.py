"""
é¡¹ç›®ä¸‰ï¼šæ™ºèƒ½ç ”ç©¶åŠ©æ‰‹

æœ¬é¡¹ç›®æ„å»ºä¸€ä¸ªå®Œæ•´çš„ç ”ç©¶åŠ©æ‰‹ç³»ç»Ÿï¼Œèƒ½å¤Ÿè¿›è¡Œå¤šæºä¿¡æ¯æ”¶é›†ã€
æ–‡çŒ®åˆ†æã€çŸ¥è¯†æ•´åˆå’Œç ”ç©¶æŠ¥å‘Šç”Ÿæˆã€‚

æ ¸å¿ƒç‰¹æ€§ï¼š
- å¤šæºä¿¡æ¯æ”¶é›†ï¼ˆæ¨¡æ‹Ÿç½‘ç»œæœç´¢ã€å­¦æœ¯æ•°æ®åº“ï¼‰
- æ–‡æ¡£åˆ†æå’Œå…³é”®ä¿¡æ¯æå–
- çŸ¥è¯†å›¾è°±æ„å»ºå’Œå…³è”åˆ†æ
- è‡ªåŠ¨åŒ–ç ”ç©¶æŠ¥å‘Šç”Ÿæˆ
- å¼•ç”¨ç®¡ç†å’Œæ¥æºè¿½è¸ª

Author: LangChain å­¦ä¹ é¡¹ç›®
Version: 1.0
"""

import os
import json
from typing import TypedDict, Literal, Annotated, Optional
from datetime import datetime
from dotenv import load_dotenv

from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, START, END, add_messages
from langgraph.checkpoint.memory import MemorySaver
from pydantic import BaseModel, Field

# ==================== JSON è§£æè¾…åŠ©å‡½æ•° ====================

def safe_parse_json(text: str, default: dict = None) -> dict:
    """
    å®‰å…¨åœ°è§£æJSONæ–‡æœ¬
    
    å¤„ç†ï¼š
    - Markdown ä»£ç å— (```json ... ```)
    - å‰åçš„ç©ºç™½å­—ç¬¦
    - è§£æå¤±è´¥æ—¶è¿”å›é»˜è®¤å€¼
    """
    if default is None:
        default = {}
    
    content = text.strip()
    
    # ç§»é™¤ Markdown ä»£ç å—
    if "```json" in content:
        try:
            content = content.split("```json")[1].split("```")[0]
        except IndexError:
            pass
    elif "```" in content:
        try:
            parts = content.split("```")
            if len(parts) >= 2:
                content = parts[1]
        except IndexError:
            pass
    
    content = content.strip()
    
    try:
        return json.loads(content)
    except json.JSONDecodeError as e:
        print(f"   âš ï¸ JSON è§£æå¤±è´¥: {e}")
        return default



# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

if not GROQ_API_KEY or GROQ_API_KEY == "your_groq_api_key_here":
    raise ValueError(
        "\nè¯·å…ˆåœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®æœ‰æ•ˆçš„ GROQ_API_KEY\n"
        "è®¿é—® https://console.groq.com/keys è·å–å…è´¹å¯†é’¥"
    )

# åˆå§‹åŒ–æ¨¡å‹
model = init_chat_model("groq:llama-3.3-70b-versatile", api_key=GROQ_API_KEY)

# ==================== æ•°æ®æ¨¡å‹å®šä¹‰ ====================

class SearchResult(BaseModel):
    """æœç´¢ç»“æœ"""
    title: str
    source: str
    url: str
    snippet: str
    relevance_score: float = Field(ge=0.0, le=1.0)
    publish_date: Optional[str] = None

class ResearchFinding(BaseModel):
    """ç ”ç©¶å‘ç°"""
    topic: str
    key_points: list[str]
    evidence: list[str]
    confidence: float = Field(ge=0.0, le=1.0)
    sources: list[str]

class ResearchOutline(BaseModel):
    """ç ”ç©¶å¤§çº²"""
    title: str
    abstract: str
    sections: list[str]
    key_questions: list[str]
    methodology: str

class Citation(BaseModel):
    """å¼•ç”¨"""
    id: str
    authors: list[str]
    title: str
    source: str
    year: int
    url: Optional[str] = None

class ResearchReport(BaseModel):
    """ç ”ç©¶æŠ¥å‘Š"""
    title: str
    executive_summary: str
    introduction: str
    methodology: str
    findings: list[str]
    analysis: str
    conclusions: list[str]
    recommendations: list[str]
    citations: list[Citation]
    generated_at: str

# ==================== çŠ¶æ€å®šä¹‰ ====================

class ResearchState(TypedDict):
    """ç ”ç©¶åŠ©æ‰‹çŠ¶æ€"""
    # æ¶ˆæ¯å†å²
    messages: Annotated[list, add_messages]
    
    # ç ”ç©¶ä¸»é¢˜
    research_topic: str
    research_questions: list[str]
    
    # æ”¶é›†çš„æ•°æ®
    search_results: list[dict]
    analyzed_sources: list[dict]
    
    # ç ”ç©¶è¿›å±•
    outline: dict
    findings: list[dict]
    
    # æŠ¥å‘Š
    draft_sections: dict
    final_report: str
    citations: list[dict]
    
    # çŠ¶æ€è¿½è¸ª
    current_phase: str
    iteration_count: int
    quality_score: float

# ==================== æ¨¡æ‹Ÿæ•°æ®æº ====================

# æ¨¡æ‹Ÿå­¦æœ¯æ•°æ®åº“
ACADEMIC_DATABASE = {
    "äººå·¥æ™ºèƒ½": [
        {
            "title": "æ·±åº¦å­¦ä¹ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨ç»¼è¿°",
            "authors": ["å¼ æ˜", "æå"],
            "source": "è®¡ç®—æœºå­¦æŠ¥",
            "year": 2024,
            "snippet": "æœ¬æ–‡ç»¼è¿°äº†æ·±åº¦å­¦ä¹ æŠ€æœ¯åœ¨NLPé¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼ŒåŒ…æ‹¬Transformeræ¶æ„ã€é¢„è®­ç»ƒæ¨¡å‹å’Œå¤§è¯­è¨€æ¨¡å‹çš„å‘å±•ã€‚",
            "url": "https://example.com/paper1"
        },
        {
            "title": "å¤§è¯­è¨€æ¨¡å‹çš„æ¶Œç°èƒ½åŠ›ç ”ç©¶",
            "authors": ["ç‹å¼º", "èµµä¸½"],
            "source": "äººå·¥æ™ºèƒ½ç ”ç©¶",
            "year": 2024,
            "snippet": "ç ”ç©¶å‘ç°ï¼Œå½“æ¨¡å‹è§„æ¨¡è¶…è¿‡ä¸€å®šé˜ˆå€¼æ—¶ï¼Œä¼šå‡ºç°æ€ç»´é“¾æ¨ç†ã€ä¸Šä¸‹æ–‡å­¦ä¹ ç­‰æ¶Œç°èƒ½åŠ›ã€‚",
            "url": "https://example.com/paper2"
        },
        {
            "title": "AI Agentç³»ç»Ÿçš„è®¾è®¡ä¸å®ç°",
            "authors": ["åˆ˜ä¼Ÿ", "é™ˆé™"],
            "source": "è½¯ä»¶å·¥ç¨‹å­¦æŠ¥",
            "year": 2024,
            "snippet": "æå‡ºäº†ä¸€ç§åŸºäºLLMçš„æ™ºèƒ½ä½“æ¶æ„ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨ã€è§„åˆ’å’Œå¤šæ™ºèƒ½ä½“åä½œã€‚",
            "url": "https://example.com/paper3"
        }
    ],
    "æ°”å€™å˜åŒ–": [
        {
            "title": "å…¨çƒæ°”å€™å˜åŒ–å¯¹å†œä¸šçš„å½±å“è¯„ä¼°",
            "authors": ["å­™æ¶›", "å‘¨æ˜"],
            "source": "ç¯å¢ƒç§‘å­¦å­¦æŠ¥",
            "year": 2024,
            "snippet": "ç ”ç©¶è¡¨æ˜ï¼Œæ°”å€™å˜åŒ–å¯¼è‡´å…¨çƒä¸»è¦å†œä½œç‰©äº§é‡æ³¢åŠ¨åŠ å‰§ï¼Œæç«¯å¤©æ°”äº‹ä»¶é¢‘å‘ã€‚",
            "url": "https://example.com/paper4"
        },
        {
            "title": "ç¢³ä¸­å’Œè·¯å¾„ä¸æŠ€æœ¯åˆ›æ–°",
            "authors": ["å´èŠ³", "éƒ‘å¼º"],
            "source": "èƒ½æºç ”ç©¶",
            "year": 2024,
            "snippet": "åˆ†æäº†å®ç°ç¢³ä¸­å’Œç›®æ ‡çš„æŠ€æœ¯è·¯å¾„ï¼ŒåŒ…æ‹¬å¯å†ç”Ÿèƒ½æºã€ç¢³æ•é›†å’Œå‚¨èƒ½æŠ€æœ¯ã€‚",
            "url": "https://example.com/paper5"
        }
    ],
    "é‡å­è®¡ç®—": [
        {
            "title": "é‡å­è®¡ç®—æœºçš„å‘å±•ç°çŠ¶ä¸æŒ‘æˆ˜",
            "authors": ["é»„ä¼Ÿ", "æ—å°æ˜"],
            "source": "ç‰©ç†å­¦æŠ¥",
            "year": 2024,
            "snippet": "ç»¼è¿°äº†è¶…å¯¼ã€ç¦»å­é˜±å’Œå…‰é‡å­ç­‰æŠ€æœ¯è·¯çº¿çš„æœ€æ–°è¿›å±•ï¼Œè®¨è®ºäº†é‡å­çº é”™å’Œæ‰©å±•æ€§æŒ‘æˆ˜ã€‚",
            "url": "https://example.com/paper6"
        }
    ]
}

# æ¨¡æ‹Ÿç½‘ç»œæœç´¢ç»“æœ
WEB_SEARCH_RESULTS = {
    "äººå·¥æ™ºèƒ½": [
        {
            "title": "OpenAIå‘å¸ƒGPT-5ï¼šAIèƒ½åŠ›å†æ¬¡é£è·ƒ",
            "source": "ç§‘æŠ€æ–°é—»ç½‘",
            "url": "https://news.example.com/ai1",
            "snippet": "æœ€æ–°å‘å¸ƒçš„GPT-5åœ¨æ¨ç†èƒ½åŠ›å’Œå¤šæ¨¡æ€ç†è§£ä¸Šå–å¾—é‡å¤§çªç ´...",
            "date": "2024-12"
        },
        {
            "title": "ä¼ä¸šAIåº”ç”¨è°ƒæŸ¥æŠ¥å‘Šï¼š85%ä¼ä¸šå·²éƒ¨ç½²AIç³»ç»Ÿ",
            "source": "å•†ä¸šå‘¨åˆŠ",
            "url": "https://news.example.com/ai2",
            "snippet": "è°ƒæŸ¥æ˜¾ç¤ºï¼Œå¤§å¤šæ•°ä¼ä¸šå·²åœ¨å®¢æœã€åˆ†æå’Œè‡ªåŠ¨åŒ–é¢†åŸŸåº”ç”¨AIæŠ€æœ¯...",
            "date": "2024-11"
        }
    ],
    "æ°”å€™å˜åŒ–": [
        {
            "title": "COP29å³°ä¼šè¾¾æˆæ–°æ°”å€™åè®®",
            "source": "ç¯çƒæ—¶æŠ¥",
            "url": "https://news.example.com/climate1",
            "snippet": "å„å›½æ‰¿è¯ºåŠ é€Ÿå‡æ’è¿›ç¨‹ï¼Œå‘è¾¾å›½å®¶å°†æä¾›æ›´å¤šæ°”å€™èèµ„...",
            "date": "2024-11"
        }
    ],
    "é‡å­è®¡ç®—": [
        {
            "title": "Googleå®ç°é‡å­éœ¸æƒ2.0ï¼š1åˆ†é’Ÿå®Œæˆè¶…ç®—1ä¸‡å¹´ä»»åŠ¡",
            "source": "ç§‘å­¦æ—¥æŠ¥",
            "url": "https://news.example.com/quantum1",
            "snippet": "æ–°å‹é‡å­å¤„ç†å™¨åœ¨ç‰¹å®šè®¡ç®—ä»»åŠ¡ä¸Šå±•ç°å‡ºå‹å€’æ€§ä¼˜åŠ¿...",
            "date": "2024-10"
        }
    ]
}

# ==================== å·¥å…·å‡½æ•° ====================

def search_academic_database(topic: str, max_results: int = 5) -> list[dict]:
    """æœç´¢å­¦æœ¯æ•°æ®åº“"""
    results = []
    
    for key, papers in ACADEMIC_DATABASE.items():
        if topic.lower() in key.lower() or key.lower() in topic.lower():
            for paper in papers[:max_results]:
                results.append({
                    **paper,
                    "type": "academic",
                    "relevance_score": 0.9
                })
    
    # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œè¿”å›éƒ¨åˆ†ç›¸å…³ç»“æœ
    if not results:
        for papers in ACADEMIC_DATABASE.values():
            results.extend(papers[:2])
            if len(results) >= max_results:
                break
        for r in results:
            r["relevance_score"] = 0.5
    
    return results[:max_results]

def search_web(topic: str, max_results: int = 5) -> list[dict]:
    """æ¨¡æ‹Ÿç½‘ç»œæœç´¢"""
    results = []
    
    for key, items in WEB_SEARCH_RESULTS.items():
        if topic.lower() in key.lower() or key.lower() in topic.lower():
            for item in items[:max_results]:
                results.append({
                    **item,
                    "type": "web",
                    "relevance_score": 0.8
                })
    
    if not results:
        for items in WEB_SEARCH_RESULTS.values():
            results.extend(items[:2])
            if len(results) >= max_results:
                break
        for r in results:
            r["relevance_score"] = 0.4
    
    return results[:max_results]

def format_citation(source: dict, citation_id: str) -> Citation:
    """æ ¼å¼åŒ–å¼•ç”¨"""
    return Citation(
        id=citation_id,
        authors=source.get("authors", ["Unknown"]),
        title=source.get("title", "Untitled"),
        source=source.get("source", "Unknown"),
        year=source.get("year", 2024),
        url=source.get("url")
    )

# ==================== æ™ºèƒ½ä½“èŠ‚ç‚¹ ====================

def create_research_assistant():
    """åˆ›å»ºç ”ç©¶åŠ©æ‰‹ç³»ç»Ÿ"""
    
    # ---- ç ”ç©¶è§„åˆ’èŠ‚ç‚¹ ----
    def planning_node(state: ResearchState) -> dict:
        """è§„åˆ’ç ”ç©¶æ–¹å‘å’Œå¤§çº²"""
        print("\n" + "="*50)
        print("ğŸ“‹ ç ”ç©¶è§„åˆ’é˜¶æ®µ...")
        
        topic = state["research_topic"]
        
        # ä¿®æ”¹promptï¼Œæ˜ç¡®è¦æ±‚JSONæ ¼å¼
        planning_prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±ç ”ç©¶å‘˜ã€‚è¯·ä¸ºä»¥ä¸‹ç ”ç©¶ä¸»é¢˜åˆ¶å®šç ”ç©¶è®¡åˆ’ã€‚

ç ”ç©¶ä¸»é¢˜ï¼š{topic}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼ˆä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹ï¼‰ï¼š
{{
    "title": "ç ”ç©¶æ ‡é¢˜",
    "abstract": "æ‘˜è¦ï¼ˆ100å­—ä»¥å†…ï¼‰",
    "sections": ["ç« èŠ‚1", "ç« èŠ‚2", "ç« èŠ‚3", "ç« èŠ‚4"],
    "key_questions": ["é—®é¢˜1", "é—®é¢˜2", "é—®é¢˜3"],
    "methodology": "ç ”ç©¶æ–¹æ³•è®ºæè¿°"
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""
        
        response = model.invoke([HumanMessage(content=planning_prompt)])
        
        # ä½¿ç”¨å®‰å…¨çš„ JSON è§£æï¼Œæä¾›é»˜è®¤å€¼
        default_outline = {
            "title": f"{topic}ç ”ç©¶",
            "abstract": f"æœ¬ç ”ç©¶æ¢è®¨{topic}çš„ç›¸å…³é—®é¢˜ã€‚",
            "sections": ["å¼•è¨€", "æ–‡çŒ®ç»¼è¿°", "ç ”ç©¶æ–¹æ³•", "ç»“æœåˆ†æ", "ç»“è®º"],
            "key_questions": [f"{topic}çš„ç°çŠ¶å¦‚ä½•ï¼Ÿ", f"{topic}çš„å‘å±•è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ", f"{topic}é¢ä¸´å“ªäº›æŒ‘æˆ˜ï¼Ÿ"],
            "methodology": "æ–‡çŒ®ç ”ç©¶ä¸æ¡ˆä¾‹åˆ†æç›¸ç»“åˆ"
        }
        
        outline_data = safe_parse_json(response.content, default_outline)
        
        # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨
        for key in default_outline:
            if key not in outline_data:
                outline_data[key] = default_outline[key]
        
        print(f"   æ ‡é¢˜: {outline_data.get('title', 'N/A')}")
        print(f"   ç« èŠ‚æ•°: {len(outline_data.get('sections', []))}")
        print(f"   ç ”ç©¶é—®é¢˜æ•°: {len(outline_data.get('key_questions', []))}")
        
        return {
            "outline": outline_data,
            "research_questions": outline_data.get("key_questions", []),
            "current_phase": "information_gathering",
            "messages": [AIMessage(content=f"ç ”ç©¶è®¡åˆ’å·²åˆ¶å®šï¼š{outline_data.get('title', topic)}")]
        }
    
    # ---- ä¿¡æ¯æ”¶é›†èŠ‚ç‚¹ ----
    def information_gathering_node(state: ResearchState) -> dict:
        """æ”¶é›†ç›¸å…³ä¿¡æ¯"""
        print("\n" + "-"*50)
        print("ğŸ” ä¿¡æ¯æ”¶é›†é˜¶æ®µ...")
        
        topic = state["research_topic"]
        
        # æœç´¢å­¦æœ¯æ•°æ®åº“
        print("   æœç´¢å­¦æœ¯æ•°æ®åº“...")
        academic_results = search_academic_database(topic)
        print(f"   æ‰¾åˆ° {len(academic_results)} ç¯‡å­¦æœ¯æ–‡çŒ®")
        
        # æœç´¢ç½‘ç»œ
        print("   æœç´¢ç½‘ç»œèµ„æº...")
        web_results = search_web(topic)
        print(f"   æ‰¾åˆ° {len(web_results)} æ¡ç½‘ç»œç»“æœ")
        
        all_results = academic_results + web_results
        
        # æ˜¾ç¤ºæœç´¢ç»“æœ
        print("\n   æ”¶é›†åˆ°çš„èµ„æ–™ï¼š")
        for i, result in enumerate(all_results[:5], 1):
            print(f"   {i}. [{result['type']}] {result['title']}")
        
        return {
            "search_results": all_results,
            "current_phase": "analysis",
            "messages": [AIMessage(content=f"å·²æ”¶é›† {len(all_results)} æ¡ç›¸å…³èµ„æ–™")]
        }
    
    # ---- ä¿¡æ¯åˆ†æèŠ‚ç‚¹ ----
    def analysis_node(state: ResearchState) -> dict:
        """åˆ†ææ”¶é›†çš„ä¿¡æ¯"""
        print("\n" + "-"*50)
        print("ğŸ“Š ä¿¡æ¯åˆ†æé˜¶æ®µ...")
        
        topic = state["research_topic"]
        search_results = state.get("search_results", [])
        research_questions = state.get("research_questions", [])
        
        # æ•´ç†èµ„æ–™æ‘˜è¦
        sources_summary = "\n".join([
            f"- {r['title']}: {r.get('snippet', '')}"
            for r in search_results[:8]
        ])
        
        analysis_prompt = f"""åŸºäºä»¥ä¸‹èµ„æ–™ï¼Œå¯¹ç ”ç©¶ä¸»é¢˜è¿›è¡Œæ·±å…¥åˆ†æï¼š

ç ”ç©¶ä¸»é¢˜ï¼š{topic}

æ ¸å¿ƒé—®é¢˜ï¼š
{chr(10).join(f'- {q}' for q in research_questions)}

æ”¶é›†çš„èµ„æ–™ï¼š
{sources_summary}

è¯·æä¾›ï¼š
1. å¯¹æ¯ä¸ªæ ¸å¿ƒé—®é¢˜çš„åˆæ­¥å›ç­”
2. èµ„æ–™ä¸­çš„å…³é”®å‘ç°
3. ä¸åŒè§‚ç‚¹çš„æ¯”è¾ƒ
4. ä¿¡æ¯ç©ºç™½å’Œéœ€è¦è¿›ä¸€æ­¥ç ”ç©¶çš„æ–¹å‘

ç”¨JSONæ ¼å¼è¾“å‡ºï¼ŒåŒ…å« key_findings, analysis_points, information_gaps ä¸‰ä¸ªå­—æ®µã€‚"""
        
        response = model.invoke([HumanMessage(content=analysis_prompt)])
        
        # è§£æåˆ†æç»“æœï¼ˆç®€åŒ–å¤„ç†ï¼‰
        findings = [
            {
                "topic": topic,
                "key_points": [
                    "å¤šé¡¹ç ”ç©¶è¡¨æ˜è¯¥é¢†åŸŸæ­£åœ¨å¿«é€Ÿå‘å±•",
                    "å­˜åœ¨å¤šç§æŠ€æœ¯è·¯çº¿å’Œæ–¹æ³•è®º",
                    "å®é™…åº”ç”¨æ¡ˆä¾‹å¢åŠ "
                ],
                "confidence": 0.85,
                "sources": [r["title"] for r in search_results[:3]]
            }
        ]
        
        analyzed_sources = []
        for i, result in enumerate(search_results[:6]):
            analyzed_sources.append({
                "id": f"src_{i+1}",
                "title": result["title"],
                "key_takeaways": result.get("snippet", "")[:100],
                "relevance": result.get("relevance_score", 0.5)
            })
        
        print(f"   åˆ†æäº† {len(analyzed_sources)} ä¸ªæ¥æº")
        print(f"   æå–äº† {len(findings)} ç»„å…³é”®å‘ç°")
        
        return {
            "findings": findings,
            "analyzed_sources": analyzed_sources,
            "current_phase": "synthesis",
            "messages": [AIMessage(content=response.content)]
        }
    
    # ---- çŸ¥è¯†ç»¼åˆèŠ‚ç‚¹ ----
    def synthesis_node(state: ResearchState) -> dict:
        """ç»¼åˆçŸ¥è¯†ï¼Œç”ŸæˆæŠ¥å‘Šåˆç¨¿"""
        print("\n" + "-"*50)
        print("ğŸ”® çŸ¥è¯†ç»¼åˆé˜¶æ®µ...")
        
        topic = state["research_topic"]
        outline = state.get("outline", {})
        findings = state.get("findings", [])
        analyzed_sources = state.get("analyzed_sources", [])
        
        # ç”Ÿæˆå„ç« èŠ‚å†…å®¹
        sections = outline.get("sections", ["å¼•è¨€", "èƒŒæ™¯", "å‘ç°", "ç»“è®º"])
        
        synthesis_prompt = f"""åŸºäºç ”ç©¶å¤§çº²å’Œåˆ†æç»“æœï¼Œä¸ºä»¥ä¸‹ç ”ç©¶æŠ¥å‘Šç”Ÿæˆå†…å®¹ï¼š

ç ”ç©¶ä¸»é¢˜ï¼š{topic}

ç ”ç©¶å¤§çº²ï¼š
- æ ‡é¢˜: {outline.get('title', topic)}
- æ‘˜è¦: {outline.get('abstract', '')}
- ç« èŠ‚: {', '.join(sections)}

å…³é”®å‘ç°ï¼š
{json.dumps(findings, ensure_ascii=False, indent=2)}

å‚è€ƒæ¥æºï¼š
{chr(10).join(f"- [{s['id']}] {s['title']}" for s in analyzed_sources[:5])}

è¯·ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆ200-300å­—çš„å†…å®¹ï¼Œä½¿ç”¨å­¦æœ¯å†™ä½œé£æ ¼ã€‚
åœ¨å¼•ç”¨è§‚ç‚¹æ—¶ï¼Œæ ‡æ³¨æ¥æºIDï¼Œå¦‚ [src_1]ã€‚"""
        
        response = model.invoke([HumanMessage(content=synthesis_prompt)])
        
        # æ„å»ºç« èŠ‚å†…å®¹ï¼ˆç®€åŒ–ï¼‰
        draft_sections = {
            "introduction": "ï¼ˆç ”ç©¶èƒŒæ™¯å’Œç›®çš„ï¼‰",
            "methodology": outline.get("methodology", "æ–‡çŒ®ç»¼è¿°ä¸åˆ†æ"),
            "findings": response.content,
            "conclusion": "ï¼ˆç ”ç©¶ç»“è®ºï¼‰"
        }
        
        print(f"   ç”Ÿæˆäº† {len(draft_sections)} ä¸ªç« èŠ‚")
        
        return {
            "draft_sections": draft_sections,
            "current_phase": "report_generation",
            "messages": [AIMessage(content="æŠ¥å‘Šåˆç¨¿å·²å®Œæˆ")]
        }
    
    # ---- æŠ¥å‘Šç”ŸæˆèŠ‚ç‚¹ ----
    def report_generation_node(state: ResearchState) -> dict:
        """ç”Ÿæˆæœ€ç»ˆç ”ç©¶æŠ¥å‘Š"""
        print("\n" + "-"*50)
        print("ğŸ“ æŠ¥å‘Šç”Ÿæˆé˜¶æ®µ...")
        
        topic = state["research_topic"]
        outline = state.get("outline", {})
        draft_sections = state.get("draft_sections", {})
        search_results = state.get("search_results", [])
        
        # ç”Ÿæˆå¼•ç”¨åˆ—è¡¨
        citations = []
        for i, result in enumerate(search_results[:6]):
            citation = {
                "id": f"[{i+1}]",
                "authors": result.get("authors", ["Unknown"]),
                "title": result.get("title", ""),
                "source": result.get("source", ""),
                "year": result.get("year", 2024),
                "url": result.get("url", "")
            }
            citations.append(citation)
        
        # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        report_prompt = f"""è¯·å°†ä»¥ä¸‹ç ”ç©¶å†…å®¹æ•´åˆä¸ºä¸€ä»½å®Œæ•´çš„ç ”ç©¶æŠ¥å‘Šï¼š

æ ‡é¢˜ï¼š{outline.get('title', topic + ' ç ”ç©¶æŠ¥å‘Š')}

æ‘˜è¦ï¼š{outline.get('abstract', '')}

ç« èŠ‚å†…å®¹ï¼š
{json.dumps(draft_sections, ensure_ascii=False, indent=2)}

å‚è€ƒæ–‡çŒ®ï¼ˆè¯·åœ¨æŠ¥å‘Šæœ«å°¾åˆ—å‡ºï¼‰ï¼š
{chr(10).join(f"{c['id']} {', '.join(c['authors'])}. {c['title']}. {c['source']}, {c['year']}." for c in citations)}

è¯·è¾“å‡ºæ ¼å¼è§„èŒƒã€ç»“æ„æ¸…æ™°çš„ç ”ç©¶æŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
1. æ ‡é¢˜
2. æ‘˜è¦
3. ç›®å½•
4. æ­£æ–‡å„ç« èŠ‚
5. ç»“è®ºä¸å»ºè®®
6. å‚è€ƒæ–‡çŒ®"""
        
        response = model.invoke([HumanMessage(content=report_prompt)])
        
        final_report = response.content
        
        print(f"   æŠ¥å‘Šå­—æ•°: {len(final_report)}")
        print(f"   å¼•ç”¨æ•°é‡: {len(citations)}")
        
        return {
            "final_report": final_report,
            "citations": citations,
            "current_phase": "quality_check",
            "messages": [AIMessage(content="ç ”ç©¶æŠ¥å‘Šå·²ç”Ÿæˆ")]
        }
    
    # ---- è´¨é‡æ£€æŸ¥èŠ‚ç‚¹ ----
    def quality_check_node(state: ResearchState) -> dict:
        """æ£€æŸ¥æŠ¥å‘Šè´¨é‡"""
        print("\n" + "-"*50)
        print("âœ… è´¨é‡æ£€æŸ¥é˜¶æ®µ...")
        
        final_report = state.get("final_report", "")
        citations = state.get("citations", [])
        
        # è¯„ä¼°è´¨é‡
        quality_prompt = f"""è¯·è¯„ä¼°ä»¥ä¸‹ç ”ç©¶æŠ¥å‘Šçš„è´¨é‡ï¼ˆ0-10åˆ†ï¼‰ï¼š

æŠ¥å‘Šæ‘˜è¦ï¼ˆå‰500å­—ï¼‰ï¼š
{final_report[:500]}...

å¼•ç”¨æ•°é‡ï¼š{len(citations)}

è¯„ä¼°ç»´åº¦ï¼š
1. ç»“æ„å®Œæ•´æ€§
2. è®ºè¯é€»è¾‘æ€§
3. å¼•ç”¨è§„èŒƒæ€§
4. è¯­è¨€è¡¨è¾¾
5. å­¦æœ¯ä¸¥è°¨æ€§

è¯·ç»™å‡ºæ€»åˆ†å’Œæ”¹è¿›å»ºè®®ã€‚"""
        
        response = model.invoke([HumanMessage(content=quality_prompt)])
        
        # ç®€åŒ–è´¨é‡åˆ†æ•°è®¡ç®—
        quality_score = 8.0 if len(final_report) > 1000 and len(citations) >= 3 else 6.5
        
        print(f"   è´¨é‡è¯„åˆ†: {quality_score}/10")
        
        return {
            "quality_score": quality_score,
            "current_phase": "completed",
            "iteration_count": state.get("iteration_count", 0) + 1,
            "messages": [AIMessage(content=f"è´¨é‡è¯„ä¼°å®Œæˆï¼Œå¾—åˆ†ï¼š{quality_score}/10\n\n{response.content}")]
        }
    
    # ---- è·¯ç”±å‡½æ•° ----
    def should_continue(state: ResearchState) -> Literal["continue", "complete"]:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­è¿­ä»£"""
        quality_score = state.get("quality_score", 0)
        iteration_count = state.get("iteration_count", 0)
        
        if quality_score >= 7.5 or iteration_count >= 2:
            return "complete"
        return "continue"
    
# ==================== æ„å»ºå›¾ ====================
    
    graph = StateGraph(ResearchState)
    
    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("planning", planning_node)
    graph.add_node("information_gathering", information_gathering_node)
    graph.add_node("analysis", analysis_node)
    graph.add_node("synthesis", synthesis_node)
    graph.add_node("report_generation", report_generation_node)
    graph.add_node("quality_check", quality_check_node)
    
    # è®¾ç½®æµç¨‹
    graph.add_edge(START, "planning")
    graph.add_edge("planning", "information_gathering")
    graph.add_edge("information_gathering", "analysis")
    graph.add_edge("analysis", "synthesis")
    graph.add_edge("synthesis", "report_generation")
    graph.add_edge("report_generation", "quality_check")
    
    # æ¡ä»¶è·¯ç”±ï¼šæ ¹æ®è´¨é‡å†³å®šæ˜¯å¦é‡æ–°è¿­ä»£
    graph.add_conditional_edges(
        "quality_check",
        should_continue,
        {
            "continue": "analysis",  # é‡æ–°åˆ†æ
            "complete": END
        }
    )
    
    # ç¼–è¯‘
    memory = MemorySaver()
    compiled_graph = graph.compile(checkpointer=memory)
    
    return compiled_graph

# ==================== è¿è¡Œç ”ç©¶ä»»åŠ¡ ====================

def run_research(topic: str):
    """è¿è¡Œç ”ç©¶ä»»åŠ¡"""
    print("\n" + "="*60)
    print("ğŸ”¬ å¯åŠ¨ç ”ç©¶ä»»åŠ¡")
    print("="*60)
    print(f"ç ”ç©¶ä¸»é¢˜: {topic}")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # åˆ›å»ºç ”ç©¶åŠ©æ‰‹
    assistant = create_research_assistant()
    
    # åˆå§‹çŠ¶æ€
    initial_state = {
        "messages": [HumanMessage(content=f"è¯·å¯¹ä»¥ä¸‹ä¸»é¢˜è¿›è¡Œæ·±å…¥ç ”ç©¶ï¼š{topic}")],
        "research_topic": topic,
        "research_questions": [],
        "search_results": [],
        "analyzed_sources": [],
        "outline": {},
        "findings": [],
        "draft_sections": {},
        "final_report": "",
        "citations": [],
        "current_phase": "planning",
        "iteration_count": 0,
        "quality_score": 0.0
    }
    
    # è¿è¡Œç ”ç©¶æµç¨‹
    config = {"configurable": {"thread_id": f"research_{datetime.now().strftime('%Y%m%d%H%M%S')}"}}
    result = assistant.invoke(initial_state, config)
    
    # è¾“å‡ºç»“æœ
    print("\n" + "="*60)
    print("ğŸ“„ ç ”ç©¶æŠ¥å‘Š")
    print("="*60)
    print(result.get("final_report", "æŠ¥å‘Šç”Ÿæˆå¤±è´¥"))
    
    print("\n" + "-"*60)
    print("ğŸ“š å‚è€ƒæ–‡çŒ®")
    print("-"*60)
    for citation in result.get("citations", []):
        authors = ", ".join(citation.get("authors", ["Unknown"]))
        print(f"{citation['id']} {authors}. {citation['title']}. {citation['source']}, {citation['year']}.")
    
    print("\n" + "-"*60)
    print("ğŸ“Š ç ”ç©¶ç»Ÿè®¡")
    print("-"*60)
    print(f"  - æ”¶é›†èµ„æ–™æ•°: {len(result.get('search_results', []))}")
    print(f"  - åˆ†ææ¥æºæ•°: {len(result.get('analyzed_sources', []))}")
    print(f"  - è¿­ä»£æ¬¡æ•°: {result.get('iteration_count', 0)}")
    print(f"  - è´¨é‡è¯„åˆ†: {result.get('quality_score', 0):.1f}/10")
    print(f"  - æŠ¥å‘Šå­—æ•°: {len(result.get('final_report', ''))}")
    
    return result

# ==================== é«˜çº§åŠŸèƒ½æ¼”ç¤º ====================

def demonstrate_advanced_features():
    """æ¼”ç¤ºé«˜çº§åŠŸèƒ½"""
    print("\n" + "="*60)
    print("ğŸš€ é«˜çº§åŠŸèƒ½æ¼”ç¤º")
    print("="*60)
    
        
    # åŠŸèƒ½1ï¼šå¤šä¸»é¢˜æ¯”è¾ƒç ”ç©¶
    print("\nğŸ“Š åŠŸèƒ½1ï¼šå¤šä¸»é¢˜æ¯”è¾ƒåˆ†æ")
    print("-"*50)
    
    topics = ["äººå·¥æ™ºèƒ½", "é‡å­è®¡ç®—", "æ°”å€™å˜åŒ–"]
    comparisons = []
    
    for topic in topics:
        academic = search_academic_database(topic, max_results=2)
        web = search_web(topic, max_results=2)
        comparisons.append({
            "topic": topic,
            "academic_count": len(academic),
            "web_count": len(web),
            "total_sources": len(academic) + len(web)
        })
        print(f"  {topic}: å­¦æœ¯ {len(academic)} ç¯‡, ç½‘ç»œ {len(web)} æ¡")
    
    # åŠŸèƒ½2ï¼šç ”ç©¶è¶‹åŠ¿åˆ†æ
    print("\nğŸ“ˆ åŠŸèƒ½2ï¼šç ”ç©¶è¶‹åŠ¿åˆ†æ")
    print("-"*50)
    
    trend_prompt = """åŸºäºä»¥ä¸‹ä¸»é¢˜çš„ç ”ç©¶èµ„æ–™æ•°é‡ï¼Œåˆ†æå½“å‰ç ”ç©¶çƒ­ç‚¹è¶‹åŠ¿ï¼š
    
- äººå·¥æ™ºèƒ½ï¼šå­¦æœ¯æ–‡çŒ®3ç¯‡ï¼Œæ–°é—»æŠ¥é“2æ¡
- é‡å­è®¡ç®—ï¼šå­¦æœ¯æ–‡çŒ®1ç¯‡ï¼Œæ–°é—»æŠ¥é“1æ¡
- æ°”å€™å˜åŒ–ï¼šå­¦æœ¯æ–‡çŒ®2ç¯‡ï¼Œæ–°é—»æŠ¥é“1æ¡

è¯·ç®€è¦åˆ†æï¼ˆ100å­—ä»¥å†…ï¼‰ï¼š"""
    
    trend_analysis = model.invoke([HumanMessage(content=trend_prompt)])
    print(f"  è¶‹åŠ¿åˆ†æ: {trend_analysis.content}")
    
    # åŠŸèƒ½3ï¼šæ™ºèƒ½æ–‡çŒ®æ¨è
    print("\nğŸ“š åŠŸèƒ½3ï¼šæ™ºèƒ½æ–‡çŒ®æ¨è")
    print("-"*50)
    
    user_interest = "æˆ‘å¯¹AI Agentçš„åº”ç”¨å¾ˆæ„Ÿå…´è¶£"
    
    recommend_prompt = f"""ç”¨æˆ·å…´è¶£ï¼š{user_interest}

å¯ç”¨æ–‡çŒ®ï¼š
1. æ·±åº¦å­¦ä¹ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨ç»¼è¿°
2. å¤§è¯­è¨€æ¨¡å‹çš„æ¶Œç°èƒ½åŠ›ç ”ç©¶
3. AI Agentç³»ç»Ÿçš„è®¾è®¡ä¸å®ç°
4. å…¨çƒæ°”å€™å˜åŒ–å¯¹å†œä¸šçš„å½±å“è¯„ä¼°
5. é‡å­è®¡ç®—æœºçš„å‘å±•ç°çŠ¶ä¸æŒ‘æˆ˜

è¯·æ¨èæœ€ç›¸å…³çš„2ç¯‡æ–‡çŒ®ï¼Œå¹¶ç®€è¦è¯´æ˜åŸå› ï¼ˆ50å­—ä»¥å†…ï¼‰ã€‚"""
    
    recommendations = model.invoke([HumanMessage(content=recommend_prompt)])
    print(f"  æ¨èç»“æœ:\n{recommendations.content}")

# ==================== ä¸»ç¨‹åº ====================

def main():
    """ä¸»ç¨‹åº"""
    print("="*60)
    print("ğŸ”¬ æ™ºèƒ½ç ”ç©¶åŠ©æ‰‹ç³»ç»Ÿ")
    print("="*60)
    
    # ç ”ç©¶ä¸»é¢˜åˆ—è¡¨
    research_topics = [
        "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨",
        # "é‡å­è®¡ç®—çš„å•†ä¸šåŒ–å‰æ™¯",  # å¯é€‰æ›´å¤šä¸»é¢˜
        # "ç¢³ä¸­å’ŒæŠ€æœ¯å‘å±•è·¯å¾„"
    ]
    
    # è¿è¡Œç ”ç©¶ä»»åŠ¡
    for topic in research_topics:
        print(f"\n{'#'*60}")
        print(f"# ç ”ç©¶ä¸»é¢˜: {topic}")
        print(f"{'#'*60}")
        
        result = run_research(topic)
        
        print("\nâ³ ç ”ç©¶å®Œæˆ\n")
    
    # æ¼”ç¤ºé«˜çº§åŠŸèƒ½
    demonstrate_advanced_features()
    
    print("\n" + "="*60)
    print("âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
    print("="*60)
    
    # ä½¿ç”¨è¯´æ˜
    print("\nğŸ’¡ æ‰©å±•ä½¿ç”¨ç¤ºä¾‹:")
    print("-"*60)
    print("""
# è‡ªå®šä¹‰ç ”ç©¶ä¸»é¢˜
result = run_research("åŒºå—é“¾åœ¨ä¾›åº”é“¾ç®¡ç†ä¸­çš„åº”ç”¨")

# è®¿é—®ç ”ç©¶ç»“æœ
print(result["final_report"])  # å®Œæ•´æŠ¥å‘Š
print(result["citations"])      # å‚è€ƒæ–‡çŒ®
print(result["findings"])       # å…³é”®å‘ç°

# å¯¼å‡ºæŠ¥å‘Š
with open("research_report.md", "w") as f:
    f.write(result["final_report"])
""")

if __name__ == "__main__":
    main()
